
    \begin{chapter}{Sistemas lineales}\label{chap-sist-lin}
        
        En  este capítulo estudiaremos en forma sistemática los sistemas de ecuaciones lineales,  es decir las soluciones de un conjunto finito de ecuaciones  donde la relación entre las incógnitas se expresa en forma lineal.  
        
        
        \begin{section}{Sistemas de ecuaciones lineales}\label{seccion-sistemas-de-ecuaciones-lineales}
  
        
            El problema a resolver será el siguiente: buscamos números  $x_1,\ldots,x_n$ en el cuerpo $\K$ ($= \R$ o $\C$)  que satisfagan las siguientes condiciones
            \begin{equation}\label{sist-eq}
            \begin{matrix}
            a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
            \vdots&  &\vdots& &&  &\vdots \\
            a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_m
            \end{matrix}
            \end{equation}
            donde $y_1, \ldots,y_m$ y $a_{i,j}$ ($1 \le i \le m$, $1 \le j \le n$) son números en $\K$.
            
            Llamaremos a \eqref{sist-eq} un \textit{sistema de $m$ ecuaciones lineales con $n$ incógnitas.}\index{sistema de ecuaciones lineales} A una  $n$-tupla $(x_1,\ldots,x_n)$ de elementos de $\K^n$ que satisface cada una de las ecuaciones de  \eqref{sist-eq} la llamaremos una \textit{solución del sistema}. Si $y_1 = \cdots = y_m=0$, el sistema se llamará \textit{homogéneo.} En caso contrario el sistema se denominará \textit{no homogéneo.}\index{sistema de ecuaciones lineales!homogéneo}\index{sistema de ecuaciones lineales!no  homogéneo}

            \begin{ejemplo*}
                Los siguientes son sistemas de $2$ ecuaciones lineales con $2$ incógnitas:
                    \begin{enumerate}
                        \begin{minipage}{0.3\textwidth}
                        \item $\begin{matrix*}[l]
                            2x_1 + 8x_2 &= 0 &  \\
                            2x_1 + x_2 &=  1& 
                            \end{matrix*}$\end{minipage}
                            \begin{minipage}{0.3\textwidth}
                        \item $\begin{matrix*}[l]
                            2x_1 + x_2 &= 0 &  \\
                            2x_1 - x_2 &=  1& 
                            \end{matrix*}$\end{minipage}
                            \begin{minipage}{0.3\textwidth}
                        \item $ \begin{matrix*}[l]
                            2x_1 + x_2 &= 1 &  \\
                            4x_1 +2 x_2 &=  2& 
                            \end{matrix*}$\end{minipage}
                    \end{enumerate}
            \end{ejemplo*} 
            
            \begin{ejemplo}\label{ej-sist-1}
                Resolvamos ahora un sistema de ecuaciones homogéneo sencillo:
                \begin{equation*}
                \begin{matrix}
                \text{\footnotesize\circled{1}}&\qquad& 2x_1 -x_2 + x_3 &=& 0 \\
                \text{\footnotesize\circled{2}}&\qquad& x_1 + 3x_2 + 4x_3 &=& 0.
                \end{matrix}
                \end{equation*}
            \end{ejemplo}
            \begin{proof}[Solución]
                Observar que $(0,0,0)$ es solución. Busquemos otras soluciones manipulado las ecuaciones.

                Si  hacemos $-2$ {\footnotesize\circled{2}} $+$  {\footnotesize\circled{1}}, obtenemos: 
                $$ -7x_2 - 7x_3 = 0 \;\Rightarrow\; x_2 = -x_3.$$
                
                Si  hacemos $3$ {\footnotesize\circled{1}} $+$ {\footnotesize\circled{2}}, obtenemos: 
                $$ 7x_1 + 7x_3 = 0 \;\Rightarrow\;  x_1  =  -x_3.$$
                
                Esto nos dice que las soluciones son de la forma $\{(-x_3,-x_3, x_3): x_3 \in \R \}$, por ejemplo $(-1,-1,1)$ es solución y $(1,2,3)$ no es solución.
            \end{proof}
            
                
            En  el ejemplo anterior hemos encontrado soluciones por \textit{eliminación de incógnitas},  es decir multiplicando por constantes adecuadas  ciertas ecuaciones y sumándolas hemos eliminado en  {\footnotesize\circled{$1$}} a $x_1$ y en  {\footnotesize\circled{$2$}} a $x_2$, con lo cual la solución del sistema se deduce inmediatamente por pasaje de término.   
            
            \begin{ejemplo}\label{ej-sist-2}
                    Encontrar las soluciones $(x,y,z)$ del sistema de ecuaciones:
                    \begin{equation*}
                    \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad&x &  & +2z & =& 1 \\
                    \text{\footnotesize\circled{2}}&\qquad&x& -3y & +3z & =&2 \\
                    \text{\footnotesize\circled{3}}&\qquad&2x& -y & +5z & =&3
                    \end{matrix} \tag{S1}
                    \end{equation*}
                    Es decir, queremos encontrar los números reales $x$, $y$ y $z$ que satisfagan las ecuaciones anteriores.
                
            \end{ejemplo}
                
                \begin{proof}[Solución]
                    Veremos que la única solución es $(x,y,z)=(-1,0,1)$.  El  método que usaremos, similar al del ejemplo anterior,  será el de eliminación de variables o incógnitas: vemos  en el sistema que queremos resolver $8$ variables, algunas repetidas: $2$ de la ecuación \text{\footnotesize\circled{1}}, $3$ de la ecuación \text{\footnotesize\circled{2}} y $3$ de la ecuación \text{\footnotesize\circled{3}}. Trataremos de eliminar en cada ecuación la mayor cantidad de variables posibles de tal forma de llegar a una formulación equivalente del sistema que nos de inmediatamente la solución. 

    Supongamos que $(x,y,z)$ es una solución de nuestro sistema. Entonces también vale que: 
    \begin{equation*}
    \begin{matrix}
    &\text{\footnotesize\circled{2}}&\qquad&x& -3y & +3z & = & 2 \\
    (-1)&\text{\footnotesize\circled{1}}&\qquad(-1)&(x &  & +2z) & = &(-1)\cdot1 \\
    \hline
    &\text{\footnotesize\circled{2}}&\qquad&& -3y & +z & = & 1  
    \end{matrix}
    \end{equation*}
    (a la ecuación que modificamos le asignamos el mismo número).
     
    Por lo tanto $(x,y,z)$ también es solución del sistema
    \begin{equation*}
    \begin{matrix}
        \text{\footnotesize\circled{1}}&\qquad&x &  & +2z & = 1 \\
        \text{\footnotesize\circled{2}}&\qquad&& -3y & +z & = 1   \\
        \text{\footnotesize\circled{3}}&\qquad&2x& -y & +5z & =3
    \end{matrix}\tag{S2}
    \end{equation*}
 


 
Dado que $(x,y,z)$ es solución del sistema (S2),  entonces también vale que:
\begin{equation*}
\begin{matrix}
& \text{\footnotesize\circled{3}}&\qquad&&2x& -y & +5z & = &3 \\
(-2)& \text{\footnotesize\circled{1}}&\qquad&(-2)&(x &  & +2z) & = &(-2)\cdot1 \\
\hline
& \text{\footnotesize\circled{3}}&\qquad&& & -y & + z & = & 1  
\end{matrix}
\end{equation*}
 

Por lo tanto $(x,y,z)$ también es solución del sistema
\begin{equation*}
\begin{matrix}
    \text{\footnotesize\circled{1}}&\qquad&x &  & +2z & = 1 \\
    \text{\footnotesize\circled{2}}&\qquad&& -3y & +z & = 1   \\
    \text{\footnotesize\circled{3}}&\qquad&& -y & +z & =1
\end{matrix}\tag{S3}
\end{equation*}
 

 
Dado que $(x,y,z)$ es solución del sistema (S3), entonces también vale que: 
\begin{equation*}
\begin{matrix}
& \text{\footnotesize\circled{2}}&\qquad&& -3y & +z & = & 1 \\
(-3)& \text{\footnotesize\circled{3}}&\qquad&(-3)&( -y & +z) & = &(-3)\cdot1 \\
\hline
& \text{\footnotesize\circled{2}}&\qquad&&   & -2z & = & -2  
\end{matrix}
\end{equation*}

 
Por lo tanto $(x,y,z)$ también es solución del sistema
\begin{equation*}
    \begin{cases}
        x  +2z  &= 1 \\
 -2z & = -2\\
 -y  +z & =1 
    \end{cases},
\qquad\mbox{o equivalentemente}\qquad
\begin{cases}
x +2z & = 1 \\
 z & = 1\\
 -y  +z & =1 
\end{cases}
\end{equation*}
 

 
Dado $(x,y,z)$ es solución del sistema
\begin{equation*}
\begin{matrix}
    \text{\footnotesize\circled{1}}&x &  & +2z & = 1 \\
    \text{\footnotesize\circled{2}}&&    & z & = 1 \\
    \text{\footnotesize\circled{3}}&& -y & +z & =1
\end{matrix}\tag{S4}
\end{equation*}
o equivalentemente, intercambiando la 2º y 3º ecuación,  
\begin{equation*}
\begin{matrix}
    \text{\footnotesize\circled{1}}&x &  & +2z & = 1 \\
    \text{\footnotesize\circled{2}}&& -y & +z & =1\\
    \text{\footnotesize\circled{3}}&&    & z & = 1 
\end{matrix}\tag{S5}
\end{equation*}

 Haciendo {\footnotesize\circled{1}} $- 2$ {\footnotesize\circled{3}} y {\footnotesize\circled{2}} $-$ {\footnotesize\circled{3}}, obtenemos 
\begin{equation*}
    \begin{cases}
        x  & = -1 \\
        -y  & =0 \\
        z & = 1
    \end{cases} 
    \qquad \Rightarrow\qquad
    \begin{cases}
        x & = -1 \\
    y & =0 \\
    z & = 1
    \end{cases}
\end{equation*}

En resumen, supusimos que $(x,y,z)$ es una solución del sistema
\begin{equation*}
\begin{cases}
    x  +2z & = 1 \\
    x -3y  +3z & =2 \\
    2x -y  +3z & =1
\end{cases}
\end{equation*}
y probamos que 
\begin{equation*}
x=-1\quad y=0,\quad z=1. 
\end{equation*}
\end{proof}

Tanto en el ejemplo \ref{ej-sist-1} como en el ejemplo \ref{ej-sist-2} eliminamos variables usando alguna de las siguientes operaciones entre ecuaciones:
    \begin{enumelem}
        \item\label{e1-v1} multiplicar una ecuación por una constante no nula,  
        \item\label{e2-v1} sumar a una ecuación una constante por otra, y
        \item\label{e3-v1} permutar ecuaciones.  
    \end{enumelem}
    
Cada una de estas operaciones entre ecuaciones es  ``reversible'': en el caso de \ref{e1-v1}, si multiplicamos una ecuación por una constante $c\ne 0$, multiplicando por $1/c$ volvemos a la ecuación original.  En el caso de \ref{e2-v1}, si modificamos la ecuación $i$-ésima sumándole $c$ veces la ecuación $j$-ésima, podemos recuperar el sistema de ecuaciones original, restándole a la ecuación $i$-ésima  $c$ veces la ecuación $j$-ésima. Finalmente, en el caso  de  \ref{e3-v1}, si permutamos la ecuación $i$  con la $j$,  volvemos al sistema original haciendo la misma permutación. 


Veremos en las siguientes secciones que con las operaciones \ref{e1-v1}, \ref{e2-v1} y \ref{e3-v1} podemos reducir todo sistema de ecuaciones a uno cuyas soluciones son obvias. Eso es lo que hicimos en el ejemplo \ref{ej-sist-2}.  
    
    
\begin{ejemplo*}
Así como  haciendo operaciones del tipo\ref{e1-v1}, \ref{e2-v1} y \ref{e3-v1}   en la ecuaciones del ejemplo \ref{ej-sist-2}   llegamos de 
    
    \begin{equation*}
    \begin{matrix}
    x &  & +2z & =& 1 \\
    x& -3y & +3z & =&2 \\
    2x& -y & +5z & =&3
    \end{matrix}
    \qquad \text{ a } 
    \qquad 
    \begin{matrix}x&=&-1\\ y&=&0 \\ z&=&1,
    \end{matrix}
    \end{equation*}
haciendo  las ``operaciones inversas'' (que son del mismo tipo)  podemos llegar de  
\begin{equation*}
\begin{matrix}x&=&-1\\ y&=&0 \\ z&=&1.
\end{matrix}
\qquad \text{ a } 
\qquad 
\begin{matrix}
x &  & +2z & =& 1 \\
x& -3y & +3z & =&2 \\
2x& -y & +5z & =&3
\end{matrix}.
\end{equation*}
\end{ejemplo*}

\subsection*{$\S$ Ejercicios}
\begin{enumex}
    \item Usando operaciones del tipo  \ref{e1-v1}, \ref{e2-v1} y \ref{e3-v1} reducir los siguientes sistemas de ecuaciones lineales a  sistemas más sencillos (que permitan conocer las soluciones) y mostrar como podemos recuperar los sistemas originales.
    \begin{enumex}
        \begin{minipage}{0.4\textwidth}
        \item $\begin{cases}
            x+y+z &= 1 \\
            x+2y-z&=-2 \\
            x-y+6z &= 3
        \end{cases}$,\end{minipage}
        \begin{minipage}{0.4\textwidth}
        \item $\begin{cases}
            3x +2 y + z &=0 \\
            x+y+z &= 0 \\
            2x +y &=0
        \end{cases}$.\end{minipage}
    \end{enumex}
\end{enumex}


\end{section}


\begin{section}{Equivalencia de sistemas de ecuaciones lineales}\label{seccion-equivalencia-de-sistemas-de-ecuaciones-lineales}

            Dado el sistema
            \begin{equation}\label{sist-eq-2}
            \begin{matrix}
            a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
            \vdots&  &\vdots& &&  &\vdots \\
            a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_m
            \end{matrix}
            \end{equation}
            donde $y_1, \ldots,y_m$ y $a_{i,j}$ ($1 \le i \le m$, $1 \le j \le n$) son números en $\K$, si multiplicamos cada ecuación por $c_i$ ($1 \le i \le m$) y sumamos miembro a miembro obtenemos
            \begin{equation*}
            \sum_{i=1}^m c_i(a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n) = \sum_i c_iy_i.
            \end{equation*}
            Expandiendo la ecuación y tomando como factor común los $x_j$ ($1 \le j \le n$) obtenemos la ecuación
            \begin{multline*}
            (c_{1}a_{11} + c_2a_{21}+ \cdots + c_ma_{m1})x_1 + \cdots +  	(c_{1}a_{1n} + c_2a_{2n}+ \cdots + c_ma_{mn})x_n = \\ = 	c_{1}y_{1} + c_2y_{2}+ \cdots + c_my_{m},
            \end{multline*}
            o,  escrito de otra forma, 
            \begin{equation}\label{comb-lin-eq}
            \left(\sum_{i=1}^{m}c_{i}a_{i1}\right)x_1 + \cdots +  	\left(\sum_{i=1}^{m}c_{i}a_{in}\right)x_n = \sum_{i=1}^{m}	c_{i}y_{i},
            \end{equation}
            la cual es una \textit{combinación lineal} de las ecuaciones dadas en \eqref{sist-eq-2}. 
            Observar que la ecuación \eqref{comb-lin-eq},  es  una ecuación lineal con $n$ incógnitas, es decir  es del mismo tipo que cada una de las ecuaciones que componen el sistema de ecuaciones original.
            
            \begin{proposicion}\label{sist-impl}
                Sean $c_1,\ldots,c_m$ en $\K$. Si $(x_1,\ldots,x_n) \in \K^n$  es solución del sistema de ecuaciones
                \begin{equation*}
                \begin{matrix}
                a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
                \vdots&  &\vdots& &&  &\vdots \\
                a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_m.
                \end{matrix}
                \end{equation*}
                 entonces $(x_1,\ldots,x_n)$ también es solución de la ecuación
                 \begin{equation*}
                 \left(\sum_{i=1}^{m}c_{i}a_{i1}\right)x_1 + \cdots +  	\left(\sum_{i=1}^{m}c_{i}a_{in}\right)x_n = \sum_{i=1}^{m}	c_{i}y_{i},
                 \end{equation*}
            \end{proposicion}
            \begin{proof}
                Por hipótesis
                \begin{equation*}
                a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = y_i,\; \text{ para } 1 \le i \le m.
                \end{equation*}
                Luego, 
                \begin{equation*}
                \sum_{i=1}^m c_i(a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n) = \sum_i c_iy_i
                \end{equation*}
                y  esta, como vimos, es otra escritura de la ecuación \eqref{comb-lin-eq}.
            \end{proof}
            
            La idea de hacer combinaciones lineales de ecuaciones es fundamental en el proceso de eliminación de incógnitas. En principio, no es cierto que si obtenemos un sistema de ecuaciones por combinaciones lineales de otro sistema, ambos tengan las mismas soluciones   (por ejemplo, hacer combinaciones lineales triviales con todos los coeficientes iguales a $0$).
        
            \begin{definicion}
            Decimos que dos sistemas de ecuaciones lineales son \textit{equivalentes}\index{sistemas lineales equivalentes} si cada ecuación de un sistema es combinación lineal del otro.
            \end{definicion}
            
            
            \begin{teorema}\label{sistemas-equiv}
                Dos sistemas de ecuaciones lineales equivalentes tienen las mismas soluciones.
            \end{teorema}
            \begin{proof}
                Sea 
                \begin{equation}\label{sist-01} \tag{*}
                \begin{matrix}
                a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
                \vdots&  &\vdots& &&  &\vdots \\
                a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_m
                \end{matrix}
                \end{equation}
                equivalente a
                \begin{equation}\label{sist-02} \tag{**}
                \begin{matrix}
                b_{11}x_1& + &b_{12}x_2& + &\cdots& + &b_{1n}x_n &= &z_1\\
                \vdots&  &\vdots& &&  &\vdots \\
                b_{k1}x_1& + &b_{k2}x_2& + &\cdots& + &b_{kn}x_n &=&z_k,
                \end{matrix}.
                \end{equation}
                En particular, las ecuaciones  de \eqref{sist-02} se obtienen a partir de combinaciones  lineales de las ecuaciones del sistema  \eqref{sist-01}. Luego, por proposición \ref{sist-impl}, si  $(x_1,\ldots,x_n)$  es solución de  \eqref{sist-01}, también será solución de cada una de las ecuaciones de \eqref{sist-02} y por lo tanto solución  del sistema. 
                
                Recíprocamente, como también las ecuaciones  de \eqref{sist-01} se obtienen a partir de     combinaciones lineales de las ecuaciones del sistema  \eqref{sist-02}, toda solución  de    \eqref{sist-02} es solución de   \eqref{sist-01}.
            \end{proof}
            

            \begin{observacion*}
                La equivalencia de sistemas lineales es una relación de equivalencia,  en particular  vale la propiedad transitiva: si el sistema (A) es equivalente al sistema (B) y  el sistema (B)  es equivalente al sistema (C),  entonces (A) es equivalente a (C). Esto nos permite, ir paso a paso para eliminar las incógnitas. 
            \end{observacion*} 

    
            \begin{ejemplo*}
                Encontrar las soluciones del siguiente sistema de ecuaciones
                \begin{equation*}\label{sist-000} \tag{S0}
                \begin{matrix}
                \text{{\footnotesize\circled{1}}}&\qquad& 2x_1 &+&4x_2 &-& 6x_3 &=& 0 \\
                \text{{\footnotesize\circled{2}}}&\qquad& 3x_1 &-& x_2 &+& 5x_3 &=& 0.
                \end{matrix}
                \end{equation*}
            \end{ejemplo*}
            \begin{proof}[Solución]
                Si reemplazamos la ecuación {\footnotesize\circled{1}} por {\footnotesize\circled{1}}$/2$, obtenemos el sistema
                \begin{align*}\label{sist-001} \tag{S1}
                \begin{matrix}
                \text{\footnotesize\circled{1}}&\qquad x_1 &+&2x_2 &-& 3x_3 &=& 0 \\
                \text{\footnotesize\circled{2}}&\qquad 3x_1 &-& x_2 &+& 5x_3 &=& 0.
                \end{matrix}
                \end{align*}
                (a la ecuación que modificamos le asignamos el mismo número). Reemplazando  \text{\footnotesize\circled{2}} por  \text{\footnotesize\circled{2}}$\,-3$ \text{\footnotesize\circled{1}}, obtenemos
                \begin{align*}\label{sist-002} \tag{S2}
                \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad x_1 &+&2x_2 &-& 3x_3 &=& 0 \\
                    \text{\footnotesize\circled{2}}&\qquad &-&7 x_2 &+& 14x_3 &=& 0.
                \end{matrix}
                \end{align*} 
                Reemplazando \text{\footnotesize\circled{2}} por \text{\footnotesize\circled{2}}$/(-7)$, obtenemos
                \begin{align*}\label{sist-003} \tag{S3}
                \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad x_1 &+&2x_2 &-& 3x_3 &=& 0 \\
                    \text{\footnotesize\circled{2}}&\qquad && x_2 &-& 2x_3 &=& 0.
                \end{matrix}
                \end{align*} 
                Reemplazando \text{\footnotesize\circled{1}} por \text{\footnotesize\circled{1}} $-2$ \text{\footnotesize\circled{2}}, obtenemos
                \begin{align*}\label{sist-004} \tag{S4}
                \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad x_1 && &+& x_3 &=& 0 \\
                    \text{\footnotesize\circled{2}}&\qquad && x_2 &-& 2x_3 &=& 0.
                \end{matrix}
                \end{align*} 
                
                Luego $x_1 = -x_3$ y $x_2 = 2x_3$, y esto nos dice que las soluciones son de la forma $\{(-x_3,2x_3, x_3): x_3 \in \R \}$.
                
                Por otro lado, observar que 
                \begin{itemize}
                    \item a partir de \eqref{sist-004} podemos obtener \eqref{sist-003} reemplazando {\footnotesize\circled{1}} por {\footnotesize\circled{1}} $+2$ {\footnotesize\circled{2}};
                    \item a partir de \eqref{sist-003} podemos obtener \eqref{sist-002} reemplazando {\footnotesize\circled{2}} por $-7$ {\footnotesize\circled{2}};
                    \item a partir de \eqref{sist-002} podemos obtener \eqref{sist-001} reemplazando {\footnotesize\circled{2}} por {\footnotesize\circled{2}} $+3$ {\footnotesize\circled{1}};
                    \item a partir de \eqref{sist-001} podemos obtener \eqref{sist-000} reemplazando  {\footnotesize\circled{1}} por $2$  {\footnotesize\circled{1}}.
                \end{itemize}
                
                Es decir los sistemas  \eqref{sist-000} y 
                \eqref{sist-004} son equivalentes y por lo tanto  tienen las mismas soluciones.  Como el conjunto de soluciones de 
                \eqref{sist-004} es $\{(-x_3,2x_3, x_3): x_3 \in \R \}$,  éste también es el conjunto de soluciones del sistema original. 
            \end{proof}
            
            \begin{ejemplo*}
                Encontrar las soluciones del siguiente sistema de ecuaciones
                \begin{equation*}
                \begin{matrix}
                \text{\footnotesize\circled{1}}&\qquad& 2x_1 &-&x_2 &+& x_3 &=& 1 \\
                \text{\footnotesize\circled{2}}&\qquad& x_1 &+& 3x_2 &+& 3x_3 &=&  2 \\
                \text{\footnotesize\circled{3}}&\qquad& x_1 &+& &+& 2x_3 &=&   1 .
                \end{matrix}
                \end{equation*}
                (observar que en {\footnotesize\circled{3}} el coeficiente de $x_2$ es cero.)
            \end{ejemplo*}
            \begin{proof}[Solución] Si
                \begin{align*}
                \begin{matrix*}[l]
                &\text{reemplazamos {\footnotesize\circled{1}} por }&\text{\footnotesize\circled{1}}-2\,\text{\footnotesize\circled{3}}  & \text{obtenemos:} & &\; -x_2 - 3x_3&=&-1, \\
                &\text{reemplazamos {\footnotesize\circled{2}} por }&\text{\footnotesize\circled{2}} - \text{\footnotesize\circled{3}}& \text{obtenemos:} & &\; 3x_2 + x_3&=& 1.
                \end{matrix*}
                \end{align*}
                El sistema es ahora
                \begin{equation*}
                    \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad&  &-&x_2 &-&3 x_3 &=& -1 \\
                    \text{\footnotesize\circled{2}}&\qquad&  && 3x_2 &+& x_3 &=& 1 \\
                    \text{\footnotesize\circled{3}}&\qquad& x_1 &+& &+& 2x_3 &=&   1 .
                    \end{matrix}
                    \end{equation*}
                Ahora, reemplazando  {\footnotesize\circled{2}} por  {\footnotesize\circled{2}} $+3$ {\footnotesize\circled{1}}, obtenemos
                \begin{equation*}
                    \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad&  &-&x_2 &-&3 x_3 &=& -1 \\
                    \text{\footnotesize\circled{2}}&\qquad&  &&  && -8x_3 &=& -2 \\
                    \text{\footnotesize\circled{3}}&\qquad& x_1 &+& &+& 2x_3 &=&   1 .
                    \end{matrix}
                \end{equation*}
                Dividiendo por $-8$ la ecuación  {\footnotesize\circled{2}}, obtenemos
                \begin{equation*}
                    \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad&  &-&x_2 &-&3 x_3 &=& -1 \\
                    \text{\footnotesize\circled{2}}&\qquad&  &&  && x_3 &=& \frac14 \\
                    \text{\footnotesize\circled{3}}&\qquad& x_1 &+& &+& 2x_3 &=&   1 .
                    \end{matrix}
                \end{equation*} 
                Finalmente, si reemplazamos {\footnotesize\circled{1}} por {\footnotesize\circled{1}} $+ 3$ {\footnotesize\circled{2}} y {\footnotesize\circled{3}} por  {\footnotesize\circled{3}} $-2$ {\footnotesize\circled{3}}, obtenemos 
                \begin{equation*}
                    \begin{matrix}
                    \text{\footnotesize\circled{1}}&\qquad&  -x_2  &=& -\frac14 \\
                    \text{\footnotesize\circled{2}}&\qquad&  x_3 &=& \frac14 \\
                    \text{\footnotesize\circled{3}}&\qquad& x_1  &=&   \frac12 .
                    \end{matrix}
                \end{equation*} 
                Por lo tanto, $x_1 = \frac12$, $x_2 = \frac14$, $x_3 = \frac14$. 
            \end{proof}
            
            \subsection*{$\S$ Ejercicios}

            \begin{enumex}
                \item Encontrar las soluciones de los siguientes sistemas de ecuaciones realizando operaciones del tipo \ref{e1-v1}, \ref{e2-v1} y \ref{e3-v1}.
                    \begin{enumex}
                        \begin{minipage}{0.4\textwidth}
                            \item $\begin{cases}
                                5x +2y&= 2 \\
                                 2x+y-z&=0 \\
                             2x+3y-z &= 3
                             \end{cases}$\,,
                        \end{minipage}
                        \begin{minipage}{0.4\textwidth}
                            \item $\begin{cases}
                                x -y + 5z&= \sqrt2 \\
                                 \sqrt5x+z&=\sqrt3 \\[.1cm]
                             \displaystyle\frac25x+3y+2z &= \displaystyle\frac52
                             \end{cases}$\,,
                        \end{minipage}
    
                        \begin{minipage}{0.4\textwidth}
                            \item $\begin{cases}
                                3x - y + 7z &=1 \\
                                5x +z &=2
                            \end{cases}$\,, 
                        \end{minipage}
                        \begin{minipage}{0.4\textwidth}
                            \item $\begin{cases}
                                x +2 y -3z -t &=0 \\
                                -3 y +2z +6t &=-8 \\
                                -3x - y +3z +t &=0 \\
                                2x +3 y +23z -t &=-8 
                            \end{cases}$\,. 
                        \end{minipage}
                    \end{enumex} 
            \end{enumex}

        \end{section}
        

        
        
        \begin{section}{Matrices}\label{seccion-matrices}
            

            \vskip .4cm En  esta sección introduciremos el concepto de matriz y veremos un sistema de ecuaciones se puede describir en el lenguaje de las matrices. También veremos que sistemas de ecuaciones lineales equivalentes se corresponden con matrices equivalentes por filas. Esto nos permitirá,  en la próxima sección, explicitar en forma clara y concisa el  método de Gauss.  
            
            Debemos tener claro que las matrices en el contexto de esta sección, no son más que una notación más cómoda para el problema de resolver sistemas de ecuaciones lineales.  
            
            Estudiaremos la solución de un sistema de ecuaciones lineales 
            \begin{equation}\label{sist-eq-hom}
            \begin{matrix}
            a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
            \vdots&  &\vdots& &&  &\vdots \\
            a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_m.
            \end{matrix}
            \end{equation}
            Observemos que podemos escribir los coeficientes de  las fórmulas de la izquierda en  un arreglo rectangular de $m$ filas y $n$ columnas:
            \begin{equation}\label{matriz}
            A = \begin{bmatrix}
            a_{11}& a_{12}& \cdots &a_{1n} \\
            \vdots&\vdots  &  &\vdots \\
            a_{m1} &a_{m2}&\cdots &a_{mn}
            \end{bmatrix}
            \end{equation} 
            También  podemos escribir los $x_1,\ldots,x_n$ e $y_1,\ldots,y_n$ como \textit{matriz columna}
            \begin{equation}\label{matriz-columna}
            X = \begin{bmatrix}
            x_1 \\
            \vdots \\
            x_{n}
            \end{bmatrix}, \qquad
            Y = \begin{bmatrix}
            y_1 \\
            \vdots \\
            y_{m}
            \end{bmatrix}
            \end{equation}
            
            
            \begin{definicion} Sea $\K$ cuerpo. Una \textit{matriz}\index{matriz} $m \times  n$ o de \textit{orden $m \times  n$} es un arreglo rectangular de elementos de $\K$ con $m$ filas y $n$ columnas. A cada elemento de la matriz la llamamos \textit{entrada} o \textit{coeficiente}. Si $A$ es una matriz $m \times  n$, denotamos $[A]_{ij}$ la entrada que se ubica en la fila $i$ y la columna $j$. Al conjunto de matrices de orden $m \times  n$ con entradas en $\K$ lo denotamos $\K^{m \times n}$ o también $M_{m\times n}(\K)$, o simplemente $M_{m\times n}$ si $\K$  está sobreentendido. 
            \end{definicion}
            
            \begin{observacion*}
                Más formalmente, podemos ver una matriz como un elemento del producto cartesiano $(\K^n)^m$, es decir como $m$-tuplas donde en cada coordenada hay una $n$-tupla. Esta es la forma usual de describir una matriz en los lenguajes de programación modernos. 
            \end{observacion*}
            
            \begin{ejemplo*}
                El siguiente es un ejemplo de una matriz $2 \times 3$:
                \begin{equation*}
                A = \begin{bmatrix}
                2& -1& 4 \\
                -3 &0&1
                \end{bmatrix}
                \end{equation*} .
            \end{ejemplo*}
            
            Usualmente escribiremos a una matriz $m \times  n$   con entradas  $[A]_{ij} = a_{ij}$ como en \eqref{matriz}. A esta matriz también la podemos denotar como $A = [a_{ij}]$. Dos matrices $A = [a_{ij}]$ y $B = [b_{ij}]$, de orden $m \times n$, son iguales si $a_{ij} = b_{ij}$ para todo $i = 1,\ldots,m$  y $j = 1,\ldots,n$. Es decir, dos matrices son iguales si los elementos que ocupan la misma posición en ambas matrices coinciden.
            
            Como hicimos al comienzo de la sección, a un sistema de $m$ ecuaciones con $n$ incógnitas le asignaremos una matriz $m \times  n$  lo cual nos permitirá trabajar en forma más cómoda y, como veremos en la próxima sección,  podremos resolver los sistemas de ecuaciones lineales en forma algorítmica, realizando operaciones elementales por fila en las matrices correspondientes. 
            
            Sean
            \begin{equation*}
                A = \begin{bmatrix}
                    a_{11}& a_{12}& \cdots &a_{1n} \\
                    \vdots&\vdots  &  &\vdots \\
                    a_{m1} &a_{m2}&\cdots &a_{mn}
                    \end{bmatrix}, \quad 
                    X = \begin{bmatrix}
                    x_1 \\ \vdots \\ x_n
                    \end{bmatrix}\quad \text{ e } \quad
                    Y = \begin{bmatrix}
                    y_1 \\ \vdots \\ y_m
                    \end{bmatrix}. 
            \end{equation*}
                
            Entonces, podemos escribir el sistema de ecuaciones \eqref{sist-eq-hom} como
        
            \begin{equation}\label{sist-eq-homm-2}
                A = \begin{bmatrix}
                a_{11}& a_{12}& \cdots &a_{1n} \\
                \vdots&\vdots  &  &\vdots \\
                a_{m1} &a_{m2}&\cdots &a_{mn}
                \end{bmatrix}
                \begin{bmatrix}
                x_1  \\ \vdots \\  x_n
                \end{bmatrix} = 
                \begin{bmatrix}
                y_1 \\ \vdots \\ y_m
                \end{bmatrix}.
            \end{equation}
            
             En forma resumida:
            \begin{equation}\label{sis-eq-hom-2}
            AX = Y.
            \end{equation}
            Más adelante, veremos que esta notación tiene un sentido algebraico (el término de la izquierda es un ``producto de matrices'').
            
            \begin{subsection}{Operaciones elementales por fila}
                Sea $A = [a_{ij}]$ una matriz $m \times  n$,  entonces la fila $i$ es 
                $$
                \begin{bmatrix} a_{i1}& a_{i2}& \cdots &a_{in} 	\end{bmatrix},
                $$
                y la denotamos $F_i(A)$ o simplemente $F_i$ si $A$ está sobreentendido. Si $c\in \K$,  entonces 
                $$
                cF_i = \begin{bmatrix} ca_{i1}& ca_{i2}& \cdots &ca_{in} 	\end{bmatrix}
                $$
                y
                $$
                F_r + F_s = \begin{bmatrix} a_{r1}+a_{s1}& a_{i2}+a_{s2}& \cdots &a_{in}+a_{sn} 	\end{bmatrix}.
                $$ 
                Diremos que la fila $i$ es nula si 
                $$
                F_i = \begin{bmatrix} 0& 0& \cdots &0 	\end{bmatrix},
                $$
                
                \begin{definicion}
                    Sea $A = [a_{ij}]$ una matriz $m \times  n$, diremos que $e$ es una  \textit{operación elemental por fila}\index{operación elemental por fila} si aplicada a la matriz $A$ se obtiene  $e(A)$ de la siguiente manera:
                    \begin{enumelem}
                        \item\label{elem-1} multiplicando la fila $r$ por una constante $c\not=0$, o
                        \item\label{elem-2} cambiando la fila $F_r$ por $F_r + tF_s$ con $r\not=s$, para algún $t \in \K$, o
                        \item\label{elem-3} permutando la fila $r$ por la fila $s$.   
                    \end{enumelem}
                    \ref{elem-1}, \ref{elem-2} y \ref{elem-1} son las tres operaciones elementales por fila. Veamos más precisamente  el efecto que tienen ellas sobre matrices genéricas. Sea 
                    \begin{equation*}
                    A = \begin{bmatrix} 
                    F_1 \\  \vdots \\	F_m
                    \end{bmatrix},
                    \end{equation*} entonces 
                    \begin{enumelem}
                        \item si multiplicamos la fila $r$ por $c \not=0$, 
                        $$ e(A) = \begin{bmatrix} 
                        F_1 \\ 	\vdots \\ cF_r \\ \vdots \\	F_m
                        \end{bmatrix} $$ con $c \not=0$, o
                        \item si $r\not=s$, multiplicamos la fila $s$ por  $t \in \K$ y la sumamos a la fila $r$, 
                        $$ e(A)= \begin{bmatrix} 
                        F_1 \\  \vdots \\ F_r + t F_s\\ \vdots \\	F_m
                        \end{bmatrix}.$$
                        \item La última operación elemental es  permutar la fila $r$ por la fila $s$:
                        $$
                        A= \begin{bmatrix} 
                        F_1 \\ 	\vdots \\ F_r \\ \vdots \\ F_s\\ \vdots \\	F_m
                        \end{bmatrix} \quad \Rightarrow \quad
                        e(A)= \begin{bmatrix} 
                        F_1 \\ 	\vdots \\ F_s \\ \vdots \\ F_r\\ \vdots \\	F_m
                        \end{bmatrix}.$$
                    \end{enumelem}
                \end{definicion} 

                Podemos describir en forma más compacta una operación elemental por fila de la matriz $A=[a_{ij}]$.
                \begin{enumelem}
                    \item Multiplicar la fila $r$ por $c \not=0$
                    $$
                    e(A)_{ij} = \left\{ \begin{matrix}
                    a_{ij}& \quad &\text{si $i\not=r$} \\
                    ca_{ij}& \quad &\text{si $i=r$}
                    \end{matrix}\right.
                    $$
                    \item Si $r\not=s$, multiplicar la fila $s$ por $t \in \K$ y sumarla a la fila $r$
                    $$
                    e(A)_{ij} = \left\{ \begin{matrix}
                    a_{ij}& \quad &\text{si $i\not=r$} \\
                    a_{rj} + t a_{sj}& \quad &\text{si $i=r$}
                    \end{matrix}\right.
                    $$
                    con $t \in \K$.
                    \item Permutar la fila $r$ por la fila $s$
                    $$
                    e(A)_{ij} = \left\{ \begin{matrix}
                    a_{ij}& \quad &\text{si $i\not=r,s$}
                    \\ a_{sj}& \quad &\text{si $i=r$}
                    \\ a_{rj}& \quad &\text{si $i=s$}
                    \end{matrix}\right.
                    $$
                \end{enumelem} 
                
                \vskip .5cm 
                \begin{ejemplo*}
                    Sea 
                    $$
                    A = 
                    \begin{bmatrix}
                    2&1\\-1&0\\4&-5
                    \end{bmatrix}.
                    $$
                    Ejemplificaremos las operaciones elementales
                    \begin{enumelem}
                        \item Multipliquemos la fila $2$ por $-2$, obtenemos
                        $$
                        e(A) = 
                        \begin{bmatrix}
                        2&1\\2&0\\4&-5
                        \end{bmatrix}.
                        $$
                        \item Sumemos a la fila $3$ dos veces la fila $1$,
                        $$
                        e(A) = 
                        \begin{bmatrix}
                        2&1\\-1&0\\8&-3
                        \end{bmatrix}.
                        $$
                        \item Permutemos la fila $2$ con la fila $3$.
                        $$
                        e(A) = 
                        \begin{bmatrix}
                        2&1\\4&-5\\-1&0
                        \end{bmatrix}.
                        $$
                    \end{enumelem}
                \end{ejemplo*}
                
                Una característica importante de las operaciones elementales es que cada una tiene como ``inversa'' otra operación elemental. 
                
                \begin{teorema}\label{op-elem}
                    A cada operación elemental por fila $e$ le corresponde otra operación elemental $e^\prime$ (del mismo tipo que $e$) tal que $e^\prime(e(A)) = A$ y $e(e^\prime(A)) = A$. En otras palabras, la operación inversa de una operación elemental es otra operación elemental del mismo tipo.  
                \end{teorema}
                \begin{proof} \
                    \begin{enumelem}
                        \item La operación inversa de multiplicar la fila $r$ por $c\not=0$ es multiplicar la misma fila por $1/r$.
                        \item La operación inversa de multiplicar la fila $s$ por  $t \in \K$ y sumarla a la fila $r$ es multiplicar  la fila $s$ por  $-t \in \K$ y sumarla a la fila $r$.
                        \item La operación inversa de permutar la fila $r$ por la fila $s$ es la misma operación.
                    \end{enumelem}
                \end{proof}
                
                \begin{definicion} 
                    Sean $A$ y $B$ dos matrices $m \times n$. Diremos que $B$ es \textit{equivalente por filas}\index{matrices equivalentes por filas} a $A$, si $B$ se puede obtener de $A$ por un número finito de operaciones elementales por fila. 
                \end{definicion}
            

                \begin{observacion*} Denotamos $A \sim B$, si $B$ es equivalente a $A$ por filas. Entonces esta relación es una \textit{relación de equivalencia}\index{relación de equivalencia}, es decir es reflexiva, simétrica y transitiva. En  nuestro caso, sean $A$, $B$ y $C$ matrices $m \times n$, entonces ``$\sim$'' cumple: 
                    \begin{enumerate}
                        \item  $A \sim A$ (reflexiva), 
                        \item $A \sim B$, entonces $B \sim A$ (simétrica), y
                        \item si $A \sim B$ y $B \sim C$, entonces $A \sim C$.   
                    \end{enumerate}
                    Claramente ``$\sim$'' es reflexiva (admitamos que no hacer nada es una equivalencia por filas). 
                    
                    Si podemos obtener $B$ de $A$ por operaciones elementales por fila, entonces, 
                    $$
                    B = e_k(e_{k-1}(\cdots(e_1(A)))\cdots),
                    $$
                    con $e_1,\ldots,e_k$ operaciones elementales por fila. Por el teorema \ref{op-elem},  tenemos $e'_1,\ldots,e'_{k-1},e'_k$ operaciones elementales inversas de  $e_1,\ldots,e_{k-1},e_k$, respectivamente. Luego, 
                    $$
                    A = e'_1(e'_{2}(\cdots(e'_k(B)))\cdots).
                    $$
                    Es decir, podemos  obtener $A$ de $B$ por operaciones elementales por fila, luego ``$\sim$'' es simétrica. Observar que para obtener $A$ a partir de $B$ tenemos que hacer las operaciones inversas en orden inverso. 
                    
                    Finalmente,   si podemos obtener $B$ de $A$ por operaciones elementales por fila y  podemos obtener $C$ de $B$ por operaciones elementales por fila, entonces podemos obtener $C$ de $A$ por operaciones elementales por fila (haciendo las primeras operaciones y luego las otras).
                \end{observacion*}
                
                \begin{ejemplo*}
                    Veamos que la matriz 
                    \begin{equation*}
                    A= 	\begin{bmatrix}
                    3 & 9 & 6 \\ 4&8&4 \\ 0&2&2
                    \end{bmatrix}
                    \end{equation*}
                    es equivalente por fila a la matriz
                    \begin{equation*}
                    B = \begin{bmatrix}
                    1&0&-1 \\ 0&0&0\\  0&-1&-1
                    \end{bmatrix}.
                    \end{equation*}
                        \end{ejemplo*}
                    
                    \begin{proof}[Solución]				
                    Hasta ahora, no hemos aprendido ningún algoritmo o método que nos lleve una matriz a otra por operaciones elementales por fila, pero no es difícil, en este caso, encontrar una forma de llevar la matriz $A$ a la matriz $B$:
                    \begin{multline*}
                    \begin{bmatrix}
                    3 & 9 & 6 \\ 4&8&4 \\ 0&2&2
                    \end{bmatrix} \stackrel{F_1/3}{\longrightarrow}
                    \begin{bmatrix}
                    1 & 3 & 2 \\ 4&8&4 \\ 0&2&2
                    \end{bmatrix} \stackrel{F_2 -4F_1}{\longrightarrow}
                    \begin{bmatrix}
                    1 & 3 & 2 \\ 0&-4&-4 \\ 0&2&2
                    \end{bmatrix}                    
                    \stackrel{F_2/4}{\longrightarrow}  \begin{bmatrix}
                    1 & 3 & 2 \\ 0&-1&-1 \\ 0&2&2 
                    \end{bmatrix} \\
                    \stackrel{F_1 + 3F_2}{\longrightarrow} 
                    \begin{bmatrix}
                    1 & 0& -1 \\ 0&-1&-1 \\ 0&2&2 
                    \end{bmatrix} \stackrel{F_3 + 2F_2}{\longrightarrow} 
                    \begin{bmatrix}
                    1 & 0& -1 \\ 0&-1&-1 \\ 0&0&0 
                    \end{bmatrix} \stackrel{F_3\leftrightarrow F_2}{\longrightarrow} 
                    \begin{bmatrix}
                    1 & 0& -1 \\ 0&0&0\\  0&-1&-1 
                    \end{bmatrix}.
                    \end{multline*}
                    
                    Comprobamos fácilmente la propiedad reflexiva, pues podemos llegar de la matriz $B$ a la matriz $A$ haciendo, sucesivamente, la operaciones inversas en orden inverso:
                    \begin{multline*}
                    \begin{bmatrix}1 & 0& -1 \\ 0&0&0\\  0&-1&-1 \end{bmatrix}
                    \stackrel{F_3\leftrightarrow F_2}{\longrightarrow} 
                    \begin{bmatrix}1 & 0& -1 \\ 0&-1&-1 \\ 0&0&0 \end{bmatrix}
                    \stackrel{F_3 - 2F_2}{\longrightarrow} 
                    \begin{bmatrix}1 & 0& -1 \\ 0&-1&-1 \\ 0&2&2 \end{bmatrix} 
                    \\ \stackrel{F_1 - 3F_2}{\longrightarrow}
                    \begin{bmatrix}1 & 3 & 2 \\ 0&-1&-1 \\ 0&2&2 \end{bmatrix}
                    \stackrel{4F_2}{\longrightarrow} 
                    \begin{bmatrix}1 & 3 & 2 \\ 0&-4&-4 \\ 0&2&2 \end{bmatrix} 
                    \stackrel{F_2 +4F_1}{\longrightarrow} 
                    \begin{bmatrix} 1 & 3 & 2 \\ 4&8&4 \\ 0&2&2\end{bmatrix} 
                    \stackrel{3F_1}{\longrightarrow} 
                    \begin{bmatrix} 3 & 9 & 6 \\ 4&8&4 \\ 0&2&2 \end{bmatrix}.
                    \end{multline*}
                \end{proof}

                \begin{definicion}
                    Consideremos un sistema como en \eqref{sist-eq-hom} y sea  $A$ la matriz correspondiente al sistema. La \textit{matriz  ampliada}\index{sistema de ecuaciones lineales!matriz  ampliada} o  \textit{matriz  aumentada}\index{sistema de ecuaciones lineales!matriz  aumentada} del sistema es 
                    \begin{equation}\label{mtrx-ampliada}
                    A' = \left[\begin{array}{@{}*{3}{c}|c@{}}
                    a_{11} & \cdots & a_{1n} &  y_1 \\
                    a_{21} & \cdots & a_{2n} &  y_2 \\
                    \vdots &  & \vdots  &  \vdots  \\
                    a_{m1} & \cdots & a_{mn} &  y_m 
                    \end{array}\right]
                    \end{equation}
                    que también podemos denotar
                    \begin{equation*}
                    A' = [A | Y].
                    \end{equation*}
                \end{definicion}
                
                La matriz ampliada $[A | Y]$ es otra forma de representar el sistema de ecuaciones lineales $AX=Y$, con la ventaja de que en la matriz ampliada solo se escriben los coeficientes del sistema y no las variables. Es decir,  es una notación más compacta. 
                
                \begin{teorema}\label{th-equiv-op-elem} Sea $[A | Y]$ la matriz ampliada de un sistema no homogéneo y sea $[B | Z]$ una matriz que se obtiene a partir de $[A | Y]$ por medio de operaciones elementales. Entonces, los sistemas correspondientes a $[A | Y]$ y  $[B | Z]$ tienen las mismas soluciones. 
            \end{teorema}
            \begin{proof}
                 Supongamos que $[B | Z]$ se obtiene por una operación elemental por fila a partir de $[A | Y]$,  entonces las ecuaciones de $[B | Z]$ son combinaciones lineales de las ecuaciones de $[A | Y]$. Como toda operación elemental por fila tiene inversa, podemos obtener $[A | Y]$ a partir de $[B | Z]$ y por lo tanto las ecuaciones de $[A | Y]$ son combinaciones lineales de las ecuaciones de $[B | Z]$. Es decir $[A | Y]$ y $[B | Z]$ determinan sistemas de ecuaciones lineales equivalentes y por lo tanto tiene las mismas soluciones (teorema \ref{sistemas-equiv}).
                 
                 En el caso que $[B | Z]$ se obtenga a partir $[A | Y]$ haciendo varias operaciones elementales,  se aplica el razonamiento de arriba las veces que sea necesario. 
            \end{proof}
                
                \begin{ejemplo*}\label{ejemplo2.11}
                    Resolvamos el siguiente sistema:
                    \begin{align}\label{sist-eq-01}
                    \begin{split}
                    2x_1 - x_2 + x_3 + 2x_4 &= 2 \\
                    x_1 - 4x_2 -x_4 &=1 \\
                    2x_1 +6x_2 -x_3 +3x_4 &= 0,  
                    \end{split}
                    \end{align}
                    para  $x_i \in \R$ ($1 \le i \le 4$). 
                
                    
                    La matriz ampliada  correspondiente a este sistema de ecuaciones es 
                    $$
                    \left[\begin{array}{@{}*{4}{c}|c@{}} 
                     2& -1&1& 2&2 \\ 1&-4 &0&-1&1 \\ 2&6&-1&3&0 \end{array}\right].
                    $$
                    Encontraremos una matriz que nos dará un sistema de ecuaciones equivalente, pero con soluciones mucho más evidentes:
                    \begin{multline*}
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  2& -1&1& 2&2 \\ 1&-4 &0&-1&1 \\ 2&6&-1&3&0 \end{array}\right]
                    \stackrel{F_1\leftrightarrow F_2}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 2& -1&1& 2&2 \\ 2&6&-1&3&0 \end{array}\right]
                    \\
                    \stackrel{F_2-2 F_1}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 0& 7&1& 4&0 \\ 2&6&-1&3&0 \end{array}\right]
                    \stackrel{F_3-2 F_1}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 0& 7&1& 4&0 \\ 0&14&-1&5&-2 \end{array}\right] 
                    \\
                    \stackrel{F_3-2 F_2}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 0& 7&1& 4&0 \\ 0&0&-3&-3&-2 \end{array}\right]  
                    \stackrel{F_3/(-3)}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 0& 7&1& 4&0 \\ 0&0&1&1&\frac{2}{3} \end{array}\right]
                    \\
                    \stackrel{F_2- F_3}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1 \\ 0& 7&0& 3&-\frac{2}{3} \\ 0&0&1&1&\frac{2}{3} \end{array}\right]
                    \stackrel{F_2/7}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}}  1&-4 &0&-1&1\\ 0& 1&0& \frac37&-\frac{2}{21}\\ 0&0&1&1&\frac{2}{3}\end{array}\right]
                    \\
                    \stackrel{F_1 +4F_2}{\longrightarrow} 
                    \left[\begin{array}{@{}*{4}{c}|c@{}} 1&0&0&\frac{5}{7}&\frac{13}{21}\\0&1&0&\frac37&-\frac{2}{21} \\ 0&0&1&1&\frac{2}{3}\end{array}\right].
                    \end{multline*}
                    Volvamos a las ecuaciones: el nuevo sistema de ecuaciones, equivalente al original, es
                    \begin{align*}
                    x_1 +\frac{5}{7}x_4 &= \frac{13}{21} \\
                    x_2 + \frac{3}{7}x_4 &=-\frac{2}{21} \\
                    x_3 +x_4 &= \frac{2}{3}, 
                    \end{align*}
                    luego 
                    \begin{align*}
                    x_1  &=-\frac{5}{7}x_4 + \frac{13}{21}\\
                    x_2  &=- \frac{3}{7}x_4 -\frac{2}{21} \\
                    x_3  &= -x_4+\frac{2}{3}. 
                    \end{align*}
                    Por lo tanto, el conjunto de soluciones del sistema de ecuaciones \eqref{sist-eq-01} es
                    $$
                    \left\{(-\frac{5}{7}t+ \frac{13}{21},\,- \frac{3}{7}t-\frac{2}{21},\, -t+\frac{2}{3},\,t): t \in \R \right\}.
                    $$
                    Luego, el sistema tiene infinitas soluciones parametrizadas por una variable $t \in \R$.
                \end{ejemplo*}
                
                
                \begin{ejemplo*}
                    Consideremos ahora el siguiente sistema sobre los números complejos:
                    \begin{align}\label{sist-eq-03}
                    \begin{split}
                    2x_1 +i x_2 &= 0 \\
                    -ix_1 +3x_2  &=0 \\
                    x_1 +2x_2  &= 0.
                    \end{split}
                    \end{align}
                    Al ser un sistema homogéneo $x_1=x_2 = 0$ es solución. Veamos si hay otras soluciones: 
                    \begin{multline*}
                    \begin{bmatrix} 2&i \\ -i&3 \\ 1&2 \end{bmatrix}
                    \stackrel{F_1\leftrightarrow F_3}{\longrightarrow} 
                    \begin{bmatrix} 1&2 \\ -i&3 \\ 2&i \end{bmatrix}
                    \stackrel{F_2+iF_1}{\longrightarrow} 
                    \begin{bmatrix} 1&2 \\ 0&3+2i \\ 2&i \end{bmatrix}
                    \stackrel{F_3-2F_1}{\longrightarrow} 
                    \begin{bmatrix} 1&2 \\ 0&3+2i \\ 0&-4+i \end{bmatrix}
                    \\
                    \stackrel{F_2/(3+2i)}{\longrightarrow} 
                    \begin{bmatrix} 1&2 \\ 0&1 \\ 0&-4+i \end{bmatrix}
                    \stackrel{F_3-(-4+i)F_2}{\longrightarrow} 
                    \begin{bmatrix} 1&2 \\ 0&1 \\ 0&0 \end{bmatrix}
                    \stackrel{F_1-2F_2}{\longrightarrow} 
                    \begin{bmatrix} 1&0 \\ 0&1 \\ 0&0 \end{bmatrix}.
                    \end{multline*}
                    Luego  el sistema \eqref{sist-eq-03} es equivalente al sistema  $x_1=x_2 = 0$, que resulta ser la única solución.
                \end{ejemplo*}
            \end{subsection} 
        
            \subsection*{$\S$ Ejercicios}
            \begin{enumex}
                \item Mostrar, en los siguientes casos, que la matriz $A$ es equivalente por filas a la  matriz $B$.
                \begin{enumex}
                    \item 
                    $A = \begin{bmatrix}1& -5& 8\\1& -2& 1\\2& -1& -5\end{bmatrix}$, \quad 
                    $B= \begin{bmatrix}0& 2& 0\\1& 0& 0\\0& 0& 1\end{bmatrix}$.
                    \item 
                    $A = \begin{bmatrix}-1& -2& 5& 4\\3& 6& 0& 1\\4& 8& -6& -3\\-1& -2& 2& 1\end{bmatrix}$, \quad 
                    $B= \begin{bmatrix}1& 2& 0& 0\\0& 0& 0& 0\\0& 0& 0& 1\\0& 0& 1& 0\end{bmatrix}$.
                \end{enumex}
            \end{enumex}


        
        \end{section}
    
    
    
            \begin{section}{Método de eliminación de Gauss }\label{seccion-metodo-de-gauss} Ahora avanzaremos en una forma sistemática para hallar todas las soluciones de un sistema de ecuaciones.
    
            
            \begin{subsection}{Matrices reducidas por filas} 
                
                \begin{definicion}
                    Una matriz $A$ de $m \times n$ se llama \textit{reducida por filas}\index{matriz!reducida por filas} o \textit{MRF}\index{MRF} si 
                    \begin{enumerate}[label=\textit{\alph*)}, ref=\textit{\alph*)}]
                        \item la primera entrada no nula de una fila de $A$ es $1$. Este $1$ es llamado \textit{$1$ principal}\index{$1$ principal de una MRF}.
                        \item Cada columna de $A$ que contiene un  $1$ principal tiene todos los otros elementos iguales a $0$. 
                    \end{enumerate} 
                Una matriz $A$ de $m \times n$ es \textit{escalón reducida por fila}\index{matriz!escalón reducida por fila} o \textit{MERF}\index{MERF} si,  es  MRF y
                \begin{enumerate}[resume*]
                    \item todas las filas cuyas entradas son todas iguales a cero están al final de la matriz, y
                    \item en dos filas consecutivas no nulas el $1$ principal de la fila inferior está más a la derecha que el $1$ principal de la fila superior. 
                \end{enumerate}
                
                \end{definicion} 
                
                \begin{ejemplo*} Las siguientes matrices son MRF, pero  no MERF:
                    \begin{equation*}
                    \begin{bmatrix}1 & 0& -1 \\  0&0&0\\ 0&1&3 \end{bmatrix}\;  \text{no cumple (c),} \qquad
                    \begin{bmatrix} 0&1&3 \\1 & 0& -1\\  0&0&0 \end{bmatrix}\; \text{no cumple (d).} \qquad
                    \end{equation*}
                    Las siguientes matrices, no son MRF:
                    \begin{equation*}
                    \begin{bmatrix}1 & 0& 1 \\ 0&2&3\\  0&0&0 \end{bmatrix}\; \text{no cumple (a),} \qquad
                    \begin{bmatrix}1 & 0& -1 \\ 0&1&3\\  0&0&1 \end{bmatrix}\; \text{no cumple (b)}. 
                    \end{equation*}
                    Las siguientes son MERF:
                    \begin{equation*}
                    \begin{bmatrix} 1&0&0&2 \\ 0&1&0&5 \\ 0&0&1&4\end{bmatrix}, \qquad
                    \begin{bmatrix} 1&0&0 \\ 0&1&0 \\ 0&0&0\end{bmatrix}, \qquad
                    \begin{bmatrix} 0&0 \\ 0&0\end{bmatrix}, \qquad
                    \begin{bmatrix} 0&1&2&0&1 \\ 0&0&0&1&0 \\ 0&0&0&0&0 \\ 0&0&0&0&0\end{bmatrix}.
                    \end{equation*}
                \end{ejemplo*}
                
                
                En general una matriz  MERF tiene la forma
                \begin{equation}\label{merf-general}
                \begin{bmatrix}
                0& \cdots & 1 & *&0&* &* &0& * &*\\
                0& \cdots &0 &\cdots & 1& *  & * & 0& * &*\\
                \vdots&  &\vdots &  &\vdots && &\vdots& &\vdots\\
                0& \cdots &0& \cdots & 0&\cdots &\cdots & 1& * &* \\
                0& \cdots &0& \cdots & 0&\cdots &\cdots & 0& \cdots &0 \\
                \vdots&  &\vdots &  &\vdots && &\vdots& &\vdots\\
                0& \cdots &0& \cdots & 0&\cdots &\cdots & 0& \cdots &0
                \end{bmatrix}
                \end{equation}
                
                \begin{definicion}
                    Sea $\Id_n$ la matriz  $n \times n$ definida 
                    \begin{equation*}
                    [\Id_n]_{ij} = \left\{ \begin{matrix}
                    1 && \text{si $i=j$,}\\
                    0 && \text{si $i\not=j$,}
                    \end{matrix}\right.\qquad \text{ o bien }\qquad \Id_n =
                    \begin{bmatrix}
                    1 & 0 & \cdots & 0 \\
                    0 & 1 & \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & 1
                    \end{bmatrix}
                    \end{equation*}
                    (la matriz cuadrada con $1$'s en la diagonal y $0$'s en las otras entradas). Llamaremos a $\Id_n$ la \textit{matriz identidad $n \times n$}\index{matriz!identidad $n \times n$}.
                \end{definicion}
                
                Observar que $\Id_n$ es una matriz escalón reducida por fila.
                
                \begin{teorema}\label{th-merf}
                    Toda matriz $m \times n$ sobre $\K$ es equivalente por fila a una matriz escalón reducida por fila.
                \end{teorema}
                \begin{proof}[Demostración (*)]
                    Sea $A = [a_{ij}]$ una matriz $m \times n$. Trabajaremos fila por fila, de la primera a la última, de tal forma de ir encontrando matrices equivalentes por fila en cada paso, con ciertas características que ya detallaremos. Cuando terminemos llegaremos a una MRF.  
                    
                    Si la primera fila es nula pasamos a la segunda fila. Si la primera fila no es nula sea $a_{1k}$ la primera entrada no nula, es decir
                    \begin{equation*}
                    A = \begin{bmatrix}
                    0 & \cdots & 0 & a_{1k} & \cdots & a_{1n} \\
                    a_{21}& \cdots & a_{2,k-1} & a_{2k} & \cdots & a_{2n} \\
                    \vdots&  &  &  &  & \vdots \\
                    a_{m1}& \cdots & a_{m,k-1} & a_{mk} & \cdots & a_{mn} \\
                    \end{bmatrix}.
                    \end{equation*} 
                    Esta matriz es equivalente por fila a $A_1$ donde $A_1$ se obtiene dividiendo la fila $1$ por $a_{1k}$. Luego 
                    \begin{equation*}
                    A_1 = \begin{bmatrix}
                    0 & \cdots & 0 & 1 & \cdots & a_{1n} \\
                    a_{21}& \cdots & a_{2,k-1} & a_{2k} & \cdots & a_{2n} \\
                    \vdots&  &  &  &  & \vdots \\
                    a_{m1}& \cdots & a_{m,k-1} & a_{mk} & \cdots & a_{mn} \\
                    \end{bmatrix}
                    \end{equation*}
                    (donde los nuevos $a_{1j}$ son  los originales divididos por $a_{1k}$).  
                    
                    Haciendo $m-1$ equivalencias por fila (reemplazamos $F_i$ por $F_i - a_{ik}F_1$) podemos hacer nulas todas las entradas debajo del  $1$ principal y obtener la matriz equivalente por fila
                    \begin{equation*}
                    A_2 = \begin{bmatrix}
                    0 & \cdots & 0 & 1 & \cdots & a_{1n} \\
                    a_{21}& \cdots & a_{2,k-1} & 0 & \cdots & a_{2n} \\
                    \vdots&  &  &  &  & \vdots \\
                    a_{m1}& \cdots & a_{m,k-1} &0 & \cdots & a_{mn} \\
                    \end{bmatrix}
                    \end{equation*}
                    (obviamente los nuevos $a_{ij}$ están transformados por las equivalencias).
                    
                    El mismo procedimiento que hicimos arriba lo podemos hacer en la fila $2$,  de tal forma que la fila $2$ es cero u obtenemos otro $1$ principal y todas las demás entradas de la columna donde se encuentra el $1$ principal son nulas. 
                    
                    Repitiendo este procedimiento en todas las filas hasta la última, obtenemos que cada fila es, o bien $0$, o bien la primera entrada no nula es  $1$ y todas las entradas en la misma columna de este $1$ principal son nulas.   Esto, claramente, nos dice que hemos obtenido una matriz reducida por fila.  
                    
                 Finalmente, intercambiando filas podemos entonces obtener una matriz escalón reducida por fila.

                
                \end{proof}
                
                          
                \begin{ejemplo*} Ejemplifiquemos con la matriz que aparece en el ejemplo de la página \pageref{ejemplo2.11},  es decir con la matriz
                    $$
                    \begin{bmatrix} 2& -1&1& 2 \\ 1&-4 &0&-1 \\ 2&6&-1&3 \end{bmatrix}.
                    $$
                    Siguiendo estrictamente el algoritmo:
                    \begin{multline*}
                    \begin{bmatrix*}[r] 2& -1&1& 2 \\ 1&-4 &0&-1 \\ 2&6&-1&3 \end{bmatrix*}
                    \stackrel{F_1/2}{\longrightarrow} 
                    \begin{bmatrix*}[r] 1& -\frac12&\frac12& 1 \\ 1&-4 &0&-1 \\ 2&6&-1&3 \end{bmatrix*}
                    \underset{F_3-2F_1}{\stackrel{F_2- F_1}{\longrightarrow}} 
                    \begin{bmatrix*}[r] 1& -\frac12&\frac12& 1 \\ 0&-\frac72 &-\frac12&-2 \\ 0&7&-2&1 \end{bmatrix*}
                    \\
                    \stackrel{F_2/(-\frac72)}{\longrightarrow} 
                    \begin{bmatrix*}[r] 1& -\frac12&\frac12& 1 \\ 0&1 &\frac17&\frac47 \\ 0&7&-2&1 \end{bmatrix*}
                    \underset{F_3-7F_2}{\stackrel{F_1 +\frac12 F_2}{\longrightarrow}} 
                    \begin{bmatrix*}[r] 1& 0&\frac47& \frac97 \\ 0&1 &\frac17&\frac47 \\ 0&0&-3&-3 \end{bmatrix*}
                    \\
                    \stackrel{F_3/(-3)}{\longrightarrow} 
                    \begin{bmatrix*}[r] 1& 0&\frac47& \frac97 \\ 0&1 &\frac17&\frac47 \\ 0&0&1&1 \end{bmatrix*}
                    \underset{F_2-\frac17F_3}{\stackrel{F_1 -\frac47 F_3}{\longrightarrow}} 
                    \begin{bmatrix*}[r] 1& 0&0& \frac{5}7 \\ 0&1 &0&\frac37 \\ 0&0&1&1 \end{bmatrix*}.
                    \end{multline*}
                    Observemos que llegamos a la misma matriz que en el ejemplo mencionado, pese a que hicimos otras operaciones elementales.
                \end{ejemplo*}
                
            \end{subsection}
                
                

                \begin{subsection}{Método de eliminación de Gauss}\label{elim-gauss} Consideremos el siguiente sistema de $m$ ecuaciones lineales con $n$ incógnitas:
                    \begin{equation}\label{eq-sistema-no-homogeneo}
                    \begin{matrix}
                    a_{11}x_1& + &a_{12}x_2& + &\cdots& + &a_{1n}x_n &= &y_1\\
                    \vdots&  &\vdots& &&  &\vdots \\
                    a_{m1}x_1& + &a_{m2}x_2& + &\cdots& + &a_{mn}x_n &=&y_n
                    \end{matrix}
                    \end{equation}
                    
                    Planteado  matricialmente el sistema es $AX=Y$  y denotamos $[A|Y]$ la matriz ampliada del sistema. El  procedimiento que explicaremos a continuación nos permitirá obtener en forma algorítmica y sencilla las soluciones del sistema \eqref{eq-sistema-no-homogeneo}. 
                    
                    Lo primero que debemos hacer es utilizar el algoritmo de la demostración del teorema \ref{th-merf}  para obtener una MERF de $A$, pero aplicándolo a la matriz ampliada. Es decir:  

                \begin{comment}                    
                    \begin{enumerate}
                        \item \label{paso-0} Nos ubicamos en la primera fila de $[A|bY]$.
                        \item \label{paso-1} Si la fila de $A$ es $0$ y no es la última, pasar a la fila siguiente.
                        \item \label{paso-2} Si la fila de $A$  no es $0$, 
                        \begin{enumerate}
                            \item si el primera entrada no nula está en  la columna $k$ de $A$ y su valor es $c$, dividir la fila por $c$ (ahora la primera entrada no nula vale $1$),
                            \item con operaciones elementales del tipo $F_r+ tF_s$ hacer $0$  todas las entradas en la columna $k$ (menos la de la columna actual).    
                        \end{enumerate}
                        De esta forma obtenemos una nueva matriz ampliada,  que llamaremos, nuevamente, $[A|Y]$, y pasamos al siguiente paso. 
                        \item \label{paso-3} Si la fila es la última, pasar al \ref{paso-4}. Si la fila no es la última, pasar a la fila siguiente  e ir al paso \ref{paso-1}.  
                        \item \label{paso-4} Permutar las filas hasta obtener una MERF de $A$. 
                    \end{enumerate}
                \end{comment}

                \begin{enumerate}
                    \item \label{paso-0} Nos ubicamos en la primera fila de $[A|Y]$.
                    \item \label{paso-1}  Si la fila es la última, pasar al \ref{paso-4}. Si la fila no es la última, continuar con el procedimiento siguiente. 
                    \begin{enumerate}
                        \item \label{paso-1.1}  Si la fila de $A$ es $0$, pasamos a la siguiente fila y volvemos al comienzo del paso \ref{paso-1}.
                        \item \label{paso-1.2} Si la fila de $A$  no es $0$: 
                        \begin{enumerate}
                            \item[\textit{i)}] si la primera entrada no nula está en  la columna $k$ de $A$ y su valor es $c$, dividir la fila por $c$ (ahora la primera entrada no nula vale $1$),
                            \item[\textit{ii)}] con operaciones elementales del tipo $F_r+ tF_s$ hacer $0$  todas las entradas en la columna $k$ (menos la de la fila actual). 
                            \item[\textit{iii)}] Pasamos a la siguiente fila.
                        \end{enumerate}
                        De esta forma obtenemos una nueva matriz ampliada,  que llamaremos, nuevamente, $[A|Y]$ y ahora volvemos al comienzo del paso \ref{paso-1}. 
                    \end{enumerate}
                    \item \label{paso-4} Permutar las filas hasta obtener una MERF de $A$. 
                \end{enumerate}
 
                A partir del sistema de ecuaciones \eqref{eq-sistema-no-homogeneo}, mediante operaciones elementales de fila hemos obtenido  una matriz $[B|Z]$, donde $B$ es matriz escalón reducida por fila. Por el teorema \ref{th-equiv-op-elem} los sistemas de ecuaciones $AX=Y$ y $BX=Z$ tiene las mismas soluciones y el sistema de ecuaciones asociado a $[B|Z]$,  debido a que $B$  es MERF, es de fácil resolución.  
                
                El médoto o  algoritmo que hemos utilizado se denomina \textit{eliminación de Gauss} o \textit{eliminación de Gauss-Jordan} o \textit{eliminación gaussiana}. 

                \begin{comment}
                \begin{ejemplo*} Supongamos que queremos encontrar las soluciones del sistema $AX = 0$ donde $A$ es una matriz  $4 \times 5$ y que $A$ es equivalente por filas a la matriz MERF
                    \begin{equation*}
                    B=\begin{bmatrix} 1&0&0&2&-3 \\ 0&1&0&0&-5 \\ 0&0&1&-1&2 \\ 0&0&0&0&0\end{bmatrix}.
                    \end{equation*} 
                    Entonces el sistema de ecuaciones original, de 4 ecuaciones y 5 incógnitas,  es equivalente al sistema
                    \begin{equation*}
                    \begin{matrix*}[r]
                    x_1 +2x_4 -3x_5 &= 0 \\ x_2 -5x_5 &= 0 \\ x_3-x_4+2x_5 &= 0
                    \end{matrix*} 
                    \qquad \Rightarrow \qquad 
                    \begin{matrix*}[l]
                    x_1  &= -2x_4 +3x_5 \\ x_2  &= 5x_5 \\ x_3 &= x_4-2x_5
                    \end{matrix*}. 
                    \end{equation*}
                    Por  lo tanto el conjunto de soluciones del sistema es
                    \begin{equation*}
                    \{(-2s +3t,  5t,  s-2t, s, t): s,t \in \R\}
                    \end{equation*}
                \end{ejemplo*} 
            \end{comment}  
            
                \begin{ejemplo*} Resolvamos el sistema
                    \begin{align*}
                    x_1 -2x_2 + x_3  &= 1\\
                    2x_1 +x_2 + x_3  &= 2\\
                    5x_2 - x_3  &= 0.
                    \end{align*}
                    La matriz  ampliada  correspondiente a este sistema es
                    \begin{equation*}
                     \left[\begin{array}{@{}*{3}{r}|r@{}} 
                     1 & -2 & 1 &  1 \\ 2 & 1 & 1 &  2 \\ 0 & 5 & -1 &  0 
                    \end{array}\right]
                    \end{equation*}
                    apliquemos el método de Gauss:
                    \begin{multline*}
                    \left[\begin{array}{@{}*{3}{r}|r@{}}1 & -2 & 1 &  1 \\ 2 & 1 & 1 &  2 \\	0 & 5 & -1 &  0  \end{array}\right]
                    \stackrel{F_2 - 2F_1}{\longrightarrow} 
                    \left[\begin{array}{@{}*{3}{r}|r@{}}1 & -2 & 1 &  1 \\ 0 & 5 & -1 &  0 \\	0 & 5 & -1 &  0  \end{array}\right]
                    \stackrel{F_3-F_1}{\longrightarrow} 
                    \left[\begin{array}{@{}*{3}{r}|r@{}}1 & -2 & 1 &  1 \\ 0 & 5 & -1 &  0 \\	0 & 0 & 0 & 0  \end{array}\right]
                    \\
                    \stackrel{F_2/5}{\longrightarrow} 
                    \left[\begin{array}{@{}*{3}{r}|r@{}}1 & -2 & 1 &  1 \\ 0 & 1 & -1/5 &  0 \\	0 & 0 & 0 &  0  \end{array}\right]
                    \stackrel{F_1+2 F_2}{\longrightarrow} 
                    \left[\begin{array}{@{}*{3}{r}|r@{}}1 & 0 & 3/5 & 1 \\ 0 & 1 & -1/5 &  0 \\	0 & 0 & 0 &  0  \end{array}\right].
                    \end{multline*}	
                    Luego,  el sistema se reduce  a
                    \begin{align*}
                    x_1  + 3/5x_3  &= 1\\
                    x_2 -1/5 x_3  &= 0.
                    \end{align*}
                    Es decir, 
                    \begin{align*}
                    x_1    &= - 3/5x_3 + 1\\
                    x_2   &= 1/5 x_3.
                    \end{align*}
                    En consecuencia,  las soluciones de esta ecuación son
                    \begin{equation*}
                    \left\{(-\frac{3}5s + 1, \frac15 s, s ): s \in \K \right\}.
                    \end{equation*}
                \end{ejemplo*} 
                
                
                Veamos ahora formalmente cuales son en forma genérica las soluciones del sistema $BX=Z$. 
                
                Sea $r$ el número de filas no nulas de $B$ y $k_1,\ldots, k_r$ las columnas donde aparecen los primeros $1$'s en las primeras $r$ filas. Entonces, $k_1 < k_2 < \cdots< k_r$ y el sistema de ecuaciones asociado a $B$ es:
                \begin{equation}
                \begin{matrix}
                &x_{k_1}& + &\sum_{j \not= k_1,\ldots, k_r} b_{1j}\,x_j&= &z_1\\
                &x_{k_2}& + &\sum_{j \not= k_1,\ldots, k_r} b_{2j}\,x_j&= &z_2\\
                & \vdots& &  &\vdots \\
                &x_{k_r}& + &\sum_{j \not= k_1,\ldots, k_r} b_{rj}\,x_j&= &z_r\\
                &&  &0&= &z_{r+1}\\
                &&  &\vdots &\\
                &&  &0&= &z_{m}.\\
                \end{matrix}
                \end{equation}  
                y, por lo tanto, el sistema tiene solución si y solo si  $z_{r+1} = \cdots = z_m =0$ y en ese caso las soluciones son: 
                \begin{equation}
                \begin{matrix}\label{sist-eq-hom-merf0}
                x_{k_1} &= z_1-\sum_{j \not= k_1,\ldots, k_r} b_{1j}\,x_j\\
                x_{k_2} &= z_2-\sum_{j \not= k_1,\ldots, k_r} b_{2j}\,x_j\\
                \vdots& \vdots \\
                x_{k_r}  &= z_r-\textstyle\sum_{j \not= k_1,\ldots, k_r} b_{rj}\,x_j
                \end{matrix}.
                \end{equation} 
                Llamaremos a  $x_{k_1}, x_{k_2}, \ldots, x_{k_r}$ las \textit{variables principales}\index{sistema de ecuaciones lineales!variables principales} del sistema  y  las $n-r$ variables restantes son las \textit{variables libres}.\index{sistema de ecuaciones lineales!variables libres} Es claro entonces que variando de forma arbitraria todas las variables libres obtenemos todas las soluciones del sistema.
                
                 Las soluciones del sistema son, entonces,  los $(x_1,\ldots,x_n)\in \K^n$ tal que $x_{k_1},\ldots,x_{k_r}$ satisfacen las ecuaciones \eqref{sist-eq-hom-merf0}.
            
                \begin{teorema}\label{inf-sol-var-libres}
                    Sea $AX=Y$ un sistema de $m$ ecuaciones lineales y $n$ incógnitas con coeficientes en $\K$. Entonces
                    \begin{enumerate}
                        \item\label{sol-homogeneo} El sistema homogéneo $AX=0$ o bien tiene a $0$ como única solución,  o bien tiene infinitas soluciones. 
                        \item\label{sol-no-homogeneo} Si $Y \ne 0$,  entonces el sistema  o bien no tiene solución, o bien tiene una solución, o bien tiene infinitas soluciones. 
                    \end{enumerate} 
                \end{teorema}
                \begin{proof}
                    \ref{sol-homogeneo}  Un  sistema homogéneo siempre tiene a $X=0$ como solución, pues $A0 =0$, y  las soluciones son de la forma dada por la ecuación \eqref{sist-eq-hom-merf0}, donde los $z_i$ son $0$. Si  no hay varables libres, entonces $x_1=x_2= \cdots =x_n =0$ es la única solución. Si hay variables libres,  entonces hay infinitas soluciones (variando las variables libres).  
                    
                   \ref{sol-no-homogeneo} Si el  sistema tiene solución, las soluciones son de la forma dada por la ecuación \eqref{sist-eq-hom-merf0}. Si  no hay variables libres la solución es única ($x_1=z_1,\ldots,x_n =z_n$). Si hay variables libres,  entonces hay infinitas soluciones.   
                \end{proof}
                
                \begin{corolario}\label{inf-sol}
                    Sea $A$ matriz $n \times n$ con coeficientes en $\K$. Si $A$ es equivalente por filas a  $B$ una  MERF y $B$ tiene filas nulas, entonces
                    \begin{enumerate}
                        \item\label{sol-homogeneo-2} El sistema homogéneo $AX=0$ tiene  infinitas soluciones. 
                        \item\label{sol-no-homogeneo-2} Si $Y \ne 0$,  entonces el sistema  $AX =Y$ o bien no tiene solución, o bien tiene infinitas soluciones.
                    \end{enumerate} 
                \end{corolario}
                \begin{proof} Sea $r$  el número de filas no nulas de $B$, como $B$ tiene filas nulas,  entonces $r<n$ y  hay al menos una variable libre. Esto nos garantiza que de haber solución, hay infinitas soluciones. Por el teorema \ref{inf-sol-var-libres} se deduce el resultado. 
                \end{proof}
                
                \begin{corolario}\label{soluciones-m-menor-n}
                    Sea $A$ una matriz $m \times n$ con  $m < n$ e $Y$ matriz $m \times 1$ . Entonces, si el sistema de ecuaciones lineales $AX=Y$ tiene solución, tiene infinitas soluciones.
                \end{corolario}
                \begin{proof}
                   El hecho de que $m < n$  nos garantiza que hay variable libres. Luego en caso de habe solución, hay infinitas soluciones. 
                \end{proof}
                
                \begin{lema}\label{lem-mtrx-merf-id}
                    Sea $R$ una matriz $n \times n$ escalón reducida por fila tal que no tiene filas nulas. Entonces $R=\Id_n$. 
                \end{lema}
                \begin{proof}
                    Como  $R$ es reducida por fila y no tiene filas nulas, cada fila tiene  un $1$ en alguna entrada y en la columna donde está el $1$ todos las otras entradas son nulas, por  lo tanto hay $n$ $1$'s principales distribuidos en $n$ columnas. Concluyendo: hay un $1$ por columna y en esa columna todas las demás entradas son nulas. 
                    
                    Ahora bien como $R$ es una MERF, la primera fila contiene el $1$ que está más a la izquierda, que no puede estar en otra ubicación que no sea la primera (pues si no la primera columna sería nula). Con el mismo razonamiento vemos que en la segunda fila hay un $1$ en la columna $2$ y en general en la fila $k$-ésima hay un $1$ en la columna $k$. Luego $R=\Id_n$.
                \end{proof}			
                
                \begin{teorema}
                    Sea $A$ una matriz $n \times n$. Entonces, $A$ es equivalente por filas a la matriz $\Id_n$  si y sólo si el sistema $AX = Y$ tiene un única solución. 
                \end{teorema}
                \begin{proof}
                    ($\Rightarrow$) Como $A$ es equivalente por filas a la matriz $\Id_n$, las soluciones de $AX =Y$ son las mismas que las de $\Id_nX=Z$, para algún $Z$. Ahora bien,  en la fila $i$ de la matriz $\Id_n$ tenemos $[\Id_n]_{ii} =1$ y las otras entradas son cero, luego la ecuación correspondiente a esa fila es $x _i =0$, y esto ocurre en todas las filas, luego el sistema de ecuaciones es
                    \begin{align*}
                    x_1 &=z_1 \\ x_2 &= z_2 \\ \vdots \\ x_n &= z_n
                    \end{align*}
                    cuya única solución es la solución trivial.
                    
                    ($\Leftarrow$) Sea $R$ la matriz escalón reducida por filas asociada a $A$. Por hipótesis, $AX=Y$ tiene una sola solución y  por lo tanto $RX=Z$, para algún $Z$, tiene una sola solución. Luego, no hay variables libres, es decir hay $n$ filas no nulas en $R$, como $R$ tiene $n$ filas, lo anterior implica que $R$ no tiene filas nulas. Entonces, por el lema anterior, $R=\Id_n$.
                \end{proof}
                \end{subsection}

                \subsection*{$\S$ Ejercicios}
                \begin{enumex}
                    \item  Usar el método de eliminación de Gauss para resolver los siguientes sistemas.
                        \begin{enumex}
                            \begin{minipage}{0.4\textwidth}
                                \item \; $\begin{cases}
                                    x + y &= 2 \\
                                    x- y &= 0
                                \end{cases}$
                            \end{minipage}
                            \begin{minipage}{0.4\textwidth}
                                \item \; $\begin{cases}
                                    x - z &=4 \\
                                    2x + y &= 1
                                \end{cases}$ 
                            \end{minipage}
        
                            \begin{minipage}{0.4\textwidth}
                                \item \; $\begin{cases}
                                    3x -2y &= 2 \\
                                    6x +y  &= \displaystyle\frac12
                                \end{cases}$
                            \end{minipage}
                            \begin{minipage}{0.4\textwidth}
                               \item \; $\begin{cases}
                                    2x - y &= -1 \\
                                    x +3 y -z  &= 5 \\
                                    y+2z &= 5 
                                \end{cases}$
                            \end{minipage}

                            \item \; $\begin{cases}
                                2 y + z &= 0 \\
                                2x- y + z &= 0 \\
                                -2x -y &=0
                            \end{cases}$
                        \end{enumex}

                    \item 
                    Encontrar la MERF  correspondiente a cada una de las siguientes matrices. 
                        \begin{enumex}
                            \begin{minipage}{0.4\textwidth}
                                \item $\begin{bmatrix}
                                    2&1\\1&3
                                \end{bmatrix}$
                            \end{minipage}
                            \begin{minipage}{0.4\textwidth}
                                \item $\begin{bmatrix}
                                    1&3&1\\2&0&4\\-1&-3&-3
                                \end{bmatrix}$
                            \end{minipage}

                            \begin{minipage}{0.4\textwidth}
                                \item $\begin{bmatrix}
                                    1&0&3&1&2\\1&4&2&1&5\\3&4&8&1&2
                                \end{bmatrix}$
                            \end{minipage}
                            \begin{minipage}{0.4\textwidth}
                                \item $\begin{bmatrix}
                                    0&1&3&2\\0&0&5&6\\1&5&1&5
                                \end{bmatrix}$
                            \end{minipage}
                        \end{enumex}
                \end{enumex}
        \end{section}

    \end{chapter}
        