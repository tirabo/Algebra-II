% PDFLaTeX
\documentclass[a4paper,12pt,twoside,spanish,reqno]{amsbook}
%%%---------------------------------------------------
\usepackage[math]{kurier}

\usepackage{etex}
\usepackage{t1enc}
\usepackage{latexsym}
\usepackage[utf8]{inputenc}
\usepackage{verbatim}
\usepackage{multicol}
\usepackage{amsgen,amsmath,amstext,amsbsy,amsopn,amsfonts,amssymb}
\usepackage{amsthm}
\usepackage{calc}         % From LaTeX distribution
\usepackage{graphicx}     % From LaTeX distribution
\usepackage{ifthen}
\input{random.tex}   
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{matrix}
\usepackage{mathtools}
\usepackage{stackrel}
\usepackage{enumitem}
\usepackage{tkz-graph}

\usepackage{enumitem} 
\usepackage[compatibility=false]{caption} % para usar subcaption
\usepackage{subcaption} % para poner varias imagenes juntas
\usetikzlibrary{arrows.meta}
\usepackage{hyperref}
\hypersetup{ 
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\usepackage{hypcap}
\numberwithin{equation}{section}
% http://www.texnia.com/archive/enumitem.pdf (para las labels de los enumerate)
\renewcommand\labelitemi{$\circ$}
\setlist[enumerate, 1]{label={(\arabic*)}}
\setlist[enumerate, 2]{label=\emph{\alph*)}}


\newcommand{\rta}{\noindent\textsc{Solución: }} 

\newcommand{\img}{\operatorname{Im}}
\newcommand{\nuc}{\operatorname{Nu}}
\newcommand\im{\operatorname{Im}}
\renewcommand\nu{\operatorname{Nu}}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\renewcommand{\t}{{\operatorname{t}}}
\renewcommand{\sin}{{\,\operatorname{sen}}}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
\newcommand{\F}{\mathbb F}
\newcommand{\Z}{\mathbb Z}
\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}

%%% FORMATOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tolerance=10000
\renewcommand{\baselinestretch}{1.3}
\usepackage[a4paper, top=3cm, left=3cm, right=2cm, bottom=2.5cm]{geometry}
\usepackage{setspace}
%\setlength{\parindent}{0,7cm}% tamaño de sangria.
\setlength{\parskip}{0,4cm} % separación entre parrafos.
\renewcommand{\baselinestretch}{0.90}% separacion del interlineado
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\end{comment}
%%% FIN FORMATOS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
    \baselineskip=0.55truecm %original
    
    
    {\bf \begin{center} Práctico 3 \\ Álgebra  II -- Año 2024/1 \\ FAMAF \end{center}}

%\title{Pr\'actico 1}


\centerline{\textsc{\'Algebra de matrices}}
\subsection*{Ejercicios resueltos}

\begin{enumerate}[topsep=6pt,itemsep=.4cm]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item\label{ej} Sean
$$
A= \begin{bmatrix} 1&-2&0\\ 1&-2&1\\ 1&-2&-1\end{bmatrix},\quad
\quad B= \begin{bmatrix}1&1&2\\ -2&0&-1\\ 1&3&5 \end{bmatrix},
\quad\quad C=\begin{bmatrix}1&-1&1\\ 2&0&1\\ 3&0&1 \end{bmatrix}.
$$

Verificar que $A(BC)=(AB)C$, es decir que vale la asociatividad del producto.
\vskip .2cm
\noindent\textsc{Solución:}
\begin{equation*}
	BC =  \begin{bmatrix}1&1&2\\ -2&0&-1\\ 1&3&5 \end{bmatrix} \begin{bmatrix}1&-1&1\\ 2&0&1\\ 3&0&1 \end{bmatrix}=\begin{bmatrix}9 & -1 & 4 \\-5 & 2 & -3 \\22 & -1 & 9 \end{bmatrix}
\end{equation*}
\begin{equation*}
	A(BC) =\begin{bmatrix} 1&-2&0\\ 1&-2&1\\ 1&-2&-1\end{bmatrix}\begin{bmatrix}9 & -1 & 4 \\-5 & 2 & -3 \\22 & -1 & 9 \end{bmatrix} =
	\begin{bmatrix}19 & -5 & 10 \\41 & -6 & 19 \\-3 & -4 & 1\end{bmatrix} \tag{*}
\end{equation*}
\begin{equation*}
	AB = \begin{bmatrix} 1&-2&0\\ 1&-2&1\\ 1&-2&-1\end{bmatrix} \begin{bmatrix}1&1&2\\ -2&0&-1\\ 1&3&5 \end{bmatrix} =
	\begin{bmatrix}5 &1 &4\\ 6&4&9\\ 4&-2&-1 \end{bmatrix}
\end{equation*}
\begin{equation*}
	(AB)C = \begin{bmatrix}5 &1 &4\\ 6&4&9\\ 4&-2&-1 \end{bmatrix}\begin{bmatrix}1&-1&1\\ 2&0&1\\ 3&0&1 \end{bmatrix} =
	\begin{bmatrix}19 & -5 & 10 \\41 & -6 & 19 \\-3 & -4 & 1\end{bmatrix} \tag{**}
\end{equation*}
Luego (*) = (**) y el resultado queda verificado. \qed


\item\label{ej2} Determinar cuál de las siguientes matrices es $A$, cuál es $B$ y cuál es $C$ de modo tal que sea posible realizar el producto $ABC$ y verificar que $A(BC)=(AB)C$.
\begin{equation*}
\begin{bmatrix} 2 & -1 & 1 \\ 1 & 2 &
1\end{bmatrix},\qquad
\begin{bmatrix} 3 \\ 1 \\ -1\end{bmatrix}, \qquad
\begin{bmatrix} 1 & -1 \end{bmatrix}.
\end{equation*}
\vskip .2cm
\noindent\textsc{Solución:} la  primera matriz es $2 \times 3$, la segunda es $3 \times 1$ y la tercera es $1 \times 2$. Entonces, podemos multiplicar la 1º por  la 2º y  queda una matrix $2 \times 1$ que es posible multiplicar por la 3º matriz,  que es $1 \times 2$,  y así obtenemos una matriz $2 \times 2$.  Es decir,
\begin{equation*}
	A=\begin{bmatrix} 2 & -1 & 1 \\ 1 & 2 &
	1\end{bmatrix},\qquad
	B= \begin{bmatrix} 3 \\ 1 \\ -1\end{bmatrix}, \qquad
	C= \begin{bmatrix} 1 & -1 \end{bmatrix}.
\end{equation*}
Ahora bien, 
\begin{equation*}
BC= \begin{bmatrix} 3 \\ 1 \\ -1\end{bmatrix}\begin{bmatrix} 1 & -1 \end{bmatrix} =  \begin{bmatrix} 3& -3\\ 1&-1 \\-1 &1\end{bmatrix}
\end{equation*}
\begin{equation*}
	A(BC)=\begin{bmatrix} 2 & -1 & 1 \\ 1 & 2 &	1\end{bmatrix}\begin{bmatrix} 3& -3\\ 1&-1 \\-1 &1\end{bmatrix} =  \begin{bmatrix} 4&-4 \\ 4&-4 \end{bmatrix}
\end{equation*}
\begin{equation*}
	AB=\begin{bmatrix} 2 & -1 & 1 \\ 1 & 2 &
	1\end{bmatrix}\begin{bmatrix} 3 \\ 1 \\ -1\end{bmatrix} = \begin{bmatrix} 4 \\ 4 \end{bmatrix}.
\end{equation*}
\begin{equation*}
	(AB)C= \begin{bmatrix} 4 \\ 4 \end{bmatrix}\begin{bmatrix} 1 & -1 \end{bmatrix} = \begin{bmatrix} 4&-4 \\ 4&-4 \end{bmatrix}.
\end{equation*}\qed


\item Calcular $A^2$ y $A^3$ para la matriz \
$
A=\begin{bmatrix}
3 & 4\\ 6 & 8
\end{bmatrix}.
$
\vskip .2cm
\noindent\textsc{Solución:}
\begin{align*}
	A^2 &= \begin{bmatrix}
		3 & 4\\ 6 & 8
		\end{bmatrix}\begin{bmatrix}
			3 & 4\\ 6 & 8
			\end{bmatrix} = \begin{bmatrix}
				33 & 44\\ 66 & 88
				\end{bmatrix}  = 11\begin{bmatrix}
					3 & 4\\ 6 & 8
					\end{bmatrix} = 11A\\
	A^3 &= A\cdot A^2 = A\cdot 11A = 11A^2 = 11^2A. 
\end{align*}

\noindent \textbf{Observación.} Este es un caso muy particular. En  el caso de una matriz escalar $c\operatorname{Id}$,  tenemos que  $(c\operatorname{Id})^n= c^n \operatorname{Id}$. Aquí tenemos una matriz $A$ tal que $A^n = 11^{n-1}A$.

\qed



\item\label{ejemplos 2x2}  Dar ejemplos de matrices no nulas $A$ y $B$ de orden $2\times2$ tales que
\begin{multicols}{2}
\begin{enumerate}[topsep=5pt,itemsep=5pt]
 \item $A^2=0$ (dar dos ejemplos).
 \item $AB\neq BA$.
 \item $A^2=-\operatorname{I}_2$.
 \item $A^2=A\neq\operatorname{I}_2$.
\end{enumerate}
\end{multicols}
\vskip .2cm
\noindent\textsc{Solución:}
\vskip .2cm
 (a)
\begin{equation*}
	A = \begin{bmatrix}
		0 & 1\\ 0 & 0
		\end{bmatrix}, \qquad A = \begin{bmatrix}
			0 & 0\\ 1 & 0
			\end{bmatrix}.
\end{equation*}
\vskip .2cm
 (b)
 \begin{equation*}
	A = \begin{bmatrix}
		0 & 1\\ 0 & 0
		\end{bmatrix}, \qquad B = 
		\begin{bmatrix}
		0 & 0\\ 1 & 0
		\end{bmatrix}.
\end{equation*}
\begin{align*}
	AB &= \begin{bmatrix}
		0 & 1\\ 0 & 0
		\end{bmatrix} \begin{bmatrix}
			0 & 0\\ 1 & 0
			\end{bmatrix} = \begin{bmatrix}
				1 & 0\\ 0 & 0
				\end{bmatrix} \\
	BA &=  
		\begin{bmatrix}
		0 & 0\\ 1 & 0
		\end{bmatrix}
		\begin{bmatrix}
		0 & 1\\ 0 & 0
		\end{bmatrix} = \begin{bmatrix}
		0 & 0\\ 0 & 1
		\end{bmatrix} 
\end{align*}
\vskip .2cm
 (c)
 \begin{equation*}
	A = \begin{bmatrix}
		0 & 1\\ -1 & 0
		\end{bmatrix}, \qquad \Rightarrow \qquad A^2 = 
		\begin{bmatrix}
			0 & 1\\ -1 & 0
			\end{bmatrix}
			\begin{bmatrix}
				0 & 1\\ -1 & 0
				\end{bmatrix}
			= \begin{bmatrix}
				-1 & 0\\ 0 & -1
				\end{bmatrix}.
\end{equation*}
\vskip .2cm
(d)
\begin{equation*}
	A = \begin{bmatrix}
		1 & 0\\ 0 & 0
		\end{bmatrix}.
\end{equation*}
\qed


\item\label{2x2 central}  Sea $A \in\mathbb{R}^{2\times 2}$ tal que $AB=BA$ para toda $B\in\mathbb{R}^{2\times 2}$. Probar que $A$ es un múltiplo de $\operatorname{I}_2$.
\vskip .2cm
\noindent\textsc{Solución:} Sea
\begin{equation*}
	A = \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22} \end{bmatrix},
\end{equation*}
y sean 
\begin{equation*}
	E_{11} = \begin{bmatrix} 1 & 0\\ 0 & 0\end{bmatrix},
	\quad
	E_{12} = \begin{bmatrix} 0 & 1\\ 0 & 0\end{bmatrix},
	\quad
	E_{21} = \begin{bmatrix} 0 & 0\\ 1 & 0\end{bmatrix},
	\quad
	E_{22} = \begin{bmatrix} 0 & 0\\ 0 & 1\end{bmatrix}. 
\end{equation*}
Entonces 
\begin{align*}
	AE_{11} = \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22} \end{bmatrix} \begin{bmatrix} 1 & 0\\ 0 & 0\end{bmatrix} =
	\begin{bmatrix} a_{11} &0\\ a_{21} & 0\end{bmatrix}, \quad
	E_{11}A =  \begin{bmatrix} 1 & 0\\ 0 & 0\end{bmatrix} \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22} \end{bmatrix}=
	\begin{bmatrix} a_{11} & a_{12}\\ 0 & 0 \end{bmatrix},
\end{align*}
Como $AE_{11} = E_{11}A$, tenemos que $a_{12} = a_{21} =0$.

Probemos ahora con $E_{12}$:
\begin{align*}
	AE_{12} = \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22} \end{bmatrix} \begin{bmatrix} 0 & 1\\ 0 & 0\end{bmatrix} =
	\begin{bmatrix} 0 &a_{11}\\ 0 & a_{21}\end{bmatrix}, \quad
	E_{12}A =  \begin{bmatrix} 0 & 1\\ 0 & 0\end{bmatrix} \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22} \end{bmatrix}=
	\begin{bmatrix} a_{21} & a_{22}\\ 0 & 0 \end{bmatrix},
\end{align*}
Como $AE_{12} = E_{12}A$, tenemos que $a_{11} = a_{22}$. 

Ya no hace falta hacer más ensayos, pues hemos probado que $a_{12} = a_{21} =0$ y $a_{11} = a_{22}$, es decir $A$ es una matriz escalar y  al ser escalar sabemos que conmuta con todas las matrices. 

\vskip .2cm
\noindent \textbf{Observación.} El resultado es cierto también para matrices $n \times  n$ con $n \in \mathbb N$. Es decir,  si $A \in\mathbb{R}^{n\times n}$ tal que $AB=BA$ para toda $B\in\mathbb{R}^{n\times n}$,  entonces  $A$ es un múltiplo de $\operatorname{I}_n$. La estrategia para probar este resultado es la misma que para el caso $2 \times 2$: probar con las matrices $E_{ij}$ que son aquellas que tiene un 1 en la entrada $ij$ y  0  en las demás entradas. 

\qed

\item  Para cada $n\in\mathbb{N}$, con $n\geq 2$, hallar una matriz no nula $A\in\mathbb{R}^{n\times n}$ tal que $A^n=0$ pero $A^{n-1}\neq0$.
\vskip .2cm
\noindent\textsc{Solución:} Las matrices  triangulares estrictas, superiores o inferiores, satisfacen la propiedad de que $A^n=0$ y  muchas de ellas satisfacen que $A^{n-1} \ne 0$. Probemos con una matriz triangular superior estricta particular 
\begin{equation*}
	A = \begin{bmatrix}
		0&1&0&0&\ldots&0 \\
		0&0&1&0&\ldots&0 \\
		0&0&0&1&\ldots&0 \\
		\vdots&&&&\ddots&\vdots \\
		0&0&0&0&\ldots &1 \\
		0&0&0&0&\ldots &0  
	\end{bmatrix} = \begin{bmatrix}
		e_2 \\ e_3 \\ e_4 \\ \vdots \\ e_n \\0
	\end{bmatrix} = \begin{bmatrix} \mid& \mid& \mid& &\mid\\ 0 & e_1 & e_2 & \cdots &e_{n-1}\\ \mid&\mid & \mid& &\mid\end{bmatrix}
\end{equation*}
Es decir $A$  es una matriz $n \times n$ con $1$ encima de la diagonal y $0$  en todas las demás entradas. Más formalmente: $[A]_{i,i+1} = 1$ y $[A]_{i,j} = 0$ si $j \ne i+1$. 
\vskip .2cm
Probaremos por inducción que para $k< n$,  $[A^k]_{i,i+k} = 1$ y $[A]_{i,j} = 0$ si $j \ne i+k$. Es decir,
\begin{equation*}
	A^k  = \begin{bmatrix} 
		\mid& \cdots & \mid& \mid& \mid&   &\mid\\ 
		0 & \cdots & 0 & e_{1}& e_2& \cdots &e_{n-k}\\ 
		\mid& \cdots& \mid& \mid& \mid&   &\mid
	\end{bmatrix},
\end{equation*}
donde $e_1$  está en la columna $k+1$. 


Si $k=1$ el resultado vale por definición de $A$. Supongamos que el resultado es cierto para $k-1$,   luego \begin{equation*}
	A^{k-1}  = \begin{bmatrix} 
		\mid& \cdots & \mid& \mid& \mid&   &\mid\\ 
		0 & \cdots & 0 & e_{1}& e_2& \cdots &e_{n-k+1}\\ 
		\mid& \cdots& \mid& \mid& \mid&   &\mid
	\end{bmatrix},\tag{HI}
\end{equation*}
donde $e_1$  está en la columna $k$. Por lo tanto,
\begin{equation*}
	A \cdot A^{k-1}  = \begin{bmatrix}
		e_2 \\ e_3 \\ e_4 \\ \vdots \\ e_n \\0
	\end{bmatrix} \begin{bmatrix} 
		\mid& \cdots & \mid& \mid& \mid&   &\mid\\ 
		0 & \cdots & 0 & e_{1}& e_2& \cdots &e_{n-k+1}\\ 
		\mid& \cdots& \mid& \mid& \mid&   &\mid
	\end{bmatrix},
\end{equation*}
Como $[A\cdot A^{k-1}]_{ij} = F_i(A) \cdot C_j(A^{k-1})$ (donde $\cdot$ indica el producto escalar), los únicos productos no nulos son $ F_1(A) \cdot C_{k+1}(A^{k-1}) = 1$,  $ F_2(A) \cdot C_{k +2}(A^{k-1}) = 1$, $ F_3(A) \cdot C_{k +3}(A^{k-1}) = 1$, etc. Es decir, las entradas de $A^k$ valen $1$ en $(1,k+1)$, $(2,k+2)$, $(3,k+3)$, etc. lo cual prueba el resultado. 


Probado esto, tenemos $A^{n-1} = [0 \;\cdots\; 0\; e_1] \ne 0$ y $A^n = A \cdot A^{n-1}=0$. 

\qed


\item\label{eq:binomio}  Dar condiciones necesarias y suficientes sobre matrices $A$ y $B$ de tama\~{n}o $n\times n$ para que
\begin{multicols}{2}
	\begin{enumerate}
		\item\label{ej-p3-8-a} $(A + B)^2 = A^2 + 2AB + B^2$.
		\item\label{ej-p3-8-b} $A^2 - B^2 = (A - B)(A + B)$.
	\end{enumerate}
\end{multicols}
\vskip .2cm
\noindent\textsc{Solución:}

(a)  Como
\begin{align*}
&(A + B)^2 = (A+B)(A+B) = AA +AB + BA +BB = A^2 + AB +BA + B^2  \; \text{ y}\\
&A^2 + 2AB + B^2 = A^2 + AB + AB + B^2, 
\end{align*}
tenemos que 
\begin{align*}
	(A + B)^2 = A^2 + 2AB + B^2 \quad &\Leftrightarrow \quad  A^2 + AB +BA + B^2  = A^2 +  AB + AB + B^2 \\
	&\Leftrightarrow \quad AB + BA = AB + AB \\
	&\Leftrightarrow \quad BA = AB.
\end{align*}

\vskip .4cm

(b) Como
\begin{align*}
	&A^2 - B^2  = AA -BB& \text{ y} &\qquad\qquad \\
	&(A - B)(A + B) = AA +AB -BA -BB,&& 
\end{align*}
tenemos que 
\begin{align*}
	A^2 - B^2 = (A - B)(A + B) \quad &\Leftrightarrow \quad AA -BB  = AA +AB -BA -BB \\
	&\Leftrightarrow \quad 0 = AB -BA \\
	&\Leftrightarrow \quad BA = AB.
\end{align*}
\qed




\item\label{ej:multiplicar por columna}  Sean
\begin{align*}
v=\begin{bmatrix} v_1 \\ \vdots \\ v_n
\end{bmatrix}\in\mathbb{R}^{n\times1}
\quad\mbox{y}\quad A=\begin{bmatrix} \mid& \mid& &\mid\\ C_1 & C_2 & \cdots &C_n\\ \mid& \mid& &\mid\end{bmatrix}
\in\mathbb{R}^{m\times n},
\end{align*}
es decir, $C_1, ..., C_n$ denotan las columnas de $A$. Probar que $Av=\sum_{j=1}^nv_jC_j$.
\vskip .2cm
\noindent\textsc{Solución:} Sea 
\begin{equation*}
	C_j = \begin{bmatrix}
		c_{1j} \\c_{2j} \\ \vdots \\ c_{mj} 
	\end{bmatrix}, \quad \text{para $1 \le j \le n$}.
\end{equation*}
$Av$  es una matriz  $m\times 1$ cuya coordenada $i,1$  es $[Av]_{i1} = F_i(C) \cdot v$ donde $\cdot$  es el producto escalar. Es  decir 
\begin{equation*}
	[Av]_{i1} = \sum_{j = 1}^n c_{ij}v_j, \qquad (1 \le i \le m).
\end{equation*}
Por lo tanto
\begin{equation*}
 Av = \begin{bmatrix}
	\sum_{j = 1}^n c_{1j}v_j \\ \vdots \\ \sum_{j = 1}^n c_{ij}v_j \\ \vdots \\ \sum_{j = 1}^n c_{mj}v_j
 \end{bmatrix} =
 \sum_{j = 1}^n
 \begin{bmatrix}
	 c_{1j}v_j \\ \vdots \\  c_{ij}v_j \\ \vdots \\ c_{mj}v_j
 \end{bmatrix} =
 \sum_{j = 1}^n v_j
 \begin{bmatrix}
	 c_{1j}\\ \vdots \\  c_{ij} \\ \vdots \\ c_{mj}
 \end{bmatrix} =
 \sum_{j = 1}^n v_j C_j.
\end{equation*}
\qed



\item\label{traza} Si $A$ es una matriz cuadrada $n\times n$, se define la {\it \textbf{traza}} de $A$ 
como $\operatorname{Tr}(A)=\displaystyle{\sum_{i=1}^n} a_{ii}$.
\begin{enumerate}[topsep=5pt,itemsep=5pt]
 \item Calcular la traza de las matrices del ejercicio  \ref{ej:inversas}. 
 \item\label{ej:traza} Probar que si $A,B\in\mathbb{R}^{n\times n}$ y $c\in\mathbb{R}$ entonces
 \begin{align*}
 \operatorname{Tr}(A+cB)=\operatorname{Tr}(A)+c\operatorname{Tr}(B)
 \quad\mbox{y}\quad
 \operatorname{Tr}(AB)=\operatorname{Tr}(BA).
 \end{align*}
\end{enumerate}
\vskip .2cm
\noindent\textsc{Solución:}
 (a) \begin{align*}
	A&= \begin{bmatrix*}[r] 3 & -1 & 2 \\ 2 & 1 & 1 \\ 1 & -3 & 0\end{bmatrix*} &\Rightarrow& \qquad \operatorname{Tr}(A)= 3+1+0 =4, \\
	B &= \begin{bmatrix*}[r] -1 & -1 &4 \\ 1 & 3 & 8 \\ 1 & 2 & 5\end{bmatrix*} &\Rightarrow& \qquad \operatorname{Tr}(B)=\ -1 +3 + 5 = 7,\\
	C &= \begin{bmatrix*}[r] 1 & 1 & 1 & 2 \\ 1 & -3 & 3 & -8 \\ -2 & 1 & 2 & -2 \\ 1 & 2 & 1 & 4 \end{bmatrix*} &\Rightarrow& \qquad \operatorname{Tr}(C)= 1 +(-3)+2+4 = 4,\\
	D &= \begin{bmatrix*}[r] 1 & -3 & 5 \\ 2 & -3 & 1 \\ 0 & -1 & 3 \end{bmatrix*}&\Rightarrow& \qquad \operatorname{Tr}(D)=1 + (-3) + 3 = 1.
	\end{align*}

(b) Sea $A = [a_{ij}]$ y $B = [b_{ij}]$,  entonces
\begin{align*}
	\operatorname{Tr}(A+cB)&=   \sum_{i=1}^n [A+cB]_{ii}\\
	&= \sum_{i=1}^n (a_{ii} + c b_{ii}) = \sum_{i=1}^n a_{ii} + c \sum_{i=1}^n  b_{ii}\\
	&=\operatorname{Tr}(A)+c\operatorname{Tr}(B)
\end{align*}

Veamos la segunda afirmación de (b):
\begin{align*}
	\operatorname{Tr}(AB)&=   \sum_{i=1}^n [AB]_{ii} = \sum_{i=1}^n (\sum_{j=1}^n  a_{ij}b_{ji}) \\
	&= \sum_{i,j=1}^n  a_{ij}b_{ji} = \sum_{j=1}^n (\sum_{i=1}^n  a_{ij}b_{ji}) \\
	&=  \sum_{j=1}^n (\sum_{i=1}^n  b_{ji}a_{ij}) =  \sum_{j=1}^n [BA]_{jj} \\
	&= \operatorname{Tr}(BA).
\end{align*}

\qed 

\item\label{ej:inversas} Para cada una de las siguientes matrices, usar operaciones elementales
por fila para decidir si son invertibles y hallar la matriz inversa cuando sea posible.
\begin{equation*}
\begin{bmatrix} 3 & -1 & 2 \\ 2 & 1 & 1 \\ 1 & -3 & 0\end{bmatrix},\qquad
\begin{bmatrix} -1 & -1 &4 \\ 1 & 3 & 8 \\ 1 & 2 & 5\end{bmatrix},\qquad
\begin{bmatrix} 1 & 1 & 1 & 2 \\ 1 & -3 & 3 & -8 \\ -2 & 1 & 2 & -2 \\ 1 & 2 & 1 & 4 \end{bmatrix},\qquad
\begin{bmatrix} 1 & -3 & 5 \\ 2 & -3 & 1 \\ 0 & -1 & 3 \end{bmatrix}.
\end{equation*}
(para que hagan menos cuentas: las matrices $3\times3$ aparecieron en el Práctico 2).
\vskip .2cm
\noindent\textsc{Solución:}

\begin{align*}
	[A|\operatornamewithlimits{Id}] &= 
	\begin{bmatrix}3 & -1 & 2&\bigm| &1 &0 & 0\\2 & 1 & 1&\bigm|& 0 &1 &0 \\1&-3&0&\bigm| &0 &0 &1\end{bmatrix}
	\stackrel{F_1 \leftrightarrow F_3}{\longrightarrow}
	\begin{bmatrix}1&-3&0&\bigm| &0 &0 &1\\2 & 1 & 1&\bigm|& 0 &1 &0 \\3 & -1 & 2&\bigm| &1 &0 & 0\end{bmatrix} \\
	&\stackrel{F_2 - 2 F_1}{\stackrel{F_3 - 3 F_1}{\longrightarrow}}
	\begin{bmatrix} 1 & -3 & 0  &\bigm|&0 &0 &1\\ 0 & 7 & 1 &\bigm|& 0 &1 &-2 \\ 0 & 8 & 2 &\bigm| &1 &0 & -3\end{bmatrix}
	\stackrel{F_3-F_2}{\longrightarrow}
	\begin{bmatrix} 1 & -3 & 0  &\bigm|&0 &0 &1\\ 0 & 7 & 1 &\bigm|& 0 &1 &-2 \\  0 & 1 & 1  &\bigm| &1 &-1 & -1\end{bmatrix}\\
	&\stackrel{F_3 \leftrightarrow F_2}{\longrightarrow} 
	\begin{bmatrix} 1 & -3 & 0  &\bigm|&0 &0 &1\\  0 & 1 & 1  &\bigm| &1 &-1 & -1\\ 0 & 7 & 1 &\bigm|& 0 &1 &-2 \end{bmatrix}
	\stackrel{F_1 + 3 F_2}{\stackrel{F_3-7F_2}{\longrightarrow}}
	\begin{bmatrix} 1 & 0 & 3 &\bigm|&3 & -3 &-2\\ 0 & 1 & 1 &\bigm| &1 &-1 & -1\\ 0 & 0 & -6 &\bigm|&-7&8&5\end{bmatrix} \\
	&\stackrel{F_3 (-\frac{1}{6}) }{\longrightarrow}
	\begin{bmatrix} 1 & 0 & 3 &\bigm|&3 & -3 &-2\\ 0 & 1 & 1 &\bigm| &1 &-1 & -1\\ 0 & 0 & 1 &\bigm|&7/6&-4/3&-5/6\end{bmatrix} \\
	&\stackrel{F_1 - 3 F_3}{\stackrel{F_2 - F_3 }{\longrightarrow}}
	\begin{bmatrix} 1 & 0 & 0&\bigm|& -1/2&1&1/2\\ 0 & 1 & 0&\bigm|&-1/6 &1/3&-1/6\\ 0 & 0 & 1&\bigm|&7/6&-4/3&-5/6 \end{bmatrix}
	\end{align*}
	Luego  
	\begin{equation*}
		\begin{bmatrix} 3 & -1 & 2 \\ 2 & 1 & 1 \\ 1 & -3 & 0\end{bmatrix}^{-1} = 
		\begin{bmatrix}-1/2&1&1/2\\ -1/6 &1/3&-1/6\\7/6&-4/3&-5/6 \end{bmatrix}. 
	\end{equation*}
\vskip .4cm
Siguiendo un procedimiento análogo al anterior se obtiene
\begin{align*}
	\begin{bmatrix} -1 & -1 &4 \\ 1 & 3 & 8 \\ 1 & 2 & 5\end{bmatrix}^{-1} = \begin{bmatrix} 1/6& -13/6& 10/3\\-1/2& 3/2& -2\\1/6& -1/6& 1/3\end{bmatrix}.
	\end{align*}

	\vskip .4cm
La tercera matriz tiene una MERF con una fila nula. Por lo tanto no es invertible:
\begin{align*}
	&\begin{bmatrix} 1 & 1 & 1 & 2 \\ 1 & -3 & 3 & -8 \\ -2 & 1 & 2 & -2 \\ 1 & 2 & 1 & 4 \end{bmatrix} 
	\stackrel{F_2 -  F_1}{\stackrel{F_3+2F_1}{\stackrel{F_4 - F_1 }{\longrightarrow}}}
	\begin{bmatrix} 1 & 1 & 1 & 2 \\ 0 & -4 & 2 & -10 \\ 0 & 3 & 4 & 2 \\ 0 & 1 & 0 & 2 \end{bmatrix} 
	\stackrel{F_1 -  F_4}{\stackrel{F_2+4F_4}{\stackrel{F_3 - 3F_1 }{\longrightarrow}}}
	\begin{bmatrix} 1 & 0 & 1 & 0 \\ 0 & 0 & 2 & -2 \\ 0 & 0 & 4 & -4 \\ 0 & 1 & 0 & 2 \end{bmatrix} \\
	&\quad
	\stackrel{F_2/2}{\stackrel{F_3/4}{\longrightarrow}}
	\begin{bmatrix} 1 & 0 & 1 & 0 \\ 0 & 0 & 1 & -1 \\ 0 & 0 & 1 & -1 \\ 0 & 1 & 0 & 2 \end{bmatrix}
	\stackrel{F_1-F_3}{\stackrel{F_2-F_3}{\longrightarrow}}
	\begin{bmatrix} 1 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 1 & -1 \\ 0 & 1 & 0 & 2 \end{bmatrix}
	\stackrel{F_2 \leftrightarrow F_4}{\longrightarrow}
	\begin{bmatrix} 1 & 0 & 0 & 1 \\ 0 & 1 & 0 & 2 \\ 0 & 0 & 1 & -1 \\ 0 & 0 & 0 & 0 \end{bmatrix}.
\end{align*}

\vskip .4cm
Finalmente, la última matriz  tiene una MERF con una fila nula. Por lo tanto no es invertible:
\begin{align*}
	&\left[\begin{array}{ccc}
	 1&-3&5\\
	 2&-3&1\\
	 0&-1&3\end{array}\right] 
	 \stackrel{F_2-2F_1}{\longrightarrow}   
	 \left[\begin{array}{ccc}
	1&-3&5\\
	 0&3&-9\\
	 0&-1&3\end{array}\right]
	 \stackrel{F_1-3F_3}{\stackrel{F_2+3F_3}{\longrightarrow}}  
	 \left[\begin{array}{ccc}
	 1&0&-4\\
	 0&0&0\\
	 0&-1&3\end{array}\right]  \\
	 &{\stackrel{-F_3}{\longrightarrow}}  \quad
	 \left[\begin{array}{ccc}
	 1&0&-4\\
	 0&0&0\\
	 0&1&-3\end{array}\right]{\stackrel{F_2 \leftrightarrow F_3}{\longrightarrow}}   
	  \left[\begin{array}{ccc}
	1&0&-4\\
	 0&1&-3\\
	0&0&0 \end{array}\right].
	\end{align*}

	\qed 


\item Sea $A$ la primera matriz del ejercicio anterior.
Hallar matrices elementales $E_1,E_2,\dots,E_k$ tales que $E_kE_{k-1}\cdots E_2E_1A=\operatorname{I}_3$.
\vskip .2cm
\noindent\textsc{Solución:} En  la primera matriz del ejercicio (\ref{ej:inversas}) realizamos 10 operaciones elementales de fila para llevar la matriz a la identidad. Si llamamos a la matriz $A$, entonces
$$
\operatorname{Id}_3= E_{10}E_9E_8E_7E_6E_5E_4E_3E_2E_1A,
$$
Donde 
\begin{align*}
	E_1 &= \begin{bmatrix} 0&0&1 \\	0&1&0 \\ 1&0&0\end{bmatrix}\;(F_1 \leftrightarrow F_3) ,\qquad
	E_2 = \begin{bmatrix} 1&0&0 \\	-2&1&0 \\ 0&0&1\end{bmatrix}\; (F_2-2F_1),\qquad \\
	E_3 &= \begin{bmatrix} 1&0&0 \\	0&1&0 \\ -3&0&1\end{bmatrix}\; (F_3-3F_1),\qquad 
	E_4 = \begin{bmatrix} 1&0&0 \\	0&1&0 \\ 0&-1&1\end{bmatrix}\; (F_3-F_2),\qquad  \\
	E_5 &= \begin{bmatrix} 1&0&0 \\	0&0&1 \\ 0&1&0\end{bmatrix}\; (F_3 \leftrightarrow F_2),\qquad 
	E_6 = \begin{bmatrix} 1&3&0 \\	0&1&0 \\ 0&0&1\end{bmatrix}\; (F_1 +3F_2),\qquad \\
	E_7 &= \begin{bmatrix} 1&0&0 \\	0&1&0 \\ 0&-7&1\end{bmatrix}\; (F_3-7F_2),\qquad 
	E_8 = \begin{bmatrix} 1&0&0 \\	0&1&0 \\ 0&0&-1/6\end{bmatrix}\; (-(1/6)F_3),\qquad \\
	E_9 &= \begin{bmatrix} 1&0&-3 \\	0&1&0 \\ 0&0&1\end{bmatrix}\; (F_1-3F_3),\qquad 
	E_{10} = \begin{bmatrix} 1&0&0 \\	0&1&-1 \\ 0&0&1\end{bmatrix}\; (F_2-F_3).\qquad 
\end{align*}

\qed



\item ¿Es cierto que si $A$ y $B$ son matrices invertibles entonces $A+B$ es una matriz invertible? Justificar su respuesta.
\vskip .2cm
\noindent\textsc{Solución:} Es  falso, el ejemplo más sencillo es $\operatorname{Id} +(-\operatorname{Id}) =0$. Otro ejemplo, 
\begin{equation*}
	\begin{bmatrix}  1&0\\0&1 \end{bmatrix} + \begin{bmatrix}  1&1\\0&-1 \end{bmatrix} = \begin{bmatrix}  2&1\\0&0 \end{bmatrix}. 
\end{equation*}\qed



\item\label{nilpotene - id} Una matriz $A\in\mathbb{R}^{n\times n}$ se dice \emph{nilpotente} si $A^k=0$ para algún $k\in\mathbb{N}$.
Probar que si una matriz $A$ es nilpotente, entonces  $\operatorname{I}_n - A$  es invertible.
\vskip .2cm
\noindent\textsc{Solución:} Supongamos que $A^k=0$ para algún $k\in\mathbb{N}$, y probemos que: $$(\operatorname{I}_n - A)^{-1} = \operatorname{I}_n + A + A^2 +\cdots + A^{k-1} = \sum_{i=0}^{k-1} A^{i}.$$
En efecto,
\begin{align*}
& (\operatorname{I}_n - A)(\operatorname{I}_n + A + A^2 +\cdots + A^{k-1})\\
&= \operatorname{I}_n (\operatorname{I}_n + A + A^2 +\cdots + A^{k-1}) - A (\operatorname{I}_n + A + A^2 +\cdots + A^{k-1})\\
&= (\operatorname{I}_n + A + A^2 +\cdots + A^{k-1}) - (A + A^2 + A^3 +\cdots + A^{k})\\
&= \operatorname{I}_n - A^{k} = \operatorname{I}_n - 0 = \operatorname{I}_n.
\end{align*}

\qed


\item\label{sol homog es subesp} Sean  $v$ y $w$ dos soluciones del sistema homogéneo $AX=0$. Probar que $v+tw$ también es solución para todo $t\in\mathbb{K}$.
\vskip .2cm
\noindent\textsc{Solución:} Como $v,w$  soluciones de $AX=0$, tenemos que $Av=0$ y $Aw=0$.  Luego, por las propiedades que cumple el producto y suma de matrices:
\begin{eqnarray*}
	A(v + tw) = Av +A(tw) = 0 + t(Aw) = 0 + 0 = 0.
\end{eqnarray*}
Es decir, $v +tw$  es solución de $AX=0$.
\qed


\item\label{homogeneo+no-homogeneo} Sea $v$ una solución del sistema $AX=Y$ y $w$ una solución del sistema homogéneo $AX=0$. Probar que $v+tw$ también es solución del sistema $AX=Y$ para todo $t\in\mathbb{K}$.
\vskip .2cm
\noindent\textsc{Solución:}  Como $v$  solución de $AX=Y$, tenemos que $Av=Y$. Al ser $w$  solución del sistema $AX=0$, se cumple $Aw=0$. Luego, por las propiedades que cumple el producto y suma de matrices:
\begin{eqnarray*}
	A(v + tw) = Av +A(tw) = Y + t(Aw) = Y + 0 = Y.
\end{eqnarray*}
Es decir, $v +tw$  es solución de $AX=Y$.
\qed


\item Probar que si el sistema homogéneo  $AX=0$ posee alguna solución no trivial, entonces el sistema $AX=Y$ no tiene
solución o tiene al menos dos soluciones distintas.
\vskip .2cm
\noindent\textsc{Solución:} Si $AX=Y$ no tiene solución, listo, pues es uno de los casos. Si $AX=Y$ tiene solución,  sea entonces $w$ alguna solución del sistema, es decir $Aw=Y$. Por hipótesis $AX=0$ tiene soluciones no triviales,  es decir existe $v \ne 0$ tal que $Av =0$. Por el ejercicio  (\ref{homogeneo+no-homogeneo}): $v+ w$ es solución del sistema $AX=Y$, como $v \ne 0$, los vectores $w$ y $v+w$ son distintos y ambos son solución del sistema  $AX=Y$.
\vskip .2cm
\noindent \textbf{Observación.} En  realidad,  la existencia de una solución $w$ del sistema $AX=Y$ implica la existencia de infinitas soluciones, pues por ejercicio   (\ref{homogeneo+no-homogeneo}) los vectores $w + tv$ son soluciones de $AX=Y$ para todo $t \in \mathbb K$. 

\qed


\item Supongamos que los sistemas $AX=Y$ y $AX=Z$ tienen solución. Probar que el sistema $AX=Y+tZ$ también tiene solución para todo $t\in\mathbb{K}$.
\vskip .2cm
\noindent\textsc{Solución:} Sea $v$ solución de $AX=Y$, es decir $Av = Y$ y sea $w$ solución del sistema $AX=Z$,  es decir $Aw=Z$. Entonces, dado $t \in \mathbb K$
\begin{equation*}
	A(v + tw) = Av + Atw = Y +tAw = Y + tZ.
\end{equation*}
Es decir $v +tw$ es solución de $AX=Y+tZ$. 

\qed


\item \label{sist-por-invertible}Sean $A$ una matriz invertible $n\times n$, y $B$ una matriz $n\times m$.  Probar que los sistemas $BX=Y$ y $ABX=AY$ tienen las mismas soluciones.
\vskip .2cm
\noindent\textsc{Solución:} 
\begin{align*}
	\text{$v$ es vsol. de $BX=Y$} \; &\Rightarrow \; Bv = Y&& \\
	&\Rightarrow \;  ABv = AY &&(\text{mult. por $A$  a izq.}) \\
	&\Rightarrow \;   \text{$v$ es sol. de $ABX=AY$}&&
\end{align*}
Esta ``ida'' vale para cualquier matriz $A$,  sea invertible o no. Para la vuelta debemos utilizar la existencia de $A^{-1}$:
\begin{align*}
	\text{$v$ es sol. de $ABX=AY$} \; &\Rightarrow \; ABv = AY&& \\
	&\Rightarrow \;  A^{-1}ABv = A^{-1}AY &&(\text{mult. por $A^{-1}$  a izq.}) \\
	&\Rightarrow \;  \operatorname{Id} Bv = \operatorname{Id}Y &&(\text{ $A^{-1}A= \operatorname{Id}$}) \\
	&\Rightarrow \;   Bv =Y&&(\text{$\operatorname{Id}$ es neutro del prod.}) \\
	&\Rightarrow \;   \text{$v$ es sol. de $BX=Y$}&&
\end{align*}

\qed


\item\label{ej:sistemas ABX} 
Sean $A$ y $B$ matrices $r\times n$ y $n\times m$ respectivamente.
Probar que:
\begin{enumerate}[topsep=5pt,itemsep=5pt]
	\item  Si $m>n$, entonces el sistema $ABX=0$ tiene soluciones no triviales.
	\item  Si $r>n$, entonces existe un $Y$, $r\times 1$, tal que $ABX=Y$
	no tiene solución.
\end{enumerate}
\vskip .2cm
\noindent\textsc{Solución:}

 (a) Como $m> n$ el sistema $BX =0$ tiene más incógnitas que ecuaciones, por lo tanto tiene soluciones no triviales. Sea $v \ne 0$ solución de $BX=0$,  es decir $Bv=0$. Entonces $ABv = A(Bv) = A0 =0$, por lo tanto $v$  es solución del sistema $ABX=0$.  

 \vskip .2cm
(b) Sea $P$  matriz $r \times r$ inversible tal que $PA$ es MERF. Como $r > n$,  la  matriz $PA$  tiene  más filas que columnas y como es MERF la última fila debe ser nula.  

Ahora bien, por el ejercicio (\ref{sist-por-invertible}), los sistemas $PABX=PY$ y $ABX=Y$ tiene las mismas soluciones, por lo tanto si existe $Y$ tal que $PABX=PY$ no tiene solución, entonces el sistema $ABX=Y$ tampoco tiene solución. 

Demostremos, entonces, que existe $Y$  tal que $PABX=PY$ no tiene solución: como $PA$ tiene la última fila nula, $PABX$ también tiene la última fila nula. Sea $e_r$ la matriz $r \times 1$ con $1$ en la coordenada $r$ y $0$  en las otras coordenadas. Entonces $e_r = P(P^{-1}e_r)$  tiene la última fila no nula, por lo tanto el sistema $PABX=P(P^{-1}e_r)$ no tiene solución y, por lo dicho anteriormente, el sistema   $ABX=P^{-1}e_r$ no tiene solución.

\qed 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{enumerate}




\end{document}
