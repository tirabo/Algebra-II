%\documentclass{beamer} 
\documentclass[handout]{beamer} % sin pausas
\usetheme{CambridgeUS}

\usepackage{etex}
\usepackage{t1enc}
\usepackage[spanish,es-nodecimaldot]{babel}
\usepackage{latexsym}
\usepackage[utf8]{inputenc}
\usepackage{verbatim}
\usepackage{multicol}
\usepackage{amsgen,amsmath,amstext,amsbsy,amsopn,amsfonts,amssymb}
\usepackage{amsthm}
\usepackage{calc}         % From LaTeX distribution
\usepackage{graphicx}     % From LaTeX distribution
\usepackage{ifthen}
%\usepackage{makeidx}
\input{random.tex}        % From CTAN/macros/generic
\usepackage{subfigure} 
\usepackage{tikz}
\usepackage[customcolors]{hf-tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{matrix}
\tikzset{
	every picture/.append style={
		execute at begin picture={\deactivatequoting},
		execute at end picture={\activatequoting}
	}
}
\usetikzlibrary{decorations.pathreplacing,angles,quotes}
\usetikzlibrary{shapes.geometric}
\usepackage{mathtools}
\usepackage{stackrel}
%\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{tkz-graph}
\usepackage{polynom}
\polyset{%
	style=B,
	delims={(}{)},
	div=:
}
\renewcommand\labelitemi{$\circ$}

%\setbeamertemplate{background}[grid][step=8 ]
\setbeamertemplate{itemize item}{$\circ$}
\setbeamertemplate{enumerate items}[default]
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=,urlcolor=links}


\newcommand{\Id}{\operatorname{Id}}
\newcommand{\img}{\operatorname{Im}}
\newcommand{\nuc}{\operatorname{Nu}}
\newcommand{\im}{\operatorname{Im}}
\renewcommand\nu{\operatorname{Nu}}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\renewcommand{\t}{{\operatorname{t}}}
\renewcommand{\sin}{{\,\operatorname{sen}}}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
\newcommand{\F}{\mathbb F}
\newcommand{\Z}{\mathbb Z}
\newcommand{\N}{\mathbb N}
\newcommand\sgn{\operatorname{sgn}}
\renewcommand{\t}{{\operatorname{t}}}
\renewcommand{\figurename }{Figura}

\include{definiciones}





\title[Clase 15 - Espacios vectoriales]{Álgebra/Álgebra II \\ Clase 15 - Espacios vectoriales}

\author[]{}
\institute[]{\normalsize FAMAF / UNC
	\\[\baselineskip] ${}^{}$
	\\[\baselineskip]
}
\date[22/10/2020]{22 de octubre de 2020}



\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Resumen}
	
    En esta clase\pause
    \begin{itemize}
     \item definiremos espacios vectoriales,\pause
     \item daremos ejemplos de espacios vectoriales\pause
     \item definiremos subespacios vectoriales y veremos algunos ejemplos.
    \end{itemize}
   
    \vskip.8cm
    \
    \pause
   El tema de esta clase  está contenido de la sección 3.1 y comienzo de la 3.2 del apunte de clase ``Álgebra II / Álgebra - Notas del teórico''.
    \end{frame}
    
    \begin{frame}

        La materia en general gira alrededor del problema de
        \begin{itemize}\pause
         \item resolver sistemas homogéneos de ecuaciones lineales y\pause
         \item  caracterizar el  conjunto de soluciones como subconjunto de $\R^n$.
        \end{itemize}
        
        
        \vskip .8cm
        \pause
        Anteriormente introdujimos dos operaciones en $\R^n$:
        \begin{itemize}
         \item los vectores de $\R^n$ se pueden sumar y multiplicar por escalares,
        \end{itemize}
     y   vimos que los conjuntos de soluciones son invariantes por estas operaciones. Dicho de otro modo
        \begin{itemize}\pause
         \item Las soluciones de un sistema homogéneo de ecuaciones lineales se pueden sumar y multiplicar por escalares.
        \end{itemize}
        
       \end{frame}
        


\begin{frame}

Estas son álgunas de las preguntas que responderemos en esta parte de la materia
\pause
\begin{block}{Preguntas}
\begin{enumerate}
    \item ?`Podremos generar todas las soluciones de un sistema homogéneo sumando y multiplicando por escalares algunas pocas soluciones?\pause
    \item ?`Cuál es la mínima cantidad de soluciones que generan todas las soluciones?\pause
    \item ?`Cómo podemos representar cada solución usando el conjunto generador?
\end{enumerate}
\end{block}

\end{frame}

\begin{frame}

Por otro lado, hay otras estructuras matemáticas que tienen suma y producto por escalar 
\begin{itemize}\pause
    \item Matrices\pause
    \item Polinomios\pause
    \item Funciones
\end{itemize}

\

Las operaciones satisfacen las mismas propiedades que las operaciones en $\R^n$
\begin{itemize}\pause
    \item asociatividad\pause
    \item conmutatividad\pause
    \item distributividad\pause
    \item neutro y opuesto
\end{itemize}


\end{frame}

\begin{frame}
Entonces estudiaremos todas estas estructuras en abstracto, sin distinguir si son vectores, matrices, polinomios, funciones o lo que fuere.
\vskip 1cm\pause
Lo importante son las operaciones y las propiedades que satisfacen.




\end{frame}  


\begin{frame}
\begin{definicion}

Un \textit{espacio vectorial (sobre $\K$)} o un \textit{$\K$-espacio vectorial} es un conjunto $V$ que tiene dos operaciones que satisfacen ciertos axiomas. Llamaremos a los elementos de $V$ \textit{vectores}. 
\end{definicion}\pause
    \vskip .2cm 
\textbf{Operaciones}
\begin{itemize}
\item Suma de vectores: Dados $v,w\in V$ podemos formar el vector $v+w\in V$ ($+: V \times V \to V $).\pause
\item Producto por escalares: Dado $v\in V$ y $\lambda\in\K$ podemos formar el vector $\lambda\cdot v\in V$ ($\cdot: \K \times V \to V$).
\end{itemize}\pause
\vskip .2cm 

\textbf{Axiomas}\pause
\begin{itemize}
    \item $+$ es conmutativa, asociativa, existe neutro y opuesto\pause
    \item $\cdot$ es asociativa, distributiva y tiene neutro.
\end{itemize}
    
\end{frame}



\begin{frame}

    Explícitamente, sean $u,v,w\in V$ y $\lambda,\mu\in\K$, los axiomas son\pause
    \vskip .3cm
    \begin{tabular}{lll}
        \textbf{S1.}&$v + w = w + v$ &(\textit{$+$ conmutativa}) \\
        &&\\
        \textbf{S2.}& $(v+ w)+ u = v + (w+u)$ &(\textit{$+$ asociativa}). \\
        &&\\
        \textbf{S3.}& $\exists !$ vector $0$, tal que  $0+ v = v$\quad& (\textit{neutro de la $+$}). \\
        &&\\
        \textbf{S4.}& $\exists !$ $-v$ tal que  $v + (-v) =0$ &(\textit{opuesto}) \\
        &&\\
        \textbf{P1.}& $1\cdot v=v$ para todo $v \in V$& (\textit{neutro de $\cdot$}) \\
        &&\\
        \textbf{P2.}& $\lambda\cdot (\mu \cdot v) = (\lambda\mu )\cdot v$& (\textit{$\cdot$ asociativo}). \\
        &&\\
        \textbf{D1.}& $\lambda\cdot (v+w) = \lambda \cdot v +\lambda \cdot w$& (\textit{propiedad distributiva 1}) \\
        &&\\
        \textbf{D2.}& $(\lambda+\mu )\cdot v = \lambda \cdot v + \mu \cdot  v$ & (\textit{propiedad distributiva 2})
    \end{tabular}
    
\end{frame}

\begin{frame}

\begin{block}{Convenciones}\pause
\begin{itemize}
    \item $\lambda v=\lambda\cdot v$\pause
    \item $-v$ se llama el \textit{opuesto} de $v$\pause
    \item Gracias a la asociatividad de $+$ y $\cdot$ podemos obviar los paréntesis\pause
    \item $w-v=w+(-v)$, en palabras ``$w$ menos $v$'' significa ``$w$ más el opuesto de $v$''
    
    También denotamos $-v + w = (-v) +w$.
\end{itemize}
\end{block}


\end{frame}

\begin{frame}

\begin{block}{Ejemplo}\pause
Podemos comprobar  que $\R$  es un $\R$-espacio vectorial con la suma y la multiplicación usuales  viendo que los axiomas de espacios vectoriales son un subconjunto de los axiomas de los números reales. 
\end{block}
\vskip .4cm

\begin{block}{Ejemplo} Respecto a los número complejos:
    \begin{itemize}
        \item $\C$  es un $\C$-espacio vectorial. 
        \item $\C$ es un $\R$-espacio vectorial. 
        \item $\R$ \textit{no} es un $\C$-espacio vectorial con la suma y multiplicación usuales. ($i\cdot 1 = i \not\in \R$). 
    \end{itemize}
\end{block}
    
\end{frame}

    
\begin{frame}
    \begin{ejemplo}
        $\R^n$  es un $\R$-espacio vectorial con 
        \begin{align*}
            (x_1,\ldots,x_n) + (y_1,\ldots,y_n) &= (x_1+y_1,\ldots,x_n+y_n)&&(x_i,y_i \in \R) \\
            \lambda \cdot (x_1,\ldots,x_n) &= (\lambda x_1,\ldots,\lambda x_n)&&(\lambda \in \R).
        \end{align*}

        El  hecho  de que $\R^n$  es un $\R$-espacio vectorial con estas operaciones  fue probado en clases anteriores. 
        
        \vskip 3cm
    \end{ejemplo}
\end{frame}   
\begin{frame}

\begin{block}{Ejemplo}\pause
El conjunto de matrices $\K^{m\times n}$ es un espacio vectorial con las operaciones que definimos previamente.
\end{block}
\pause
\begin{block}{}
Si $A,B\in\K^{m\times n}$ y $\lambda\in\K$ entonces
\begin{itemize}
    \item $A+B$ es la matriz con entradas $[A+B]_{ij}=[A]_{ij}+[B]_{ij}$
    \item $\lambda\cdot A$ es la matriz con entradas $[\lambda A]_{ij}=\lambda[A]_{ij}$
\end{itemize} 
\end{block}
\pause
Ya hemos visto que estas operaciones satisfacen los axiomas de la definición. En particular
\pause
\begin{block}{}
\begin{itemize}
    \item El elemento neutro $0$ es la matriz con todas las coordenadas iguales a cero,\pause
    \item El opuesto de $A$ es la matriz $(-1)\cdot A$
\end{itemize} 
\end{block}
\end{frame}


\begin{frame}

\begin{block}{Ejemplo}
El conjunto de vectores filas $\K^{1\times n}$  (o columnas $\K^{n\times 1}$) es un espacio vectorial con las operaciones que hemos definido anteriormente en esta clase.\pause
\begin{itemize}
    \item La suma coordenada a coordenada
    \item La multiplicación coordenada a coordenada
\end{itemize}



\end{block}
\pause
\begin{block}{}
Es un caso particular de las matrices. 
\end{block}

    
\end{frame}



\begin{frame}

\begin{block}{Ejemplo}
El conjunto de polinomios sobre $\K$
\begin{align*}
\K[x]=\{a_nx^n+\cdots +a_1 x+a_0\mid n\in\N,\, a_n, ..., a_0\in\R\} 
\end{align*}
con la suma y multiplicación que ya conocen:\pause
\end{block}

\begin{block}{}
\begin{itemize}
    \item Suma coeficiente a coeficiente
    \begin{multline*}
    (a_nx^n+\cdots +a_1 x+a_0)+(b_nx^n+\cdots +b_1 x+b_0)=\\
    = (a_n+b_n)x^n+\cdots +(a_1+b_1) x+(a_0+b_0)
    \end{multline*}

    \pause

    \item Multiplicación coeficiente a coeficiente
    \begin{multline*}
    \lambda\cdot (a_nx^n+\cdots +a_1 x+a_0)
    =(\lambda a_n)x^n+\cdots +(\lambda a_1) x+(\lambda a_0)
    \end{multline*}
\end{itemize}
    
\end{block}

    
\end{frame}




\begin{frame}


\begin{block}{}

\begin{itemize}
    \item El neutro es el polinomio  $0$.
    \vskip .4cm\pause
    \item El opuesto del polinomio $a_nx^n+\cdots +a_1 x+a_0$ es el polinomio 
    \begin{align*}
    (-a_n)x^n+\cdots +(-a_1) x+(- a_0) = -a_nx^n -\cdots -a_1 x- a_0.
    \end{align*}
    \end{itemize}
    
    \pause
\end{block}
\begin{block}{Observación}
    \begin{itemize}
        \item Si $x^i$ no aparece en la expresión de un polinomio quiere decir que respectivo coeficiente $a_i$ es cero. Por ejemplo:
        \begin{align*}
        x^2+1=x^2+0x+1 
        \end{align*}\pause
    \item Para sumar polinomios no es necesario que tengan el mismos grado. Por ejemplo:
    \begin{align*}
    (x^2+1)+(x^5+2x^2+5x+2)=x^5+3x^2+5x+3
    \end{align*}
    
    
    \end{itemize}
    
    
    
    \end{block}
    
\end{frame}


\begin{frame}

\begin{block}{Ejemplo}

Sea $X$ un conjunto. El \textit{espacio vectorial de funciones de $X$ a $\R$} es el conjunto
\begin{align*}
\R^X=\left\{\mbox{las funciones }f:X\longrightarrow\R\right\}
\end{align*}
con la suma y producto por escalar ``punto a punto''. 
\vskip .4cm\pause


\end{block}

\begin{block}{}
    Es decir, si $f, g \in \R^X$ y $\lambda \in \R$, 
    \vskip .4cm
\begin{itemize}
    \item $f+g:X\longrightarrow\R$ es la función definida por
    \begin{align*}
    (f+g)(x)=f(x)+g(x)
    \end{align*}\pause
\item $\lambda\cdot f:X\longrightarrow\R$ es la función definida por
    \begin{align*}
    (\lambda\cdot f)(x)=\lambda f(x)
    \end{align*}
\end{itemize}

    
\end{block}

    
\end{frame}

\begin{frame}

Si $f,g:X\longrightarrow\R$ y $\lambda\in\R$ entonces
\begin{itemize}
    \item el opuesto de $f$ es $-f:X\longrightarrow\R$, la función definida por
    \begin{align*}
    (-f)(x)=-f(x)
    \end{align*}\pause
\item El elemento neutro es la función constante igual a cero, es decir $f(x) =0$ para todo $x \in X$. la cual denotamos $0$
\end{itemize}

\vskip .4cm \pause
\begin{block}{Observación}
Si $X=\R$ entonces la suma y el producto por escalar es la misma definición que se usa en Análisis Matemático I.

\vskip .2cm 
En este caso se suele denotar $F(\R)=\R^\R$
\end{block}


\end{frame}


\begin{frame}

\begin{block}{Ejemplo}

El conjunto de los números reales positivos
$\R_{>0}=(0,\infty)$ es un espacio vectorial con las siguientes operaciones:
\begin{itemize}
    \item $x\oplus y=x\cdot y$ ($\oplus$ es la multiplicación)
    \item $\lambda\odot x=x^\lambda$ ($\odot$ es la potenciación)


    \item El ``neutro'' es el $1$: $1\oplus x=1\cdot x=x$
    \item El ``opuesto'' es el inverso: $x^{-1}\oplus x=x^{-1}\cdot x=1$
\end{itemize}
\end{block}
\pause
\begin{observacion}
    \begin{itemize}
        \item Definición  
        $$x^\lambda := e^{\lambda\ln(x)} = \sum_{n=0}^\infty \frac{(\lambda\ln(x))^n}{n!}.$$
        \item Probemos \textbf{D2}: \pause
        $$ (\lambda + \mu )\odot x = x^{\lambda + \mu} = x^{\lambda}x^{\mu} = 
        x^{\lambda}\oplus x^{\mu} =  \lambda\odot x \oplus \mu\odot x.\qed
        $$
    \end{itemize}
    
\end{observacion}
\end{frame}


\begin{frame}
\begin{block}{Proposición}
Sea $V$ un espacio vectorial sobre $\K$. Entonces\pause
\begin{enumerate}
    \item $\lambda\cdot 0=0$ para todo $\lambda\in \K$\pause
    \item $0\cdot v=0$ para todo $v\in V$\pause
    \item Si $\lambda\cdot v=0$ entonces $\lambda=0$ ó $v=0$\pause
    \item $(-1)\cdot v=-v$, en palabras, $-1$ por $v$ es igual al opuesto de $v$
\end{enumerate}
\end{block}
\pause
\begin{block}{Observación}
La demostración es similar  a las propiedades análogas de los números reales  o los números enteros dado que lo único que usamos son los axiomas.
\end{block}

\end{frame}

\begin{frame}
\begin{block}{Demostración 1.}\pause
\begin{itemize}
    \item $\lambda\cdot 0=0$ para todo $\lambda\in \R$ 
\end{itemize}
\begin{align*}
\lambda\cdot 0&= \lambda\cdot (0+0)&\quad (\mbox{axioma elemento neutro})\\
\lambda\cdot 0&=\lambda\cdot 0+\lambda\cdot 0
&\quad (\mbox{axioma distributividad})\\
\Rightarrow 0&=\lambda\cdot0
&\quad (\mbox{sumando el opuesto de $\lambda\cdot 0$})
\end{align*}

\end{block}
\pause
\begin{block}{Demostración 2.}\pause
\begin{itemize}
    \item $0\cdot v=0$ para todo $v\in V$
\end{itemize}
    es similar a la anterior. 
\end{block}
\end{frame}


\begin{frame}

    \begin{block}{Demostración 3.}\pause
\begin{itemize}
    \item Si $\lambda\cdot v=0$ entonces $\lambda=0$ ó $v=0$

\end{itemize}
\vskip .2cm
Si $\lambda=0$ no hay nada que demostrar. 
\vskip .2cm
Supongamos que $\lambda\neq0$. Sea $\lambda^{-1}\in\R$ su inverso multiplicativo.
\begin{align*}
\lambda^{-1}\cdot 0&=\lambda^{-1}\cdot(\lambda\cdot v)&&\mbox{(por hipótesis)}\\
0&=(\lambda^{-1}\lambda)\cdot v&\quad&\mbox{(asociatividad)}\\
0&=1\cdot v&&\\
0&=v&\quad&\mbox{(axioma neutro)}
\end{align*}
\end{block}
\end{frame}

\begin{frame}

    \begin{block}{Demostración 4.}\pause
\begin{itemize}
    \item $(-1)\cdot v=-v$, en palabras, $-1$ por $v$ es igual al opuesto de $v$
\end{itemize}
\begin{align*}
0&=0\cdot v&&\text{(por 2.)}\\
0&=(1+(-1))v&&\text{}\\
0&=1\cdot v+(-1)\cdot v&&\text{(distributividad)}\\
0&=v+(-1)\cdot v&&\text{(elemento neutro $\cdot$)}\\
-v+0&=-v+ v+(-1)\cdot v&&\text{(sumo $-v$ a ambos miembros)}\\
-v&= 0 +(-1)\cdot v&&\text{(elemento neutro $+$ y opuesto)}\\
-v&=(-1)\cdot v&&\text{(elemento neutro $+$)}
\end{align*}
\end{block} \qed
\end{frame}

\begin{frame}{Subespacios vectoriales}

    \pause
    \begin{definicion}
        Sea $V$ un espacio vectorial sobre $\K$. diremos que $W \subset V$ es \textit{subespacio de $V$}\index{subespacio} si $W \not= \emptyset$ y
        \begin{enumerate}
            \item[(a)] si para cualesquiera $w_1,w_2 \in W$, se cumple que $w_1+w_2 \in W$ y
            \item[(b)] si $\lambda \in \K$ y  $w \in W$, entonces $\lambda w \in W$.
        \end{enumerate}
    \end{definicion}
\vskip .4cm\pause
    \begin{observacion} Si $W$ subespacio de  $V$.
        \begin{itemize}
            \item $0 \in W$.
            \item Si $w \in W$,  entonces $-w \in W$.  
        \end{itemize}
        
    \end{observacion}
\end{frame}

\begin{frame}

\begin{block}{Demostración $0 \in W$.}\pause
    Como $W \ne \emptyset$, existe $w \in W$. Por la condición (b), $0\cdot w \in W$. Ahora bien,  hemos visto que $0\cdot w =0$, por lo tanto $0 \in W$.
\end{block}
\pause
\begin{block}{Demostración $-w \in W$.}\pause
    Por la condición (b), $(-1)\cdot w \in W$. Ahora bien,  hemos visto que $(-1)\cdot w =-w$, por lo tanto $-w \in W$.
\end{block}
\vskip 2cm


\end{frame}

\begin{frame}
    \begin{observacion}
        Sea $W \subset V$,   $W \ne \emptyset$. Entonces
        \begin{center}
            $W$ subespacio de $V$\quad $\Leftrightarrow$\quad  $u + \lambda w \in W$,\;  $\forall\,u,w \in W,\lambda \in \K$.
        \end{center}
    \end{observacion}
    \pause
    \begin{demostracion}\pause

    ($\Rightarrow$) \pause
    \begin{itemize}
        \item  Por (b) de la definición, $\lambda w \in W$.
        \item  Como $u \in W$ y  $\lambda w \in W$, por (a)  de la definición  $u + \lambda w \in W$.
    \end{itemize}
    \pause

    ($\Leftarrow$) \pause
    
    \begin{itemize}
        \item[(a)] Sean $w_1 , w_2 \in W$, luego $w_1 + 1 \cdot w_2 = w_1 +w_2 \in W$.
        \item[(b)] Sea $\lambda \in \K$ y $w \in W$, entonces $0 + \lambda w = \lambda w \in W$.
    \end{itemize}
    \qed
    

    

    \end{demostracion}
\end{frame}

\begin{frame}

    \begin{teorema}
        Sea $V$ un espacio vectorial sobre $\K$ y $W$ subespacio de $V$. Entonces $W$ con las operaciones suma y producto por escalares de $V$ es un espacio vectorial.
    \end{teorema}\pause
    \begin{proof} \pause
        Para que $W$ sea espacio vectorial sus operaciones deben satisfacer los axiomas de la definición de espacio vectorial. 

        \vskip .2cm
        
        $0 \in W$ y si   $w \in W$ $\Rightarrow$  $-w \in W$.
        
        \vskip .2cm         
        Teniendo en cuenta estos dos hechos,  y que las operaciones en $V$ satisfacen los axiomas de la definición (y por lo tanto en $W$ también),  queda demostrado que $W$, con las operaciones heredadas de $V$, es espacio vectorial.\qed  
        
    \end{proof}

\end{frame}

\begin{frame}{Ejemplos}
    \begin{enumerate}\pause
        \item Sea $V$ un $\K$-espacio vectorial, entonces $\{0\}$ (que se denota $0$) y $V$ son subespacios vectoriales de $V$. Suelen ser llamados los \textit{subespacios triviales}\index{subespacios triviales} de $V$.
        \vskip .4cm \pause
        \item Sea $V$ un $\K$-espacio vectorial y sea $v \in V$, entonces
        $$
        W = \{\mu v: \mu \in \K \}
        $$
        es un subespacio vectorial.
        \vskip .3cm 
        En  efecto, si $\mu_1v,\mu_2v \in W$, con $\mu_1,\mu_2 \in \K$,  entonces 
        $$\mu_1v + \lambda \mu_2v = (\mu_1+\lambda\mu_2)v \in W, $$
        para todo $\lambda\in \K$.
        \pause
        \vskip .4cm 
        El subespacio $W$ suele ser denotado $\K v$.
    \end{enumerate}
\end{frame}



\begin{frame}{Ejemplos}
    \begin{enumerate}     

        \item[3.] Sea $A \in M_{m \times n}(\K)$. Si $x = (x_1,\ldots,x_n) \in \K^n$,  entonces $Ax$ denota
        $$
        Ax := A\begin{bmatrix} x_1 \\ \vdots \\ x_n\end{bmatrix}.
        $$
        Sea 
        $$
        W = \left\{x \in \K^n: Ax=0 \right\}.
        $$
        Es decir, $W$  es el subconjunto de las soluciones del sistema $Ax=0$. 
        \vskip .2cm
        
        Entonces, $W$  es un subespacio de $\K^n$:\pause sean $x,y \in W$ y $\lambda \in \K$, es decir $Ax=0$, $Ay=0$ y $\lambda \in \K$,  entonces 
        $$
        A(x+\lambda y) = Ax + A(\lambda y) = Ax + \lambda Ay = 0 + \lambda \cdot 0 =0.$$ 
    \end{enumerate}
\end{frame}

\begin{frame}
    Es decir 
    \vskip .4cm
    \textit{El conjunto de soluciones de un sistema de ecuaciones homogéneo es un subespacio vectorial de $\K^m$,}
    \vskip .4cm\pause
    En particular, 
    \vskip .2cm
    \begin{itemize}
        \item Las rectas en el plano que pasan por el origen son subespacios de $\R^2$.
        \vskip .2cm
        \item Los planos en el espacio que pasan por el origen son subespacios de $\R^3$.
    \end{itemize}
    


\end{frame}




\begin{frame}{Resumen}

    En esta clase veremos que
    \begin{itemize}
    \item más ejemplos de subespacios, 
        \item combinaciones lineales de vectores,
        \item vectores generadores de subespacios,  y
        \item haremos algunos ejemplos.
    \end{itemize}
    

\

El tema de esta clase  está contenido de la sección 3.2 del apunte de clase ``Álgebra II / Álgebra - Notas del teórico''.
\end{frame}


    \begin{frame}{Ejemplos de subespacio vectoriales}
    
    
        \begin{enumerate}     
            \item[4.] Sean $V=\K^n$ y $1\le j \le n$. Definimos 
            $$
            W = \left\{ (x_1,x_2,\ldots,x_n): x_i \in \K\; (1 \le i \le n), x_j =0\right\}.
            $$
            Es decir $W$  es el subconjunto de $V$ de todas las $n$-tuplas con la coordenada $j$ igual a 0. Por ejemplo  si $j=1$ 
            $$
            W = \left\{ (0,x_2,\ldots,x_n): x_i \in \K \;(2 \le i \le n)\right\}.
            $$
            \pause
            Veamos que este último es un subespacio.
            
            Si $(0,x_2,\ldots,x_n), (0,y_2,\ldots,y_n) \in W$ y  $\lambda \in \K$,  entonces
            $$(0,x_2,\ldots,x_n)+ \lambda(0,y_2,\ldots,y_n) = (0,x_2+\lambda y_2,\ldots,x_n+\lambda y_n) \in W.$$
            
            
            La demostración para $j >1$ es completamente análoga. 
        \end{enumerate}

    
    \end{frame}
    

    
    
    

    \begin{frame}
        \begin{enumerate}     
            \item[5.] Sea $\operatorname{Sim}_n(\K) = \left\{A \in M_n(\K): A^\t = A\right\}$.    \pause
            \vskip .2cm 
            Es claro que: \quad   $A \in \operatorname{Sim}_n(\K)$ $\Leftrightarrow$  $[A]_{ij} = [A]_{ji}\; \forall i,j $.     \pause
            \vskip .3cm
            \begin{proposicion}
                $A \in \operatorname{Sim}_n(\K)$ es subespacio de $M_n(\K)$
            \end{proposicion}    \pause
            \begin{demostracion}    \pause
            Sean $A=[a_{ij}]$, $B= [b_{ij}]$ tales que $A=A^\t$ y $B=B^\t$ y sea  $\lambda \in \K$, entonces debemos verificar que:\quad  $A+ \lambda B \in  \operatorname{Sim}_n(\K)$.
                \begin{align*}
                    [(A+\lambda B)^\t]_{ij} &=  [(A+\lambda B)]_{ji}&& (\text{definición de transpuesta}) \\
                    &= [A]_{ji} + \lambda [B]_{ji}&& (\text{def. de suma y prod. por escalar}) \\
                    &= [A]_{ij} + \lambda [B]_{ij}&& (\text{$A$ y $B$ simétricas}) \\
                    &= [A+ \lambda B]_{ij}&& (\text{def. de suma y prod. por escalar}) \\
                \end{align*}
        Luego $A+\lambda B\in \operatorname{Sim}_n(\K) $.\qed
            \end{demostracion}
        \end{enumerate}
    \end{frame}
    
    

    
    

    \begin{frame}
        \begin{enumerate}     
        \item[6.] El  conjunto $\R[x] = \left\{P(x): P(x) \text{ es polinomio en $\R$} \right\}$, es subespacio de $\operatorname{F}(\R)$, pues $\R[x] \subset \operatorname{F}(\R)$ y las operaciones de suma y producto por un escalar son cerradas en $\R[x]$.
        \vskip .4cm     \pause
        \item[7.] Sea $\operatorname{C}(\R)$ las funciones continuas de $\R$ en $\R$. Entonces, $\operatorname{C}(\R)$ es subespacio de $\operatorname{F}(\R)$.     \pause
        \begin{demostracion}
            Sean $f,g$ funciones continuas, es decir $\lim_{x \to a} f(x) = f(a)$ y $\lim_{x \to a} g(x) = g(a)$, $\forall a \in \R$. Sea $\lambda \in \R$.  Por las propiedades de los límites 
            $$
            \lim_{x \to a} (f + \lambda g)(x) =  \lim_{x \to a} f + \lambda \lim_{x \to a} g(x) = f(a) + \lambda g(a) = 
            (f + \lambda g)(a)
            $$\qed
        \end{demostracion} 
        
        \pause
        De forma análoga, el conjunto $\R[x]$ es subespacio de $\operatorname{C}(\R)$.
        \end{enumerate}
    \end{frame}
    
\begin{frame}{Combinaciones lineales}
    \begin{definicion}
        Sea $V$ espacio vectorial sobre $\K$ y $v_1,\ldots,v_n$ vectores en $V$. Dado $v \in V$, diremos que\textit{ $v$  es combinación lineal de los $v_1,\ldots,v_n$ }\index{combinación lineal} si existen escalares $\lambda_1,\ldots,\lambda_n$ en $\K$,  tal que 
        $$
        v = \lambda_1v_1+\cdots+\lambda_nv_n.
        $$
    \end{definicion}
    
    \vskip 2cm
\end{frame}


\begin{frame}
    

\begin{ejemplo}
    
    Sean $v_1 = (1,0)$, $v_2 = (0,1)$ en $\C^2$ ¿es $v = (i,2)$ combinación lineal de $v_1,v_2$?    \pause La respuesta es sí, pues 
        $$
        v = iv_1+2v_2.
        $$    \pause
        Observar además que es la única combinación lineal posible, pues si 
        $$
        v = \lambda_1v_1+ \lambda_2 v_2,
        $$
        entonces
        $$
        (i,2) = (\lambda_1,0)+(0,\lambda_2) = (\lambda_1,\lambda_2),
        $$
        luego $\lambda_1=i$ y $\lambda_2= 2$.
        

\end{ejemplo}
\end{frame}


\begin{frame}

\begin{ejemplo}
    Puede ocurrir que un vector sea combinación lineal de otros vectores de varias formas diferentes. Por ejemplo,   si   $v = (i,2)$ y $v_1 = (1,0)$, $v_2 = (0,1)$, $v_3 = (1,1)$,  tenemos que
        \begin{align*}
            v &= iv_1+2v_2+0v_3,\quad\quad\quad\text{y también}\\
            v &= (i-1)v_1 + v_2 + v_3.  
        \end{align*}
\end{ejemplo}
\pause
\begin{ejemplo}
        Sean $(0,1,0)$, $(0,1,1)$ en $\C^3$ ¿es $(1,1,0)$ combinación lineal de $(0,1,0)$, $(0,1,1)$? La respuesta es no, pues si 
        $$
        (1,1,0) = \lambda_1(0,1,0)+ \lambda_2(0,1,1) = (0,\lambda_1,0)+ (0,\lambda_2,\lambda_2) = (0,\lambda_1+\lambda_2,\lambda_2),
        $$ 
        luego, la primera coordenada nos dice que $1=0$, lo cual es absurdo. 
        
\end{ejemplo}
    
    
\end{frame}
    


\begin{frame}

\definecolor{airforceblue}{rgb}{0.36, 0.54, 0.66}
\hfsetfillcolor{airforceblue!30}
\hfsetbordercolor{blue!10}


    \begin{block}{Observación (muy importante)}\label{obs-muy-importante}
        ¿Es $v =(b_1,\ldots,b_m) \in \K^m$  c. l. de vectores $v_1,\ldots,v_n \in \K^m$? 
        \vskip .3cm     \pause
        Sea $v_i = (a_{1i},\ldots,a_{mi})$ $(1 \le i \le n)$, entonces $v = \lambda_1v_1 + \cdots +\lambda_nv_n$ $\Rightarrow$
        \begin{align*}
            (b_1,\ldots,b_m) &= \lambda_1(a_{11},\ldots,a_{m1}) + \cdots +\lambda_n(a_{1n},\ldots,a_{mn}) \\
            &= (\lambda_1a_{11} + \cdots+ \lambda_na_{1n}, \,\ldots,\, \lambda_1a_{m1} + \cdots+ \lambda_na_{mn}).
        \end{align*}    \pause
        Luego, 
        \begin{center}
            \tikzmarkin{a}(0.2,-0.3)(-0.2,0.5) {$v$  es combinación lineal de los vectores $v_1,\ldots,v_n \in \K^m$} \tikzmarkend{a}
        \end{center}
            si y sólo si tiene solución el siguiente sistema de ecuaciones: 
        \begin{equation*}
            \tikzmarkin{b}(0.2,-0.8)(-0.2,1) 
        \begin{matrix}
        a_{11}\lambda_1& + &a_{12}\lambda_2& + &\cdots& + &a_{1n}\lambda_n &= &b_1\\
        \vdots&  &\vdots& &&  &\vdots \\
        a_{m1}\lambda_1& + &a_{m2}\lambda_2& + &\cdots& + &a_{mn}\lambda_n &=&b_m.
        \end{matrix}
        \tikzmarkend{b}
        \end{equation*}
        
    \end{block}
    
    
\end{frame}
    
    
\begin{frame}
    
    \begin{ejemplo} Demostrar que $(5,12,5)$  es combinación lineal de los vectores $(1,-5,2), (0,1,-1), (1,2,-1)$. 
    \end{ejemplo}    \pause
        \vskip .2cm
        
        \begin{solucion}  \pause
            Planteamos la ecuación:
        \begin{align*}
            (5,12,5) &= \lambda_1(1,-5,2)+\lambda_2 (0,1,-1)+\lambda_3 (1,2,-1) \\
            &= (\lambda_1,-5\lambda_1,2\lambda_1)+ (0,\lambda_2,-\lambda_2)+(\lambda_3 ,2\lambda_3 ,-\lambda_3 )	\\
            &= (\lambda_1+\lambda_3,-5\lambda_1+\lambda_2+2\lambda_3,2\lambda_1-\lambda_2-\lambda_3).
        \end{align*}  \pause
        Por consiguiente,  esta ecuación se resuelve con el siguiente sistema de ecuaciones
        \vskip -.6cm
        \begin{align*}
            \lambda_1+\lambda_3 &= 5 \\
            -5\lambda_1+\lambda_2+2\lambda_3 &= 12 \\
            2\lambda_1-\lambda_2-\lambda_3 &= 5.
        \end{align*}
        \end{solucion}
        
    


\end{frame}


\begin{frame}
    Ahora bien, usando el método de Gauss
    \begin{multline*}
\left[\begin{array}{rrr|r}1 & 0 & 1 &  5 \\ -5 & 1 & 2 &  12 \\	2 & -1 & -1 &  5  \end{array}\right]
\stackrel[F_3 -2F_1]{F_2 + 5F_1}{\longrightarrow} 
\left[\begin{array}{rrr|r}1 & 0 & 1 &  5 \\ 0 & 1 & 7 &  37 \\	0 & -1 & -3 &  -5  \end{array}\right]
\\ \stackrel{F_3+F_1}{\longrightarrow}
\left[\begin{array}{rrr|r}1 & 0 & 1 &  5 \\ 0 & 1 & 7 &  37 \\	0 & 0 & 4 & 32  \end{array}\right]
\stackrel{F_3/4}{\longrightarrow} 
\left[\begin{array}{rrr|r}1 & 0 & 1 & 5 \\ 0 & 1 & 7 & 37 \\	0 & 0 & 1& 8  \end{array}\right]
\\ \stackrel[F_2 -7F_3]{F_1 - F_3}{\longrightarrow}
\left[\begin{array}{rrr|r}1 & 0 & 0 & -3 \\ 0 & 1 & 0 &  -19 \\	0 & 0 & 1& 8  \end{array}\right].
\end{multline*}	  \pause
Luego $\lambda_1= -3$, $\lambda_2 = -19$ y $\lambda_3=8$,  es decir
\begin{align*}
(5,12,5) &= -3(1,-5,2)-19 (0,1,-1)+8 (1,2,-1).\qed
\end{align*}
\end{frame}
                    
\begin{frame}
    \begin{proposicion}
        Sea $W$ subespacio de $V$ y $w_1,\ldots,w_k \in W$,  entonces cualquier combinación lineal de los $w_1,\ldots,w_k$ pertenece a $W$.
    \end{proposicion}  \pause

    \begin{demostracion}  \pause
        Debemos probar que, para cualesquiera $\lambda_1,\ldots,\lambda_k \in \K$, se cumple que  $\lambda_1w_1+\cdots+\lambda_kw_k \in W$. 
            \vskip .2cm
            
            Ahora bien,  como $W$ es subespacio, $\lambda_iw_i \in W$ para $1\le i \le k$. 
            
            \vskip .2cm
            Por un argumento inductivo, como $W$  es subespacio, no es difícil probar que la suma de $k$ términos en $W$ es un elemento de $W$, por lo tanto $\lambda_1w_1+\cdots+\lambda_kw_k \in W$. 
            
            \qed
    \end{demostracion}
            
\end{frame}

                            
    

\begin{frame}

\begin{teorema}
    Sea $V$ un espacio vectorial sobre $\K$ y sean $v_1,\ldots,v_k \in V$. Entonces
    $$
    W = \{\lambda_1v_1+\cdots+\lambda_kv_k: \lambda_1,\ldots,\lambda_k \in \K \}
    $$
    es un subespacio vectorial. Es decir,  el conjunto de las combinaciones lineales de $v_1,\ldots,v_k$ es un subespacio vectorial.
    \end{teorema}  \pause
    \begin{proof}  \pause
                Sean $\lambda_1v_1+\cdots+\lambda_kv_k$, $\mu_1v_1+\cdots+\mu_kv_k$ dos combinaciones lineales de $v_1,\ldots,v_k$ y $\lambda \in \K$, entonces 
            \begin{align*}
                (\lambda_1v_1+\cdots+\lambda_kv_k)&+\lambda (\mu_1v_1+\cdots+\mu_kv_k) \\&=  \lambda_1v_1+\lambda\mu_1v_1+\cdots+\lambda_kv_k+\lambda\mu_kv_k\\
                &= (\lambda_1+\lambda\mu_1)v_1+\cdots+(\lambda_k+\lambda\mu_k)v_k,
            \end{align*}
            que es  una combinación lineal de  $v_1,\ldots,v_k$ y por lo tanto pertenece a $W$. 
            
            \qed
    \end{proof}
    
\end{frame}

        

\begin{frame}

\begin{definicion}
    Sea $V$ un espacio vectorial sobre $\K$ y sean $v_1,\ldots,v_k \in V$. Al  subespacio vectorial $	W = \{\lambda_1v_1+\cdots+\lambda_kv_k: \lambda_1,\ldots,\lambda_k \in \K \}$ de las combinaciones lineales de $v_1,\ldots,v_k$ se lo denomina \textit{subespacio generado por $v_1,\ldots,v_k$}\index{subespacio generado} y se lo denota  
    \begin{equation*}
        W \; = \; \langle v_1,\ldots,v_k \rangle \; = \; \operatorname{gen}\left\{ v_1,\ldots,v_k\right\}  \; = \;  \operatorname{span}\left\{ v_1,\ldots,v_k\right\}.
    \end{equation*}  \pause
    Además, en este caso, diremos que el conjunto $S = \left\{ v_1,\ldots,v_k \right\}$ \textit{genera} al subespacio $W$ o que los vectores $v_1,\ldots,v_k$ \textit{generan} $W$. 
    \vskip .2cm 
\end{definicion}  \pause
    \begin{observacion}
        Un caso especial,  que será de suma importancia,  es el caso en que consideramos todo $V$. 

        \vskip .2cm
        \pause
        Estudiaremos en las clases que siguen conjuntos de generadores de $V$ llamados \textit{bases}, que tienen la propiedad de que todo vector de $V$  se escribe de una única forma como c.l.  de los generadores.  
        
    \end{observacion}

\end{frame}



\begin{frame}{Resumen}

    En esta clase veremos 
    \begin{itemize}
        \item como determinar un subespacio vectorial de $\K^n$ en forma implícita a partir de vectores que lo generan.

        \end{itemize}\pause
        \vskip .4cm 
Además,  veremos que

        \begin{itemize}
                \item la intersección de subespacios vectoriales es subespacio vectorial, \pause
                \item la suma de subespacios vectoriales es subespacio vectorial, \pause
                \item propiedades de las suma e intersección de subespacios, y\pause
                \item dependencia lineal. 
            \end{itemize}
    
            \pause
    \
    
    El tema de esta clase  está contenido de la sección 3.3 del apunte de clase ``Álgebra II / Álgebra - Notas del teórico''.
    \end{frame}
    


    \begin{frame}{Determinación ``implícita'' de un subespacio de $\K^n$}
    
        Nos interesa tener una manera de decidir rápidamente si un vector esta en el subespacio generado o no.
        \pause

        \
        
        Una forma sencilla de verificar si un vector pertenece a un subespacio $W \subseteq\K^n$ es obtener la descripción del  subespacio por un sistema de ecuaciones lineales homogéneas,  es decir 
        \begin{equation*}
            W = \{v \in \K^n: Av =0\},
        \end{equation*} 
        o equivalentemente
        \begin{equation*}
            v \in W \quad \Leftrightarrow \quad Av =0.
        \end{equation*} 
        
        Entonces comprobar si un vector $v$ pertenece o no a $W$  se reduce a calcular $Av$. 
        \pause

        \
        
        (Ejercicios 7 y 9 del Pr\'actico 6)
        \vskip 2cm
        \end{frame}
        
        
        \begin{frame}
        Ejemplificaremos con los siguientes vectores en $\R^4$:
        \begin{align*}
        v_1=(3,1,2,-1),&\quad
        v_2=(6,2,4,-2),\\
        v_3=(3,0,1,1),&\quad
        v_4=(15,3,8,-1)
        \end{align*}
        \pause

        \begin{exampleblock}{Problema}\pause
        
        Caracterizar mediante ecuaciones el subespacio $\langle v_1, v_2, v_3, v_4\rangle$.
        
        \pause
        
        \
        
        En otras palabras, queremos describir implícitamente el conjunto de los $b=(b_1,b_2,b_3,b_4)
        \in\R^4$ tales que $b\in\langle v_1, v_2, v_3, v_4\rangle$.
        
        \

        \pause
        O sea, los $b=(b_1,b_2,b_3,b_4)
        \in\R^4$ tales que 
        \begin{equation*}
            b=\lambda_1v_1+\lambda_2v_2+\lambda_3v_3+\lambda_4v_4 \tag{*}
        \end{equation*}
        
        
        con $\lambda_1,\lambda_2,\lambda_3,\lambda_4\in\R$.
        \end{exampleblock}
        \end{frame}
        

        \begin{frame}
            Planteemos la fórmula (*) en coordenadas, pero es conveniente hacerlo con vectores columna :
            \begin{align*}
                \lambda_1 \begin{bmatrix*}[r] 
                    3\\
        1\\
        2\\
        -1
        \end{bmatrix*}+
        \lambda_2\begin{bmatrix*}[r] 
        6\\
        2\\
        4\\
        -2
            \end{bmatrix*}+
        \lambda_3
        \begin{bmatrix*}[r] 
        3\\
        0\\
        1\\
        1
    \end{bmatrix*}+\lambda_4
        \begin{bmatrix*}[r] 
        15\\
        3\\
        8\\
        -1
    \end{bmatrix*}=
        \begin{bmatrix*}[r] 
        b_1\\
        b_2\\
        b_3\\
        b_4
    \end{bmatrix*}
            \end{align*}
            
\pause Luego 

\begin{equation*}
    \begin{bmatrix*}[r]
        3\lambda_1+6\lambda_2+3\lambda_3+15\lambda_4\\
    \lambda_1+2\lambda_2+3\lambda_4\\
    2\lambda_1+4\lambda_2+ \lambda_3+8\lambda_4\\
    -x-2\lambda_2+\lambda_3-\lambda_4
    \end{bmatrix*}
    = 
    \begin{bmatrix}
        b_1\\ b_2 \\b_3 \\ b_4 
    \end{bmatrix}
\end{equation*}

        \end{frame}

        \begin{frame}
        
        En forma de producto de matrices podemos reescribirla asi:
        
        \begin{equation*}
            \begin{bmatrix*}[r]    
        3&6&3&15\\
        1&2&0&3\\
        2&4&1&8\\
        -1&-2&1&-1
    \end{bmatrix*}
        \begin{bmatrix*}[r]
        \lambda_1\\
        \lambda_2\\
        \lambda_3\\
        \lambda_4
    \end{bmatrix*}
        =
        \begin{bmatrix*}[r]
        b_1\\
        b_2\\
        b_3\\
        b_4 
    \end{bmatrix*}
    \end{equation*}
        
    \pause  En forma de sistema de ecuaciones esto es:
        
        \begin{equation*}
            \begin{cases}
                3\lambda_1+6\lambda_2+3\lambda_3+15\lambda_4 = b_1\\
            \lambda_1+2\lambda_2+3\lambda_4 = b_2\\
            2\lambda_1+4\lambda_2+ \lambda_3+8\lambda_4 = b_3\\
            -x-2\lambda_2+\lambda_3-\lambda_4 = b_4
            \end{cases}\tag{**}
        \end{equation*}

        \pause
        
        \begin{block}{Conclusión}
        $b\in\langle v_1,v_2,v_3,v_4\rangle$ si y s\'olo si el sistema anterior tiene soluci\'on.
        \end{block}
        
        \end{frame}
        
        \begin{frame}
        
        El  sistema (**) tiene solución si el siguiente sistema la tiene  (es cambio de notación solamente)
    
        \begin{equation*}
            \begin{cases}
                3x+6y+3z+15w=b_1\\
                x+2y+3w=b_2\\
                2x+4y+z+8w=b_3\\
                -x-2y+z-w=b_4
            \end{cases}
        \end{equation*}
        \vskip .4cm\pause
        Este es exactamente el Ejercicio 2 de la Tarea 2. Entonces la respuesta a nuestro problema es
        \vskip .3cm
        \begin{block}{Respuesta}
            \vskip -.8cm 
        \begin{multline*}
            \langle v_1, v_2, v_3, v_4\rangle=\\\{(b_1,b_2,b_3,b_4)\in\mathbb{R}^4\mid b_1+3b_2-3b_3=0,b_1-6b_2-3b_4=0\}.
        \end{multline*}
            
        
        \end{block}
        
        \end{frame}
        
        \begin{frame}
        Notemos que podemos repetir todo el razonamiento anterior para cualesquiera vectores $v_1, ..., v_k$ en cualquier $\R^n$ y cualquier $b\in\R^n$.\pause
        
        \
        
        Sólo hay que tener presente que multiplicar una matriz por un vector columna es lo mismo que hacer una combinación lineal de las columnas de la matriz:\pause
        
        \
        
        Es decir, si
        $$
        A=\left[
        \begin{array}{cccc}
        \mid& \mid& &\mid\\
        v_1 & v_2 & \cdots &v_k\\
        \mid& \mid& &\mid
        \end{array}
        \right]
        ,$$ 
        entonces
        \begin{align*}
        A\left[
        \begin{array}{c}
        \lambda_1\\\vdots\\\lambda_k
        \end{array}
        \right]=
        \lambda_1v_1+\cdots+\lambda_kv_k
        \end{align*}
        \end{frame}
        
        \begin{frame}
        
        \begin{block}{Conclusión}
            
            Sean $v_1, ..., v_k\in\K^n$ y $A\in\K^{n\times k}$ la matriz cuyas  columnas son los vectores $v_1, ..., v_k$, es decir
        $$
        A=\left[
        \begin{array}{cccc}
        \mid& \mid& &\mid\\
        v_1 & v_2 & \cdots &v_k\\
        \mid& \mid& &\mid
        \end{array}
        \right]
        .$$\pause
        
        Entonces
        \begin{itemize}
            \item El subespacio vectorial  $\langle v_1, ..., v_k\rangle$ es igual al conjunto de los $b\in\K^n$ para los cuales el sistema $AX=b$ tiene solución.
            \vskip .2cm
            \item Las ecuaciones vienen dadas por las filas nulas de la MERF equivalente a $A$. En particular, si no tiene filas nulas entonces $\langle v_1, ..., v_k\rangle=\K^n$ porque el sistema $AX=b$ siempre tiene solución.
        \end{itemize}
    \end{block}
        \end{frame}
        
    



    \begin{frame}{Intersección y suma de subespacios vectoriales}
    
        \begin{teorema}\label{th-interseccion}
            Sea $V$ un espacio vectorial sobre $\K$. Entonces la intersección de subespacios vectoriales es un subespacio vectorial. 
        \end{teorema}  \pause
    \begin{proof}  \pause
        Veamos el caso de la intersección de dos subespacios. 
        \vskip .2cm
        Debemos probar que si $W_1$, $W_2$ subespacios $\Rightarrow$ $W_1 \cap W_2$  es subespacio. 
        \vskip .2cm
        Observemos:\quad  $w \in W_1 \cap W_2 \quad \Leftrightarrow\quad w \in W_1 \;\wedge\; w \in W_2$.
    \begin{align*}
    \text{ Sea  $\lambda \in \K$. } u,v \in  W_1 \cap W_2\quad &\Rightarrow \quad u,v \in W_1 \;\wedge\; u,v \in W_2 \\
    &\Rightarrow \quad u+\lambda v \in W_1 \;\wedge\; u+\lambda v\in W_2\qquad\qquad\qquad\\
    &\Rightarrow\quad  u+\lambda v  \in W_1 \cap W_2. 
    \end{align*}
    
Luego $W_1 \cap W_2$  es subespacio.
\qed
    \end{proof}
    \end{frame}
    

    
\begin{frame}
    \begin{ejemplo}
        Sean 
        \begin{align*}
            W_1 = \left\{ (x,y,z):  -3x + y + 2z = 0\right\}
        \end{align*}
        y
        \begin{align*}
                W_2 = \left\{ (x,y,z):  x - y + 2z = 0\right\}.
        \end{align*}
        Encontrar generadores de $W_1 \cap W_2$. 
    \end{ejemplo}  \pause
    \begin{solucion}  \pause
        Es claro que
        \begin{equation*}
            W_1 \cap W_2 = \left\{ (x,y,z):  -3x + y + 2z = 0 \;\wedge \;  x - y + 2z = 0\right\}.
        \end{equation*}
    \end{solucion}

    \end{frame}

\begin{frame}
    Por lo tanto debemos resolver el sistema de ecuaciones
    \begin{equation*}
        \begin{cases}
        -3x + y + 2z = 0 \\  x - y + 2z = 0
        \end{cases}
    \end{equation*}\pause
    Reduzcamos la matriz del sistema a una MRF:
    \begin{align*}
        \begin{bmatrix}
        -3&1&2 \\  1&-1&2
        \end{bmatrix} &
        \stackrel{F_1+3F_2}{\longrightarrow}
        \begin{bmatrix}
        0&-2&8 \\  1&-1&2
        \end{bmatrix} 
        \stackrel{F_1/(-2)}{\longrightarrow}
        \begin{bmatrix}
        0&1&-4 \\  1&-1&2
        \end{bmatrix} 
        &\stackrel{F_2+F_1}{\longrightarrow}
        \begin{bmatrix}
        0&1&-4 \\  1&0&-2
        \end{bmatrix} 
    \end{align*}\pause

    Por lo tanto, $x_2 -4x_3 =0$ y $ x_1 -2x_3 =0$,  es decir  $x_2 = 4x_3$ y $ x_1 =2x_3 $. 
    \vskip .2cm\pause
    Luego, 
    \begin{equation*}
    W_1 \cap W_2 = \left\{ (2t,4t,t):  \t \in \R\right\} =  \left\{ t(2,4,1):  \t \in \R\right\}.
    \end{equation*}\pause

    La respuesta es entonces: $(2,4,1)$ es generador $ W_1 \cap W_2$. 




\qed

\end{frame}
        

        

\begin{frame}
    \begin{teorema}
        Sea $V$ un espacio vectorial sobre $\K$ y sean $v_1,\ldots,v_k \in V$. Entonces,  la intersección de todos los subespacios vectoriales que contienen  a $v_1,\ldots,v_k$ es igual a $\langle v_1,\ldots,v_k \rangle$.	
    \end{teorema}	  \pause
    \begin{proof}  \pause
        Denotemos 
        \begin{itemize}
            \item  $U= \bigcap$ de todos los subespacios vectoriales $\supseteq$ $\{ v_1,\ldots,v_k\}$.
        \end{itemize}
        \vskip .3cm  \pause
        Probaremos que  $U = \langle v_1,\ldots,v_k \rangle$ con la doble inclusión,  es decir probando que 
        $$U \subseteq  \langle v_1,\ldots,v_k \rangle \quad \text{y} \quad  \langle v_1,\ldots,v_k \rangle \subseteq U.$$
    \end{proof}
                    
\end{frame}

        

\begin{frame}
        
    ($U\subseteq\langle v_1, ..., v_k\rangle$) \;   \pause
    \vskip .3cm
    Primero, $U\subseteq\langle v_1, ..., v_k\rangle$ vale puesto que  $\langle v_1, ..., v_k\rangle$ es un subespacio que contiene a $\{v_1, ..., v_k\}$.
    \pause
\vskip .6cm
        
        
        
($\langle v_1,\ldots,v_k \rangle \subseteq U$) \;   \pause
\vskip .3cm
$U$  es intersección de subespacios $\Rightarrow$ (teor. p. \ref{th-interseccion}) $U$ es un subespacio.  
\vskip .3cm  \pause
Luego, $\{v_1, ..., v_k\}\subset U$  $\Rightarrow$ $\lambda_1v_1+\cdots+\lambda_kv_k\in U$, \; $\forall\,\lambda_1, ..., \lambda_k\in\K$.
\vskip .3cm  \pause
Por lo tanto $\langle v_1, ..., v_k\rangle\subseteq U.$ \qed
    
        
\end{frame}

    
\begin{frame}
    \begin{observacion}
        Si $V$ es un $\K$-espacio vectorial, $S$ y $T$ subespacios de $V$.   \pause
        \vskip .3cm
        Entonces $S \cup T$ \textit{no es necesariamente un subespacio} de $V$. 
        \vskip .3cm  \pause
        
    
        En efecto, consideremos en $\R^2$ los subespacios 
        $$S = \R(1,0)\quad \text{ y } T = \R(0,1).$$ 	
        \pause
        \begin{itemize}
            \item  $(1,0)\in  S$ y $(0,1) \in  T$ $\Rightarrow$  $(1,0), (0,1) \in  S \cup T$. \vskip .2cm
            \pause             \item Ahora bien $(1,0) + (0,1) = (1,1) \not\in S \cup T$, puesto que $(1,1) \not\in S$ y $(1,1) \not\in T$.
        \end{itemize}
    \end{observacion}
\end{frame}
            

\begin{frame}
    \begin{definicion} Sea $V$ un espacio vectorial sobre $\K$ y sean $S_1,\ldots,S_k$ subconjuntos  de $V$.
        definimos 
        \begin{equation*}
            S_1+  \cdots +S_k := \left\{s_1+\cdots+s_k: s_i \in S_i, 1 \le i \le k \right\},
        \end{equation*}
        el conjunto \textit{suma de los  $S_1,\ldots,S_k$.}
    \end{definicion}	
    \pause
    \vskip .8cm
    \begin{teorema}
        Sea $V$ un espacio vectorial sobre $\K$ y sean $W_1,\ldots,W_k$ subespacios  de $V$. Entonces $W= W_1+\cdots+W_k$ es un subespacio de $V$.
    \end{teorema}  \pause
    \begin{demostracion}  \pause
        Ejercicio (ver apunte). \qed
    \end{demostracion}
\end{frame}



\begin{frame}
    \begin{proposicion}
        Sea $V$ un espacio vectorial sobre $\K$ y sean $v_1,\ldots,v_r$ elementos de   de $V$. Entonces
        \begin{equation*}
            \langle v_1,\ldots,v_r \rangle = \langle v_1 \rangle+ \cdots + \langle v_r \rangle.
        \end{equation*}
    \end{proposicion}  \pause
    \begin{proof}  \pause
        Probemos el resultado viendo que los dos conjuntos se incluyen mutuamente.  \pause
        
        ($\subseteq$) Sea $w \in \langle v_1,\ldots,v_r \rangle$, luego $w = \lambda_1 v_1 +\cdots+ \lambda_r v_r$. Como $ \lambda_i v_i \in \langle v_i \rangle$, $1 \le i \le r$ ,  tenemos que  $w \in \langle v_1 \rangle+ \cdots + \langle v_r \rangle$.  En  consecuencia, $\langle v_1,\ldots,v_r \rangle \subseteq \langle v_1 \rangle+ \cdots + \langle v_r \rangle$.   \pause
        
        ($\supseteq$) Si $w \in \langle v_1 \rangle+ \cdots + \langle v_r \rangle$, entonces $w = w_1 + \cdots+w_r$ con $w_i \in \langle v_i\rangle$ para todo $i$. Por lo tanto, $w_i = \lambda_i v_i$ para algún $\lambda_i \in \K$ y  $w = \lambda_1 v_1 +\cdots+ \lambda_r v_r \in \langle v_1,\ldots,v_r \rangle $. En  consecuencia, $\langle v_1 \rangle+ \cdots + \langle v_r \rangle \subseteq \langle v_1,\ldots,v_r \rangle$. \qedhere
    \end{proof}

\end{frame}


\begin{frame}{Dependencia lineal}
\begin{definicion}
Sea $V$ un espacio vectorial sobre $\K$. Un subconjunto $S$ de $V$ se dice \textit{linealmente dependiente} o simplemente, \textit{LD} o \textit{dependiente}, si existen vectores distintos $v_1,\ldots,v_n \in S$  y escalares $\lambda_1,\ldots,\lambda_n$ de $\K$, no todos nulos, tales que 	
\begin{equation*}
    \lambda_1v_1+\cdots+\lambda_nv_n=0.
\end{equation*}
\end{definicion}\pause
\vskip .3cm
\begin{observacion}
Si el conjunto $S =\{v_1,\ldots,v_n\}$ , podemos reinterpretar la definición: 
    $v_1,\ldots,v_n$ son \textit{linealmente dependientes} o \textit{LD} si existen escalares $\lambda_1,\ldots,\lambda_n$ de $\K$, algún $\lambda_i \ne 0$, tales que 	
    \begin{equation*}
        \lambda_1v_1+\cdots+\lambda_nv_n=0.
    \end{equation*}
\end{observacion}


\end{frame}  




\begin{frame}
\begin{itemize}
\item En  la clase pasada vimos el concepto de que las combinaciones lineales de un conjunto de vectores generan un subespacio vectorial.\pause
\item Dado un subespacio vectorial: ¿Cuál es el  número mínimo de vectores que generan el subespacio?
\item En  general, dado un espacio vectorial ¿Cuál es el  número mínimo de vectores que generan el espacio y que propiedades tienen esos generadores?\pause

\end{itemize}
\vskip 1cm\pause
Estas preguntas serán respondidas en la clase siguiente,  pero ahora veremos algunas herramientas que nos permitan prepararnos para estos resultados.   
\end{frame}  







\begin{frame}

\begin{block}{Proposición}
Sea $V$ un espacio vectorial y $v_1, ..., v_n\in V$. Entonces $v_1, ..., v_n$ son LD si y solo si alguno de ellos es combinación lineal de los otros.
\end{block}\pause

\begin{demostracion}\pause
$(\Rightarrow)$ \pause Supongamos que son LD. Entonces $\lambda_1v_1+\cdots+\lambda_n v_n=0$ donde alg\'un escalar es no nulo. Digamos que tal escalar es $\lambda_i$. Podemos entonces despejar $v_i$, es decir escribirlo como combinación lineal de los otros:
\begin{align*}
    v_i=-\frac{\lambda_1}{\lambda_i}v_1-\cdots-\frac{\lambda_{i-1}}{\lambda_{i-1}}v_{i-1}-\frac{\lambda_{i+1}}{\lambda_{i+1}}v_{i+1}-\cdots-\frac{\lambda_n}{\lambda_i}v_n
    \end{align*}

\vskip .4cm\pause

$(\Leftarrow)$ \pause 
Supongamos que $v_i$ es combinaci\'on lineal de los otros, es decir 
\begin{align*}
&v_i=\lambda_1v_1+\cdots+\lambda_n\lambda_nv_n\\
\Rightarrow&0=\lambda_1v_1+\cdots-v_i+\cdots+\lambda_n\lambda_iv_n
\end{align*}
como $-1\neq0$ esta multiplicando a $v_i$, la \'ultima igualdad dice que los vectores son LD.\qed
\end{demostracion}

\end{frame}



\begin{frame}{Resumen}

En esta clase veremos que todo espacio vectorial tiene una base,  que es un conjunto de generadores mínimo. En  el caso que este conjunto sea finito, todo otro conjunto de generadores mínimo tendrá el  mismo número de elementos,  y este número será llamado \textit{dimensión}. 

\vskip .2cm

Los temas de la clase se ordenan de la siguiente forma: 

\begin{itemize}
    \item Definición de independencia lineal. 
    \item Definición de base (un conjunto linealmente independiente que genera el espacio).
    \item Ejemplos de bases de espacios vectoriales.  
    \item Propiedades de las bases y dimensión. 
\end{itemize}


\vskip .2cm

El tema de esta clase  está contenido de la sección 3.3 y 3.4 del apunte de clase ``Álgebra II / Álgebra - Notas del teórico''.
\end{frame}



\begin{frame}{Independencia lineal}
    \begin{definicion}
        Sea $V$ un espacio vectorial sobre $\K$. Un subconjunto $S$ de $V$ se dice \textit{linealmente independiente} (o simplemente, \textit{LI} o \textit{independiente}) si no es linealmente dependiente. 

\vskip .8cm
    \end{definicion}
    \begin{observacion}
        Si el conjunto $S$ tiene solo un número finito de vectores $v_1,\ldots,v_n$, se dice,
        a veces, que los $v_1,\ldots,v_n$ son \textit{independientes} o \textit{LI}, en vez de decir que $S$ es independiente.
    \end{observacion}
        
    
\end{frame}  




\begin{frame}
    
    \begin{observacion}
        Sea $V$ un espacio vectorial sobre $\K$ y $v_1,\ldots,v_n \in V$. 
        \begin{equation*}
            v_1,\ldots,v_n \text{ son LD} \; \Leftrightarrow\; \exists \lambda_i\text{'s} \in \K, \text{ alguno no nulo, t.q. }\;  \lambda_1v_1+\cdots+\lambda_nv_n=0.
        \end{equation*}
    \end{observacion}

    \begin{observacion} Por definición, un conjunto $v_1,\ldots,v_n $ es LI si se cumple:
        \begin{enumerate}
            \item[(a)] $\forall \,\lambda_i \in \K$ tal que $\lambda_j \ne 0$ para algún $j$\; $\Rightarrow$ \;  $\lambda_1v_1+\cdots+\lambda_nv_n\not=0$, 
            
            o bien
            
            \item[(b)]si $\lambda_i \in \K$ tal que $\lambda_1v_1+\cdots+\lambda_nv_n=0$ \; $\Rightarrow$ \;$0=\lambda_1=\cdots=\lambda_n$
        \end{enumerate}

        \vskip .2cm

        El enunciado (a) se deduce  negando  la definición de linealmente dependiente.
        
        \vskip .2cm 
        El enunciado  (b) es el contrarrecíproco  de (a).
        
    
        
    \end{observacion}
\end{frame}  


\begin{frame}
    
\begin{ejemplo}
En $\R^3$  los vectores $(1,-1,1)$ y $(-1,1,1)$ son LI, pues si $\lambda_1(1,-1,1)+\lambda_2(-1,1,1) =0$,  entonces $0= (\lambda_1,-\lambda_1,\lambda_1)+(-\lambda_2,\lambda_2,\lambda_2) =  (\lambda_1-\lambda_2,-\lambda_1+\lambda_2,\lambda_1+\lambda_2)$, 

y esto es cierto si 
\begin{equation*}
    \begin{array}{rcl}
    \lambda_1-\lambda_2 &=& 0 \\
    -\lambda_1+\lambda_2 &=& 0 \\
    \lambda_1+\lambda_2 &=& 0 
    \end{array}.
\end{equation*} 
Luego $\lambda_1 = \lambda_2$ y $\lambda_1 = -\lambda_2$, por lo tanto $\lambda_1 = \lambda_2 =0$. Es decir,  hemos visto que 
$$
\lambda_1(1,-1,1)+\lambda_2(-1,1,1) =0 \quad \Rightarrow \quad\lambda_1 = \lambda_2 =0,
$$
y, por lo tanto,  $(1,-1,1)$ y $(-1,1,1)$ son LI. \qed
\end{ejemplo}
\end{frame}  


\begin{frame}
    
\begin{ejemplo} Sea $\K$  cuerpo. En $\K^3$ los vectores
\begin{align*}
v_1 &= (\;\;3,\;0,-3) \\
v_2 &= (-1,\;1,\;\;2) \\
v_3 &= (\;\;4,\;2,-2) \\
v_4 &= (\;\;2,\;1,\,\;\;1)
\end{align*}

son linealmente dependientes, pues
$$
2v_1+2v_2 -v_3 +0.v_4 =0.
$$
Por otro lado, los vectores
\begin{align*}
e_1 &= (1,0,0) \\
e_2 &= (0,1,0) \\
e_3 &= (0,0,1) 
\end{align*}
son linealmente independientes. \qed
\end{ejemplo}

\end{frame}  


\begin{frame}
    Las siguientes afirmaciones son consecuencias casi inmediatas de la definición.
    \begin{enumerate}
        \item Todo conjunto que contiene un conjunto linealmente dependiente es linealmente dependiente.
        
        {\color{blue} Dem.} En el conjunto ``más chico''  hay una c. l.  no trivial que lo anula,  luego,  en el ``más grande'' también. \qed
        \item  Todo subconjunto de un conjunto linealmente independiente es linealmente independiente.
        
        {\color{blue} Dem.} Si el subconjnuto tiene una c. l.  no trivial que lo anula,  el conjunto también. \qed
        \item  Todo conjunto que contiene el vector $0$ es linealmente dependiente.
        
        {\color{blue} Dem.} En efecto, $1.0 = 0$. \qed
    \end{enumerate}
\end{frame}  


\begin{frame}
    
\begin{observacion}
En  general,  en $\K^m$, si queremos determinar si  $v_1,\ldots,v_n$ es LI, planteamos la ecuación  
\begin{equation*}
\lambda_1v_1+\cdots+\lambda_nv_n=(0,\ldots,0).
\end{equation*}
\vskip .4cm

Viendo esta ecuación  coordenada a coordenada, es equivalente a un sistema de $m$ ecuaciones lineales con  $n$ incógnitas (que son $\lambda_1,\ldots,\lambda_n$). 
\vskip .4cm

Si  la única solución es la trivial entonces $v_1,\ldots,v_n$ es LI. 
\vskip .4cm

Si hay alguna solución no trivial, entonces $v_1,\ldots,v_n$ es LD. 
\end{observacion}
\end{frame}  


\begin{frame}
    \begin{definicion}
        Sea $V$ un espacio vectorial. Una \textit{base}\index{base de un espacio vectorial} de $V$ es un conjunto $\mathcal B \subseteq V$ tal que
        \begin{enumerate}
            \item $\mathcal B$ genera a $V$, y
            \item $\mathcal B$ es LI.
        \end{enumerate}
        \vskip .6cm 
            El espacio $V$ es de \textit{dimensión finita} si tiene una base finita,  es decir con  un número finito de elementos.
    \end{definicion}
\end{frame}  


\begin{frame}
    
\begin{block}{ Ejemplo: base canónica de $\K^n$} Sea el espacio vectorial $\K^n$ y sean
\begin{equation*}
\begin{array}{rcl}
e_1 &=& (1,0,0,\ldots,0) \\
e_2 &=& (0,1,0,\ldots,0) \\
&&\qquad.\,.\,.\,.\,.\,.\,\\ 
e_n&=& (0,0,0,\ldots,1)
\end{array}
\end{equation*}
($e_i$ es el vector con todas sus coordenadas iguales a cero,  excepto  la coordenada $i$ que vale 1). Entonces veamos que  $e_1,\ldots,e_n$ es una base de $\K^n$.
\vskip .2cm
    1. Si $(x_1,\ldots,x_n) \in \K^n$,  entonces
    $$
    (x_1,\ldots,x_n) = x_1e_1+\cdots+x_ne_n.
    $$
    Por lo tanto, $e_1,\ldots,e_n$ genera a  $\K^n$.
\end{block}

\end{frame}  


\begin{frame}
    2. Si 
    $$
    x_1e_1+\cdots+x_ne_n =0,
    $$
    entonces
    \begin{align*}
        (0,\ldots,0) &= x_1(1,0,\ldots,0)+ x_2(0,1,\ldots,0)+\cdots+x_n(0,0,\ldots,1)\\ 
        &=  (x_1,0,\ldots,0)+(0,x_2,\ldots,0)+\cdots+(0,0,\ldots,x_n)\\ &= (x_1,x_2,\ldots,x_n).
    \end{align*}
    Luego, $x_1= x_2=\cdots=x_n =0$. 
    
    Por lo tanto $e_1,\ldots,e_n$ es LI.
    
    \vskip .4cm  
    Para $1 \le i \le n$, al vector $e_i$ se lo denomina el \textit{$i$-ésimo vector canónico}  y a la base $\mathcal B_n = \left\{e_1,\ldots,e_n \right\}$ se la denomina la \textit{base canónica}\index{base canónica} de $\K^n$. \qed
\end{frame}  


\begin{frame}
    \begin{block}{Ejemplo: vectores columna de una matriz invertible}
        Sea $P$ una matriz $n \times n$ invertible con elementos en el cuerpo $\K$. Sean $C_1,\ldots,C_n$ son los vectores columna de $P$. 


        Entonces, $\mathcal B = \{C_1,\ldots,C_n\}$, es una base de $\K^n$.
    \end{block}
    \begin{demostracion}
        Si $X = (x_1,\ldots,x_n) \in \K^n$, lo podemos ver como vector columna y 
        $$
        PX=x_1C_1+\cdots+x_nC_n.
        $$
        $PX=0$ tiene solo solución $X= 0$ $\Rightarrow$  $\mathcal B =\{C_1,\ldots,C_n\}$ es LI. 
        \vskip .4cm
        ¿Por qué generan $\K^n$? Sea $Y \in \K^n$, si $X = P^{-1} Y$, entonces $Y = PX$, esto es
        $$
        Y=x_1C_1+\cdots+x_nC_n.
        $$
        Así, $\{C_1,\ldots,C_n\}$ es una base de $\K^n$. \qed
    \end{demostracion}
\end{frame}  


\begin{frame}
    
    \begin{block}{Ejemplo: polinomios de grado $\le n-1$}
Sea $\K_n[x]$  el conjunto de polinomios de grado menor  que $n$ con coeficientes en $\K$:
$$
\K_n[x] = \left\{a_0 + a_1 x + a_2x^2+\cdots+a_{n-1}x^{n-1}: a_0,\ldots,a_{n-1} \in \K  \right\}.
$$
Entonces $1,x,x^2,\ldots,x^{n-1}$  es una base de $\K_n[x]$.

\vskip .4cm 

Es claro que los $1,x,x^2,\ldots,x^{n-1}$ generan $\K_n[x]$. 

\vskip .4cm 

Por otro lado, si  $\lambda_0 + \lambda_1 x + \lambda_2x^2+\cdots+\lambda_{n-1}x^{n-1} =0$, tenemos que $\lambda_0=\lambda_1 = \lambda_2 =\cdots =\lambda_{n-1} =0$.
\end{block}
\end{frame}  
            

\begin{frame}
    
    \begin{block}{Ejemplo: polinomios (base infinita)}
        Sea $\K[x]$  el conjunto de polinomios  con coeficientes en $\K$:
        $$
        \K[x] = \left\{a_0 + a_1 x + a_2x^2+\cdots+a_{n}x^{n}: n \in \N, a_0,\ldots,a_{n} \in \K  \right\}.
        $$
        Entonces $\mathcal B = \{1,x,x^2,\ldots,x^i, \ldots\} = \{x^i: i \in \N_0\}$  es una base de $\K[x]$.
        
        \vskip .4cm 
    
        Es claro que los $x^i$ generan $\K[x]$. 
        
        \vskip .4cm 
    
        Por otro lado, supongamos $\mathcal B$ se LD,  luego existe un subconjunto  \textit{finito} $S$  de $\mathcal B$ con el cual puedo hacer una c.l.  no trivial que de $0$. 
        
        \vskip .4cm 

        Sea $n$ tal que $S \subset   \{1,x,x^2,\ldots,x^n\}$. Entonces existen $\lambda_i$ no todos nulos tal que 
            $\lambda_0 + \lambda_1 x + \lambda_2x^2+\cdots+\lambda_{n-1}x^{n} =0$. Absurdo.

            \vskip .4cm 

            Por lo tanto $\mathcal B$ es base.
    \end{block}
\end{frame}


\begin{frame}
    \begin{block}{Ejemplo: base canónica de $M_{m \times n}(\K)$}
        Sean $1 \le i \le m$, $1\le j \le n$ y $E_{ij} \in M_{m \times n}(\K)$ definida por
        \begin{equation*}
            [E_{ij}]_{kl} = \left\{ 
            \begin{array}{lll}
            1& &\text{si $i=k$ y $j=l$,} \\
            0& &\text{otro caso}. 
            \end{array}
                \right.
        \end{equation*}
        Es decir $E_{ij}$  es la matriz cuyas entradas son todas iguales a 0,  excepto la entrada $ij$ que vale 1. En el caso $2 \times 2$  tenemos la matrices
        \begin{equation*}
            E_{11} = \begin{bmatrix} 1&0\\0&0\end{bmatrix}, \quad
            E_{12} = \begin{bmatrix} 0&1\\0&0\end{bmatrix}, \quad
            E_{21} = \begin{bmatrix} 0&0\\1&0\end{bmatrix}, \quad
            E_{22} = \begin{bmatrix} 0&0\\0&1\end{bmatrix}.
        \end{equation*}
        Volviendo al caso general,  
        $$
        \mathcal B = \{ E_{ij}: 1 \le i \le m, 1\le j \le n\}
        $$
        (son $mn$ vectores) es una base de  $M_{m \times n}(\K)$ y se la denomina la \textit{base canónica} de  $M_{m \times n}(\K)$.
        
        \vskip.4cm  
        La demostración es análoga al caso $\K^n$.

    \end{block}
\end{frame}  


\begin{frame}


Si $S$ es un conjunto finito denotemos $|S|$  al \textit{cardinal} de  $S$ es decir, la cantidad de elementos de $S$. 

\vskip .4cm

\begin{block}{Preguntas}
\vskip .4cm
\begin{itemize}
\item Dado $V$ espacio vectorial ¿existe una base de  $V$?

{\color{blue} Respuesta:} sí. La respuesta la da la teoría de conjuntos (Lema de Zorn). 
\vskip .4cm
\item Sea $V$ espacio vectorial y $\mathcal B$, $ \mathcal B'$ bases finitas de $V$ ¿Es  $|\mathcal B| =  |\mathcal B'|$?

{\color{blue} Respuesta:} sí. Es lo que veremos más adelante. 
\end{itemize}
\end{block}

\end{frame}  

\begin{frame}{¿Todo espacio vectorial  tiene una base ``explícita''?}
\begin{itemize}
\item Vimos en los ejemplos de las páginas anteriores bases de distintos espacios vectoriales.
\vskip.4cm  
\item Vimos  que hay bases finitas y bases infinitas, pero todas la bases que consideramos eran explícitas. 
\vskip.4cm  
\item Por  el Lema de Zorn existe una base $\mathcal B$  de $F(\R) = \{f: \R \to \R\}$.
\vskip.4cm  
\item ¿Se puede dar en forma relativamente explícita una base de $F(\R)$?
\vskip.4cm  
\item Respuesta: NO. 
\end{itemize}
\end{frame}


\begin{frame}




\begin{teorema}\label{indep-menorigual-gen}
    Sea $V$ un espacio vectorial generado por un conjunto finito de vectores $w_1,\ldots,w_m$. Entonces 
    $$
    S \subset V \text{ es LI } \Rightarrow |S| \le m.
    $$
\end{teorema}
\begin{proof} 
    Para demostrar este teorema es suficiente probar el contrarrecíproco del enunciado, es decir:
    $$
    \text{si }|S| > m \Rightarrow S \text{ es LD},
    $$
    Sea  $S = \{v_1,\ldots,v_n\}$ con $n >m$.  
    
    \vskip .2cm 
    Como  $w_1,\ldots,w_m$ generan $V$, existen escalares $a_{ij}$ en $\K$ tales que
    \begin{equation*}
        v_j = \sum_{i=1}^{m}a_{ij}w_i, \qquad (1 \le j \le n).
    \end{equation*}
\end{proof}
    
                
\end{frame}  


\begin{frame}
    Probaremos ahora que existen $x_1,\ldots,x_n \in \K$ no todos nulos, tal que $x_1v_1 + \cdots+x_nv_n =0$ ($S$ es LD). 
    \vskip .2cm
    Ahora bien, para cualesquiera $x_1,\ldots,x_n \in \K$ tenemos
    \begin{align*}
        x_1v_1 + \cdots+x_nv_n &= \sum_{j=1}^{n} x_jv_j& \\
        & = \sum_{j=1}^{n}x_j \sum_{i=1}^{m}a_{ij}w_i& \\
        & = \sum_{j=1}^{n} \sum_{i=1}^{m}(x_ja_{ij})w_i& \\ 
        & = \sum_{i=1}^{m}(\sum_{j=1}^{n} x_ja_{ij})w_i.& 
    \end{align*}
    
\end{frame}  


\begin{frame}

    Es decir,  para cualesquiera $x_1,\ldots,x_n \in \K$ tenemos
    \begin{align*}
        x_1v_1 + \cdots+x_nv_n &= \sum_{i=1}^{m}(\underbrace{\sum_{j=1}^{n} x_ja_{ij}}_{c_i})w_i.\tag{*}
    \end{align*}

    Si cada coeficiente $c_i$ es nulo $\Rightarrow$ $  x_1v_1 + \cdots+x_nv_n=0$. 
    
    \vskip .4cm 


    Vamos a ver ahora que $\exists$  $x_1,\ldots,x_n$ no todos nulos tal $c_i =0, \forall i$. 
    
    \vskip .4cm 
    
    
    Esto se debe a que el sistema de ecuaciones 
    \begin{equation*}
        \sum_{j=1}^{n} x_ja_{ij} = 0, \qquad (1 \le i \le m) 
    \end{equation*}
    tiene $m$ ecuaciones  y $n$ incógnitas con  $n > m$ $\Rightarrow$ existen soluciones no triviales (quedan variable libres). 
    
    \vskip .4cm
    
    
\end{frame}  

\begin{frame}
    Es decir, existen escalares $x_1,\ldots,x_n \in \K$ no todos nulos, tal que $$c_i = \sum_{j=1}^{n} x_ja_{ij} = 0,\quad  (1 \le i \le m)$$ y, por $(*)$, tenemos que  
    $$x_1v_1 + \cdots+x_nv_n =0.$$ 
    
    Esto quiere decir que los $v_1,\ldots,v_n$ son LD.
    \qed

    \vskip 3cm
\end{frame}




\begin{frame}{Resumen}

    Dado $V$  espacio vectorial de dimensión finita, veremos \pause
    \begin{itemize}
        \item la definición de dimensión,\pause
        \item todo subconjunto LI puede se completado a una base,\pause
        \item de todo subconjunto de generadores se puede extraer una base.\pause
    \end{itemize}
\vskip .4cm
Veremos también la forma de encontrar bases de subespacios de $\K^n$. Se hará usando operaciones elementales de fila. 

\vskip .8cm


    
    \pause
    \
    
    El tema de esta clase  está contenido de la sección 3.3 y 3.4 del apunte de clase ``Álgebra II / Álgebra - Notas del teórico''.
    \end{frame}
    
    \begin{frame}
        
    Recordemos este importante resultado de la clase anterior:
    \vskip.6cm
\pause
    Sea $V$ un espacio vectorial  y $T \subset V$, finito tal que  $\la T \ra = V$. Sea $S \subset V$.
    \vskip.4cm
    Entonces 
        \begin{equation*} \label{eq-1}
            \la T \ra = V, \quad  S \text{ es LI } \Rightarrow |S| \le |T|. \tag{P1}
        \end{equation*}
        
        
        \vskip.4cm

        El contrarrecíproco también nos resultará de utilidad

        \begin{equation*}\label{eq-2}
            \la T \ra = V, \quad  |S| > |T| \Rightarrow S \text{ es LD}.\tag{P2}
        \end{equation*}





    \end{frame} 
                    

\begin{frame} 
    
\begin{corolario}
Si $V$ es un espacio vectorial de dimensión finita, entonces dos bases cualesquiera de $V$ tienen el mismo número de elementos.
\end{corolario}\pause
\begin{proof}\pause
        $V$ es de dimensión finita $\Rightarrow$ $\exists\;\mathcal B$  base con  $|\mathcal B| < \infty$.

\vskip .2cm
    Sea $\mathcal B'$  otra base de $V$.\pause
    \vskip .2cm
    Como $\mathcal B$ es base $\Rightarrow$ $\la \mathcal B \ra  = V$ y  $\mathcal B'$ es   LI $\stackrel{(\ref{eq-1})}{\Rightarrow}$  $|\mathcal B'| \le |\mathcal B|$. 
    
    \vskip .2cm\pause

    Como $\mathcal B'$ es base  $\Rightarrow$  $\la \mathcal B' \ra  = V$ y  $\mathcal B$ es LI  $\stackrel{(\ref{eq-1})}{\Rightarrow}$  $|\mathcal B| \le |\mathcal B'|$.
    \pause
    \vskip .4cm
    En consecuencia $|\mathcal B| = |\mathcal B'|$. \qed
\end{proof}
\end{frame}  


\begin{frame}
    Hemos demostrado: si $V$  es un espacio vectorial de dimensión finita y $\mathcal B,\mathcal B' $ dos bases de $V$,  entonces $|\mathcal B|=|\mathcal B'|$.
    \vskip .2cm Esto nos permite hacer la siguiente definición. 

    \vskip .4cm\pause

    \begin{definicion}
        Sea $V$ espacio vectorial de dimensión finita. 
        \vskip .2cm
        Diremos que $n$  es \textit{la dimensión de $V$}\index{dimensión de un espacio vectorial} y  denotaremos $\dim V =n$,  si existe una base de $V$  de $n$  vectores. 
        \pause
    \vskip .2cm Si $V = \{0\}$,  entonces definimos $\dim V =0$.
    \end{definicion}
    
\end{frame}  


\begin{frame}
    


\begin{block}{Ejemplos} Sean $m,n \in \mathbb N$. 
\vskip .4cm\pause
\begin{enumerate}
    \item $\dim \K^n= n$, pues  la base canónica tiene $n$ elementos.\vskip .4cm\pause
    \item $\dim M_{m \times n}(\K) = mn$, pues la base canónica de $M_{m \times n}(\K)$ tiene $mn$  elementos.  \vskip .4cm\pause
    \item $\dim \K_n[x] =n$, pues $1,x,x^2,\ldots,x^{n-1}$ es una base.   
\end{enumerate}
\end{block}
    
\end{frame}  

                                        
                        
\begin{frame}
    
\begin{corolario}
Sea $V$ un espacio vectorial de dimensión finita y sea $n = \dim V$. 
Entonces
\begin{enumerate}
    \item  $S \subset V$  y  $|S| > n$ $\Rightarrow$ $S$  es LD.
    \item  $S \subset V$  y  $|S| < n$ $\Rightarrow$ $\la S \ra \subsetneqq V$.
\end{enumerate} 
\end{corolario}\pause
\begin{block}{Demostración} \pause Sea $\mathcal B$ base de $V$. 
\begin{enumerate}
\item Como $\mathcal B$ es base $\Rightarrow$ $\la \mathcal B \ra  = V$ y  $|S| > |\mathcal B|$ $\stackrel{(\ref{eq-2})}{\Rightarrow}$  $S$ es LD. 
\vskip .4cm    \pause
\item Supongamos que $\la S \ra  = V$.
\vskip .2cm    
Como $\mathcal B$ es base $\Rightarrow$ $\mathcal B$ es LI.
\vskip .2cm    
$\la S \ra  = V$ y $\mathcal B$ es LI  $\stackrel{(\ref{eq-1})}{\Rightarrow}$ $n=|\mathcal B| \le |S|$. Absurdo.

\end{enumerate} \qed
\end{block}
\end{frame}


\begin{frame}

\begin{lema}\label{li+vec=li} Sea $V$ espacio vectorial. 
\begin{itemize}
    \item  Sea $S \subset V$ y $S$ es LI.
    \item Sea $w$ tal que $w \not\in \la S \ra$.
\end{itemize}
\vskip .2cm
Entonces $S \cup  \{w\}$ es LI.
\end{lema}\pause
\vskip .4cm
\begin{proof}\pause
Sean  $v_1,\ldots,v_n$  vectores distintos de $S$ y  $\lambda_i,\lambda \in \K$  tales que
\begin{equation}\label{eq-dep-lin}
    \lambda_1 v_1 + \cdots + \lambda_n v_n + \lambda w =0 .
\end{equation}
Debemos probar que $\lambda_i=0$, $1 \le i \le n$, y $\lambda =0$.


\end{proof}


\end{frame}

\begin{frame}

Supongamos que $\lambda \ne 0$, entonces podemos dividir la ecuación por $\lambda$ y haciendo  pasaje de término  obtenemos
$$
w = \left(-\frac{\lambda_1}{\lambda}\right) v_1 + \cdots   \left(-\frac{\lambda_n}{\lambda}\right) v_n.
$$
\pause
Luego $w$ estaría  en el subespacio generado por $S$, lo cual contradice la hipótesis. 
\vskip .4cm 
Por  lo tanto $\lambda =0$ y, en consecuencia  
$$
\lambda_1 v_1 + \cdots + \lambda_n v_n =0.
$$ 
Como $S$ es un conjunto linealmente independiente, todo $\lambda_i = 0$. 

\qed
\end{frame}



\begin{frame}


\begin{teorema}\label{completar-bases}
Sea $V$ espacio vectorial de dimensión finita $n$ y $S_0$ un subconjunto LI de $V$. Entonces $S_0$  es finito  y existen $w_1,\ldots,w_m$ vectores en  $V$ tal que  $S_0 \cup \{w_1,\ldots,w_m\}$ es una base de $V$. 
\end{teorema}

\pause


\begin{corolario}
    Sea $W$  un subespacio de un espacio vectorial con de dimensión finita $n$ y $S_0$ un subconjunto LI de $W$. Entonces, $S_0$ se puede completar a una base de $W$. 
\end{corolario}

\pause
\begin{corolario}
    Sea $V$ espacio vectorial de dimensión finita y $V \ne \{0\}$, entonces $\dim V >0$.
\end{corolario}

\end{frame}




\begin{frame}

\begin{corolario}\label{dimw-menor-dimv}
Si $W$ es un subespacio propio de un espacio vectorial de dimensión finita $V$, entonces $W$ es de dimensión finita y  $\dim W < \dim V$.
\end{corolario}\pause
\begin{proof}\pause Si $W = \{0\}$, entonces $\dim W = 0$,  como $W \subsetneq V$,  tenemos que $V$  es no nulo y por lo tanto $\dim W = 0 < \dim V$. 
\vskip .4cm 
Si $W \ne \{0\}$, sea $\mathcal{B}'$ base de $W$. 

Si $\la  \mathcal{B}' \ra =V$, entonces $W = V$,  absurdo. Luego $\la  \mathcal{B}' \ra \ne V$ $\Rightarrow$ existen $w_1, \ldots, w_r$ que completan a una base de $V$ $\Rightarrow$ $\dim(W) = \dim(V) -r < \dim(V)$. 





\qed
\end{proof}

\end{frame}


\begin{frame}
Hemos visto que si  $V$  es un espacio de dimensión finita,  entonces todo conjunto LI se puede extender a una base. También vale: 
\pause

\begin{teorema}\label{gen->base}
Sea $V \ne 0$ espacio vectorial y $S$ un conjunto finito de generadores de $V$,  entonces existe un subconjunto $\mathcal B$  de $S$ que es una base.  
\end{teorema} 
\vskip .4cm\pause
El siguiente resultado relaciona dimensión con  suma e intersección de subespacios. 
\pause
\begin{teorema}
Si $W_1$, y $W_2$ son subespacios de dimensión finita de un espacio vectorial, entonces $W_1+ W_2$ es de dimensión finita y 
$$\dim (W_1 + W_2) = \dim W_1 + \dim W_2 - \dim (W_1 \cap W_2).$$
\end{teorema}
\end{frame}





\begin{frame}{Dimensiones de subespacios}
\pause
\begin{itemize}
    \item Si $A$ matriz $m \times n$, en donces $W = \{x: Ax=0\}$ es un subespacio.
    \vskip .6cm\pause
    \item ¿Cuál es la dimensión de $W$? ¿Qué relación tiene con $R$, la MRF equivalente a $A$?
    \vskip .6cm\pause
    \item Veremos que si $r$  es la cantidad  de filas no  nulas de $R$, entonces $\dim(W) = n-r$. 
\end{itemize}

\vskip 3cm

\end{frame}


\begin{frame}
        
\begin{ejemplo}
    Encontrar una base del subespacio 
    $$
    W = \left\{(x,y,z,w) \in \mathbb{R}: \quad\begin{array}{rcl}
    x-y -3z +\;\;w &=& 0 \\ y +5z +3w &=& 0
    \end{array} \right\}.
    $$
\end{ejemplo}\pause
\begin{solucion}\pause
    $W$  está definido implícitamente y usando el método de Gauss podemos describirlo paramétricamente, pues:
    \begin{equation*}
    \begin{bmatrix}1&-1&-3&1 \\ 0&1&5&3  \end{bmatrix}
    \stackrel{F_1+F_2}{\longrightarrow} 
    \begin{bmatrix}1&0&2&4 \\ 0&1&5&3  \end{bmatrix}.
    \end{equation*}
\end{solucion}
\end{frame}


\begin{frame}
Por lo tanto, el sistema de ecuaciones que define $W$ es equivalente a 
\begin{equation*}
\begin{array}{rcl}
x  +2z +4w &=& 0 \\ y +5z +3w &=& 0,
\end{array}
\end{equation*}
es decir 
\begin{equation*}
\begin{array}{rcl}
x  &=& -2z - 4w  \\ y &=& -5z -3w ,
\end{array}
\end{equation*}
y entonces
\begin{align*}
W &= \left\{(-2z -4w,-5z -3w,z,w) : z,w\in \mathbb{R} \right\} \\
&= \left\{(-2,-5,1,0)z+(-4, -3,0,1)w : z,w\in \mathbb{R} \right\}\\
&= \langle (-2,-5,1,0),(-4, -3,0,1)\rangle.
\end{align*}
Concluimos entonces que $(-2,-5,1,0),(-4, -3,0,1)$  es una base de $W$ y, por lo tanto,  su dimensión es 2.\qed
\end{frame}

\begin{frame}
\begin{proposicion}
Sea $A$ matriz $m \times n$ y sea $W = \{x: Ax=0\}$. 
\vskip .2cm
Sea $R$ una MRF equivalentes por filas a $A$ y  sea $r$ la cantidad de filas no nulas de $R$. 
\vskip .2cm
Entonces $\dim(W) = n - r$.
\end{proposicion}

\begin{demostracion} Es posible hacer este demostración con las herramientas actuales. Sin embargo,  haremos una demostración mucho más conceptual de  este hecho  cuando veamos transformaciones lineales. 
    \qed   
    
\end{demostracion}

\end{frame}


\begin{frame}
\begin{definicion}\label{espacio-fila-columna}  Sea $A = [a_{ij}] \in M_{m \times n}(\K)$.
    \vskip .4cm\pause
    \begin{itemize}
        \item  El \textit{vector fila $i$} es el vector  $(a_{i1},\ldots,a_{in}) \in \K^n$.
        \vskip .4cm\pause
        \item  El \textit{espacio fila}\index{matriz!espacio fila} de $A$ es el subespacio de $\K^n$ generado por los $m$ vectores fila de $A$. \pause
        \vskip .4cm
        \item El vector columna $j$ es el vector $(a_{1j},\ldots,a_{mj}) \in \K^m$.
        \vskip .4cm\pause
        \item El \textit{espacio columna}\index{matriz!espacio columna} de $A$ es el subespacio de $\K^m$ generado por los $n$ vectores columna de $A$
    \end{itemize}
\end{definicion}

\end{frame}


\begin{frame}

\begin{ejemplo*}
    Sea
    $$
    A = \begin{bmatrix}
    1&2&0&3&0\\ 0&0&1&4&0 \\0&0&0&0&1
    \end{bmatrix}.
    $$
    El vector fila 1 es $(1,2,0,3,0)$, el vector columna 4 es $(3,4,0)$,  etc.
\vskip .3cm
    Sea $W$ el espacio fila de $A$.  entonces

    \begin{equation*}
        W = \la (1,2,0,3,0), (0,0,1,4,0), (0,0,0,0,1)\ra
    \end{equation*}

    Sea $U$  el espacio columna de $A$. Entonces:

    \begin{equation*}
        U = \la (1,0,0), (2,0,0), (0,1,0), (3,4,0), (0,0,1)\ra = \R^3.
    \end{equation*}
\end{ejemplo*}
\end{frame}



\begin{frame}
        
\begin{teorema}
    Sean $A$ matriz $m \times n$ con coeficientes en $\K$, $P$ matriz $m\times m$ invertible y $B =PA$. Entonces el el espacio fila de $A$ es igual al espacio fila de $B$.
\end{teorema}\pause
\begin{proof}\pause

    Sea $W_1$ espacio fila de $A$ y $W_2$ espacio fila de $B$.
    \vskip .2cm 

    Sea $A= [a_{ij}]$, $P =[p_{ij}]$ y $B = [b_{ij}]$. Como  $B= PA$, tenemos que la fila $i$ de $B$ es
    \begin{align*}
        (b_{i1},\ldots,b_{in})&= (F_i(P).C_1(A),\ldots,F_i(P).C_n(A)) \\
        &= (\sum_{j=1}^{m} p_{ij}a_{j1}, \ldots, \sum_{j=1}^{m} p_{ij}a_{jn}) \\
        &= \sum_{j=1}^{m} p_{ij}(a_{j1}, \ldots,a_{jn}). \tag{*}
    \end{align*}

\end{proof}
\end{frame}


\begin{frame}




\begin{itemize}
    \item por (*) cada vector fila de $B$ se puede obtener como combinación lineal de los vectores fila de $A$.
    \vskip .2cm 
    \item Por lo tanto el espacio fila de $B$ está incluido en el espacio fila de $A$: $W_2 \subset W_1$.
    \vskip .4cm 
    \item $P$ invertible $\Rightarrow$ $\exists P^{-1}$.
    \vskip .2cm 
    \item $P^{-1}B = P^{-1}P A = A$.
    \vskip .2cm 
    \item Un razonamiento análogo al (*) de la página anterior $\Rightarrow$ espacio fila de $A$ está incluido en el espacio fila de $B$: $W_1 \subset W_2$. 
\end{itemize}

$$
W_2 \subset W_1 \quad \wedge \quad W_1 \subset W_2 \qquad \Rightarrow \qquad W_1 = W_2.  \qed
$$
\end{frame}


\begin{frame}

\begin{corolario}\label{subesp-merf}
    Sean $A$ matriz $m \times n$ y $R$ la MRF equivalente por filas a $A$. Entonces, 
    \begin{enumerate}
        \item  el espacio fila de $A$ es igual al espacio fila de $R$,
        \item las filas no nulas de $R$ forman una base del espacio fila de $A$. 
    \end{enumerate}
\end{corolario}\pause
\begin{proof}\pause

(1)   $R$ la MRF equivalente por filas a $A$ $\Rightarrow$  $R=PA$ con  $P$ invertible $\stackrel{Teor. ant.}{\Rightarrow}$ espacio fila de $A$ $=$ espacio fila de $B$. 

\vskip .4cm
(2) $R$ es MRF $\Rightarrow$  cada fila no nula comienza con un 1 y en esa coordenada  todas las demás filas tienen un 0 $\Rightarrow$ las filas no nulas de $R$ son LI $\Rightarrow$ las filas no nulas de $R$ son base.

\qed

\end{proof}

\end{frame}


\begin{frame}

\begin{corolario}\label{inv-impl-filasgen}
    Sean $A$ matriz $n \times n$. Entonces, $A$ es invertible si y sólo si las filas de $A$ son una base de $\K^n$.
\end{corolario}\pause
\begin{proof}\pause
Si $A$ es invertible entonces la MERF de $A$ es la identidad, por lo tanto  el espacio fila de $A$ genera $\K^n$.
\vskip .4cm
Por otro lado, si el espacio fila de $A$  genera $\K^n$, el espacio fila de  la  MERF es $\K^n$ y por lo tanto  la MERF de $A$ es la identidad y en consecuencia $A$ es invertible.
\vskip .4cm
Hemos probado que $A$ es invertible si y sólo si las $n$ filas de $A$ generan $\K^n$. 
\vskip .4cm
Como $\dim \K^n = n$,  todo conjunto de $n$ generadores es una base. \qed
\end{proof}

\end{frame}


\begin{frame}{Bases de subespacios}

El corolario de la p. \ref{subesp-merf} nos permite encontrar fácilmente la dimensión de un subespacio de $\K^n$ generado explícitamente por $m$ vectores.\vskip .2cm\pause
\begin{itemize}
\item Sea $v_1,\ldots,v_m \in \K^n$ y $W = \langle v_1,\ldots,v_m\rangle$,\pause
\item Consideramos la matriz 
$$
A = \begin{bmatrix}
v_1 \\ v_2 \\ \vdots \\ v_m
\end{bmatrix}
$$\pause
\item Calculamos $R$, una MRF equivalente por filas a $A$. \pause
\item $W$ $=$ espacio fila de $R$.\pause
\item Si $R$ tiene $r$ filas no nulas, las $r$ filas no nulas son una base de $W$.\pause
\item   Por consiguiente, $\dim W = r$. 
\end{itemize}


\end{frame}


\begin{frame}
\begin{ejemplo*}\label{ej-4.5}
    Encontrar una base  de $W= \langle (1,0,1), (1,-1,0), (5,-3,2)\rangle$. 
\end{ejemplo*}\pause
\begin{solucion}\pause
    Formemos la matriz cuyas filas son los vectores que generan $W$,  es decir 
    $$
    A = \begin{bmatrix} 1&0&1 \\ 1&-1&0 \\ 5&-3&2 \end{bmatrix}.
    $$
    Entonces
    \begin{equation*}
    \begin{bmatrix}1&0&1 \\ 1&-1&0 \\ 5&-3&2  \end{bmatrix}
    \underset{F_3-5F_1}{\stackrel{F_2- F_1}{\longrightarrow}} 
    \begin{bmatrix}1&0&1 \\ 0&-1&-1 \\ 0&-3&-3\end{bmatrix}
    \stackrel{-F_2}{\longrightarrow} 
    \begin{bmatrix}1&0&1 \\ 0&1&1 \\ 0&-3&-3\end{bmatrix}
    \stackrel{F_3 - 3F_2}{\longrightarrow}
    \begin{bmatrix}1&0&1 \\ 0&1&1 \\ 0&0&0\end{bmatrix}.
    \end{equation*}
    Por lo tanto, $\dim W =2$ y $(1,0,1), (0,1,1)$ es una base de  $W$. \qed
\end{solucion}
\end{frame}


\begin{frame}{Subconjuntos LI de un sistema de generadores}
\pause
\begin{itemize}
    \item Dada un conjunto de generadores de un subespacio $W$ de $\K^n$ ``sabemos'' encontrar una base de $W$.\vskip .4cm\pause
    \item Esa base de $W$,  en general, utiliza otros  vectores (no  necesariamente los generadores).\vskip .4cm\pause
    \item Veremos a continuación que dado $S= \{v_1, \ldots, v_m\}$ y $W= \la S \ra$, podemos encontrar fácilmente un subconjunto de $S$ base de $W$.    \vskip .4cm
\end{itemize}
\vskip 2cm
\end{frame}


\begin{frame}
\begin{teorema}
    Sea $v_1,\ldots, v_r$ vectores en $\K^n$ y $W = \langle  v_1,\ldots, v_r \rangle$. 
    \vskip .4cm
    Sea $A$ la matriz formada por las filas $v_1,\ldots, v_r$ y $R$ una MRF equivalente por filas a $A$ que se obtiene \textbf{sin} el uso de permutaciones de filas. 
    \vskip .4cm
    Si $i_1,i_2,\ldots,i_s$  filas no nulas de $R$ $\Rightarrow$ $v_{i_1},v_{i_2},\ldots,v_{i_s}$  base de $W$.
\end{teorema}\pause

\begin{proof}\pause
    Se hará por inducción sobre $r$. 
    \vskip .2cm
    Si $r = 1$ es trivial ver que vale la afirmación. 
    \vskip .2cm
    
    Supongamos que tenemos el resultado probado para $r-1$ (hipótesis inductiva).
    


\end{proof}
\end{frame}


\begin{frame}
        
Sea $W' = \langle  v_1,\ldots, v_{r-1} \rangle$ y sea $A'$ la matriz formada por las $r-1$ filas $v_1,\ldots, v_{r-1}$. 		
Sea $R'$ la MRF equivalente por filas a $A'$ que se obtiene sin usar permutaciones de filas. Por hipótesis inductiva, si $i_1,i_2,\ldots,i_s$ son las filas no nulas de $R'$,  entonces $v_{i_1},v_{i_2},\ldots,v_{i_s}$ es una base de $W'$.

Sea
\begin{equation*}
    R_0 = \begin{bmatrix}
    R' \\ v_r
    \end{bmatrix}.
\end{equation*}
Si $v_r \in W'$, entonces  $v_{i_1},v_{i_2},\ldots,v_{i_s}$ es una base de $W$ y 
\begin{equation*}
R = \begin{bmatrix}
R' \\ 0
\end{bmatrix}
\end{equation*}
es la MRF de $A$.

Si $v_r \not\in W'$, entonces  $v_{i_1},v_{i_2},\ldots,v_{i_s}, v_r$ es una base de $W$  y la MRF de $A$ tiene la última fila no nula.  \qed

\end{frame}


\begin{frame}
Finalmente, terminaremos la clase  con un teorema que resume algunas equivalencias respecto a matrices invertibles.

\begin{teorema}
Sea $A$ matriz $n \times n$ con coeficientes en $\K$. Entonces son equivalentes\pause
\begin{enumerate} 
    \item $A$ es invertible.\pause
    \item $A$  es equivalente por filas a $\Id_n$.\pause
    \item $A$ es producto de matrices elementales.\pause
    \item El sistema $AX=Y$ tiene una única solución para toda matriz $Y$ de orden $n \times 1$. \pause
    \item El sistema homogéneo $AX=0$ tiene una única solución trivial.\pause
    \item $\det A \ne 0$.\pause
    \item Las filas de $A$ son LI.\pause
    \item Las columnas de $A$ son LI.
\end{enumerate}
\end{teorema}
\end{frame}



\end{document}



\begin{frame}

\begin{definicion}
    Si $V$ es un espacio vectorial de dimensión finita, una \textit{base ordenada}\index{base ordenada} de $V$ es una sucesión finita de vectores linealmente independiente y que genera $V$.
\end{definicion}
\vskip .4cm
\pause
La diferencia entre la definición de ``base'' y la de ``base ordenada'',  es que en la última es  importante el orden de los vectores de la base. 
\vskip .6cm\pause
Se incurrirá en un pequeño abuso de notación y se escribirá
$$
\mathcal{B} = \{v_1,\ldots,v_n\}
$$
diciendo que $\mathcal{B}$ es una base ordenada de $V$.
\vskip 2cm

\end{frame}


\begin{frame}
\begin{proposicion}
    Sea $V$  espacio vectorial de dimensión finita y sea $\mathcal{B} = \{v_1,\ldots,v_n\}$ una base ordenada de $V$. Entonces, para cada $v \in V$,  existen únicos $x_1,\ldots,x_n \in \K$ tales que $$v =   x_1v_1 + \cdots +x_nv_n.$$
\end{proposicion}\pause
\begin{proof}\pause
    Como $v_1,\ldots,v_n$  generan $V$,  es claro que existen $x_1,\ldots,x_n \in \K$ tales que 
    $$v =   x_1v_1 + \cdots +x_nv_n.$$
    Sean $y_1,\ldots,y_n \in \K$ tales que $$v =   y_1v_1 + \cdots +y_nv_n.$$
    
    
    
\end{proof}


\end{frame}


\begin{frame}

Veremos que $x_i = y_i$ para $1 \le i \le n$.

\vskip .4cm

Como $v =  \sum_{i=1}^{n} x_iv_i$ y $v =  \sum_{i=1}^{n} y_iv_i$,  restando miembro a miembro obtenemos 
$$
0 =   \sum_{i=1}^{n} (x_i-y_i)v_i.
$$
Ahora bien,  $v_1,\ldots,v_n$ son  LI, por lo tanto todos los coeficientes de la ecuación anterior son nulos.
\vskip .2cm
Es decir $x_i-y_i=0$ para $1 \le i \le n$.
\vskip .2cm
Entonces $x_i = y_i$ para $1 \le i \le n$.

\qed \vskip 2cm
\end{frame}
                                            
                
\end{document}